<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S0957417416301786</prism:url><dc:identifier>doi:10.1016/j.eswa.2016.04.012</dc:identifier><eid>1-s2.0-S0957417416301786</eid><prism:doi>10.1016/j.eswa.2016.04.012</prism:doi><pii>S0957-4174(16)30178-6</pii><dc:title>Sliding window-based support vector regression for predicting micrometeorological data </dc:title><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>09574174</prism:issn><prism:volume>59</prism:volume><prism:startingPage>217</prism:startingPage><prism:endingPage>225</prism:endingPage><prism:pageRange>217-225</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2016-10-15</prism:coverDate><prism:coverDisplayDate>15 October 2016</prism:coverDisplayDate><prism:copyright>© 2016 The Authors. Published by Elsevier Ltd.</prism:copyright><prism:publisher>The Authors. Published by Elsevier Ltd.</prism:publisher><dc:creator>Kaneda, Yukimasa</dc:creator><dc:creator>Mineno, Hiroshi</dc:creator><dc:description>AbstractSensor network technology is becoming more widespread and sophisticated, and devices with many sensors, such as smartphones and sensor nodes, have been used extensively. Since these devices have more easily accumulated various kinds of micrometeorological data, such as temperature, humidity, and wind speed, an enormous amount of micrometeorological data has been accumulated. In recent years, it has been expected that such an enormous amount of data, called big data, will produce novel knowledge and value. Accordingly, many current applications have used data mining technology or machine learning to exploit big data. However, micrometeorological data has a complicated correlation among different features, and its characteristics change variously with time. Therefore, it is difficult to predict micrometeorological data accurately with low computational complexity even if state-of-the-art machine learning algorithms are used. In this paper, we propose a new methodology for predicting micrometeorological data, sliding window-based support vector regression (SW-SVR) that involves a novel combination of support vector regression (SVR) and ensemble learning. To represent complicated micrometeorological data easily, SW-SVR builds several SVRs specialized for each representative data group in various natural environments, such as different seasons and climates, and changes weights to aggregate the SVRs dynamically depending on the characteristics of test data. In our experiment, we predicted the temperature after 1h and 6 h by using large-scale micrometeorological data in Tokyo. As a result, regardless of testing periods, training periods, and prediction horizons, the prediction performance of SW-SVR was always greater than or equal to other general methods such as SVR, random forest, and gradient boosting. At the same time, SW-SVR reduced the building time remarkably compared with those of complicated models that have high prediction performance.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType>Author</openaccessSponsorType><openaccessUserLicense>http://creativecommons.org/licenses/by/4.0/</openaccessUserLicense><dcterms:subject>Predicting micrometeorological data</dcterms:subject><dcterms:subject>Data extraction</dcterms:subject><dcterms:subject>Dynamic aggregation</dcterms:subject><dcterms:subject>Support vector regression</dcterms:subject><dcterms:subject>Ensemble learning</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S0957417416301786"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S0957417416301786"/></coredata><objects><object ref="gr1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="81" size="8499">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr1.sml?httpAccept=%2A%2F%2A</object><object ref="gr2" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="84" size="9224">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr2.sml?httpAccept=%2A%2F%2A</object><object ref="gr3" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="84" size="9329">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr3.sml?httpAccept=%2A%2F%2A</object><object ref="gr4" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="67" size="6979">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr4.sml?httpAccept=%2A%2F%2A</object><object ref="gr5" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="89" size="8390">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr5.sml?httpAccept=%2A%2F%2A</object><object ref="gr6" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="90" size="8454">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr6.sml?httpAccept=%2A%2F%2A</object><object ref="gr1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="708" height="262" size="50640">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr1.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="698" height="268" size="58160">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr2.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="700" height="267" size="56554">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr3.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="712" height="216" size="42356">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr4.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="701" height="285" size="54802">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr5.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="701" height="288" size="52938">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-gr6.jpg?httpAccept=%2A%2F%2A</object><object ref="si10" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="219" height="20" size="666">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si10.gif?httpAccept=%2A%2F%2A</object><object ref="si20" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="254" height="108" size="2265">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si20.gif?httpAccept=%2A%2F%2A</object><object ref="si30" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="79" height="18" size="340">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si30.gif?httpAccept=%2A%2F%2A</object><object ref="si5" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="13" height="11" size="139">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si5.gif?httpAccept=%2A%2F%2A</object><object ref="si6" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="63" height="12" size="259">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si6.gif?httpAccept=%2A%2F%2A</object><object ref="si7" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="226" height="41" size="1177">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si7.gif?httpAccept=%2A%2F%2A</object><object ref="si8" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="274" height="20" size="944">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si8.gif?httpAccept=%2A%2F%2A</object><object ref="si9" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="186" height="20" size="646">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si9.gif?httpAccept=%2A%2F%2A</object><object ref="si11" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="363" height="16" size="1249">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si11.gif?httpAccept=%2A%2F%2A</object><object ref="si12" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="225" height="16" size="661">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si12.gif?httpAccept=%2A%2F%2A</object><object ref="si13" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="179" height="44" size="1044">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si13.gif?httpAccept=%2A%2F%2A</object><object ref="si14" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="145" height="21" size="644">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si14.gif?httpAccept=%2A%2F%2A</object><object ref="si15" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="283" height="17" size="905">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si15.gif?httpAccept=%2A%2F%2A</object><object ref="si16" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="170" height="41" size="1024">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si16.gif?httpAccept=%2A%2F%2A</object><object ref="si17" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="194" height="17" size="726">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si17.gif?httpAccept=%2A%2F%2A</object><object ref="si18" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="132" height="20" size="544">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si18.gif?httpAccept=%2A%2F%2A</object><object ref="si19" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="10" height="9" size="120">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si19.gif?httpAccept=%2A%2F%2A</object><object ref="si2" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="108" height="13" size="400">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si2.gif?httpAccept=%2A%2F%2A</object><object ref="si21" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="285" height="143" size="3392">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si21.gif?httpAccept=%2A%2F%2A</object><object ref="si22" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="404" height="110" size="3615">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si22.gif?httpAccept=%2A%2F%2A</object><object ref="si23" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="465" height="170" size="4006">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si23.gif?httpAccept=%2A%2F%2A</object><object ref="si24" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="187" height="21" size="828">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si24.gif?httpAccept=%2A%2F%2A</object><object ref="si25" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="35" height="22" size="246">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si25.gif?httpAccept=%2A%2F%2A</object><object ref="si26" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="115" height="18" size="449">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si26.gif?httpAccept=%2A%2F%2A</object><object ref="si27" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="299" height="22" size="1085">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si27.gif?httpAccept=%2A%2F%2A</object><object ref="si28" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="465" height="53" size="2034">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si28.gif?httpAccept=%2A%2F%2A</object><object ref="si29" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="376" height="48" size="1823">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si29.gif?httpAccept=%2A%2F%2A</object><object ref="si3" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="159" height="41" size="835">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si3.gif?httpAccept=%2A%2F%2A</object><object ref="si31" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="11" height="18" size="151">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si31.gif?httpAccept=%2A%2F%2A</object><object ref="si32" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="226" height="56" size="1355">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si32.gif?httpAccept=%2A%2F%2A</object><object ref="si4" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="41" height="11" size="181">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si4.gif?httpAccept=%2A%2F%2A</object><object ref="si1" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="203" height="17" size="720">http://api.elsevier.com/content/object/eid/1-s2.0-S0957417416301786-si1.gif?httpAccept=%2A%2F%2A</object></objects><scopus-id>84964961073</scopus-id><scopus-eid>2-s2.0-84964961073</scopus-eid><link rel="abstract" href="http://api.elsevier.com/content/abstract/scopus_id/84964961073"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>271506</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291817</xocs:ssid><xocs:ssid type="subj">291820</xocs:ssid><xocs:ssid type="subj">291862</xocs:ssid><xocs:ssid type="subj">291866</xocs:ssid><xocs:ssid type="subj">291870</xocs:ssid><xocs:ssid type="subj">291883</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>Expert Systems with Applications</xocs:srctitle><xocs:normalized-srctitle>EXPERTSYSTEMSAPPLICATIONS</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20160423">2016-04-23</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20160423">2016-04-23</xocs:available-online-date><xocs:vor-load-date yyyymmdd="20160506">2016-05-06</xocs:vor-load-date><xocs:vor-available-online-date yyyymmdd="20160506">2016-05-06</xocs:vor-available-online-date><xocs:ew-transaction-id>2016-05-17T17:01:59</xocs:ew-transaction-id><xocs:eid>1-s2.0-S0957417416301786</xocs:eid><xocs:pii-formatted>S0957-4174(16)30178-6</xocs:pii-formatted><xocs:pii-unformatted>S0957417416301786</xocs:pii-unformatted><xocs:doi>10.1016/j.eswa.2016.04.012</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.1</xocs:item-version-number><xocs:item-weight>FULL-TEXT</xocs:item-weight><xocs:hub-eid>1-s2.0-S0957417416X00103</xocs:hub-eid><xocs:timestamp yyyymmdd="20160517">2016-05-17T12:40:53.866652-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20161015</xocs:date-search-begin><xocs:year-nav>2016</xocs:year-nav><xocs:indexeddate epoch="1461423505">2016-04-23T14:58:25.628847Z</xocs:indexeddate><xocs:articleinfo>articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>0957-4174</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>09574174</xocs:issn-primary-unformatted></xocs:issns><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>NONE</xocs:funding-body-id><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>59</xocs:vol-first><xocs:volume-list><xocs:volume>59</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 59</xocs:vol-iss-suppl-text><xocs:sort-order>17</xocs:sort-order><xocs:first-fp>217</xocs:first-fp><xocs:last-lp>225</xocs:last-lp><xocs:pages><xocs:first-page>217</xocs:first-page><xocs:last-page>225</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>20161015</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>15 October 2016</xocs:cover-date-text><xocs:cover-date-start>2016-10-15</xocs:cover-date-start><xocs:cover-date-year>2016</xocs:cover-date-year><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>© 2016 The Authors. Published by Elsevier Ltd.</xocs:copyright-line><xocs:normalized-article-title>SLIDINGWINDOWBASEDSUPPORTVECTORREGRESSIONFORPREDICTINGMICROMETEOROLOGICALDATA</xocs:normalized-article-title><xocs:normalized-first-auth-surname>KANEDA</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>Y</xocs:normalized-first-auth-initial><xocs:item-toc><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>1</xocs:item-toc-label><xocs:item-toc-section-title>Introduction</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2</xocs:item-toc-label><xocs:item-toc-section-title>Related work</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2.1</xocs:item-toc-label><xocs:item-toc-section-title>Support vector regression</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2.2</xocs:item-toc-label><xocs:item-toc-section-title>Ensemble learning</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3</xocs:item-toc-label><xocs:item-toc-section-title>SW-SVR: Sliding window-based support vector regression</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4</xocs:item-toc-label><xocs:item-toc-section-title>Evaluation</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.1</xocs:item-toc-label><xocs:item-toc-section-title>Experiment</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.2</xocs:item-toc-label><xocs:item-toc-section-title>Results and discussion</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5</xocs:item-toc-label><xocs:item-toc-section-title>Conclusion and future work</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:acknowledgment"><xocs:item-toc-section-title>Acknowledgements</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:bibliography"><xocs:item-toc-section-title>References</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc><xocs:references><xocs:ref-info refid="sbref0001"><xocs:ref-normalized-surname>ANTONANZAS</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-first-fp>380</xocs:ref-first-fp><xocs:ref-last-lp>390</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0002"><xocs:ref-normalized-surname>BREIMAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2001</xocs:ref-pub-year><xocs:ref-first-fp>5</xocs:ref-first-fp><xocs:ref-last-lp>32</xocs:ref-last-lp><xocs:ref-normalized-initial>L</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0003"><xocs:ref-normalized-surname>CAO</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>9</xocs:ref-last-lp><xocs:ref-normalized-initial>H</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0004"><xocs:ref-normalized-surname>CHANG</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>39</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0005"><xocs:ref-normalized-surname>CHEVALIER</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>151</xocs:ref-first-fp><xocs:ref-last-lp>159</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0006"><xocs:ref-normalized-surname>FAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>1871</xocs:ref-first-fp><xocs:ref-last-lp>1874</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0007"><xocs:ref-normalized-surname>FREUND</xocs:ref-normalized-surname><xocs:ref-pub-year>1997</xocs:ref-pub-year><xocs:ref-first-fp>119</xocs:ref-first-fp><xocs:ref-last-lp>139</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0008"><xocs:ref-normalized-surname>FRIEDMAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2001</xocs:ref-pub-year><xocs:ref-first-fp>1189</xocs:ref-first-fp><xocs:ref-last-lp>1232</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0009"><xocs:ref-normalized-surname>HUANG</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>231</xocs:ref-first-fp><xocs:ref-last-lp>240</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0010"/><xocs:ref-info refid="sbref0011"><xocs:ref-normalized-surname>KISI</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>783</xocs:ref-first-fp><xocs:ref-last-lp>792</xocs:ref-last-lp><xocs:ref-normalized-initial>O</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0012"><xocs:ref-normalized-surname>KOLOKOTSA</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>1850</xocs:ref-first-fp><xocs:ref-last-lp>1863</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0012a"><xocs:ref-normalized-surname>LOOSLI</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-first-fp>291</xocs:ref-first-fp><xocs:ref-last-lp>301</xocs:ref-last-lp><xocs:ref-normalized-initial>G</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0013"><xocs:ref-normalized-surname>MACQUEEN</xocs:ref-normalized-surname><xocs:ref-pub-year>1967</xocs:ref-pub-year><xocs:ref-first-fp>281</xocs:ref-first-fp><xocs:ref-last-lp>297</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCEEDINGSFIFTHBERKELEYSYMPOSIUMMATHEMATICALSTATISTICSPROBABILITY</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>METHODSFORCLASSIFICATIONANALYSISMULTIVARIATEOBSERVATIONS</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0014"><xocs:ref-normalized-surname>MAITY</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>917</xocs:ref-first-fp><xocs:ref-last-lp>923</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0015"><xocs:ref-normalized-surname>MOHAMMADI</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-first-fp>433</xocs:ref-first-fp><xocs:ref-last-lp>441</xocs:ref-last-lp><xocs:ref-normalized-initial>K</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0016"><xocs:ref-normalized-surname>OTHMAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>1204</xocs:ref-first-fp><xocs:ref-last-lp>1210</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCEDIAENGINEERING</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>WIRELESSSENSORNETWORKAPPLICATIONSASTUDYINENVIRONMENTMONITORINGSYSTEM</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0017"><xocs:ref-normalized-surname>PARK</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>3640</xocs:ref-first-fp><xocs:ref-last-lp>3651</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="othref0002"/><xocs:ref-info refid="sbref0018"><xocs:ref-normalized-surname>PLATT</xocs:ref-normalized-surname><xocs:ref-pub-year>1998</xocs:ref-pub-year><xocs:ref-first-fp>185</xocs:ref-first-fp><xocs:ref-last-lp>208</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0019"><xocs:ref-normalized-surname>RAHIMI</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-first-fp>1177</xocs:ref-first-fp><xocs:ref-last-lp>1184</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0020"><xocs:ref-normalized-surname>SINGH</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>426</xocs:ref-first-fp><xocs:ref-last-lp>437</xocs:ref-last-lp><xocs:ref-normalized-initial>K</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0021"><xocs:ref-normalized-surname>SMITH</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>52</xocs:ref-first-fp><xocs:ref-last-lp>61</xocs:ref-last-lp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0022"><xocs:ref-normalized-surname>SUZUKI</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>8</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>SWSVRIMPROVEDBYSHORTDISTANCEDATACOLLECTIONMETHOD</xocs:ref-normalized-srctitle></xocs:ref-info><xocs:ref-info refid="sbref0023"><xocs:ref-normalized-surname>SUZUKI</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-first-fp>37</xocs:ref-first-fp><xocs:ref-last-lp>48</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0024"><xocs:ref-normalized-surname>TENENHAUS</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>159</xocs:ref-first-fp><xocs:ref-last-lp>205</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0025"><xocs:ref-normalized-surname>TSANG</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>363</xocs:ref-first-fp><xocs:ref-last-lp>392</xocs:ref-last-lp><xocs:ref-normalized-initial>I</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0026"><xocs:ref-normalized-surname>URRACA</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-article-number>023136</xocs:ref-article-number><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0027"><xocs:ref-normalized-surname>VAPNIK</xocs:ref-normalized-surname><xocs:ref-pub-year>1995</xocs:ref-pub-year><xocs:ref-normalized-initial>V</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>NATURESTATISTICALLEARNINGTHEORY</xocs:ref-normalized-srctitle></xocs:ref-info><xocs:ref-info refid="sbref0028"><xocs:ref-normalized-surname>WANG</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>20</xocs:ref-last-lp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0029"><xocs:ref-normalized-surname>XIE</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>5445</xocs:ref-first-fp><xocs:ref-last-lp>5449</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:refkeys><xocs:refkey3>KANEDAX2016X217</xocs:refkey3><xocs:refkey4lp>KANEDAX2016X217X225</xocs:refkey4lp><xocs:refkey4ai>KANEDAX2016X217XY</xocs:refkey4ai><xocs:refkey5>KANEDAX2016X217X225XY</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2016-04-25T08:31:20Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>Author</xocs:oa-sponsor-type></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by/4.0/</xocs:oa-user-license></xocs:open-access><xocs:self-archiving><xocs:sa-start-date>2018-05-06T00:00:00Z</xocs:sa-start-date><xocs:sa-embargo-status>UnderEmbargo</xocs:sa-embargo-status><xocs:sa-user-license>http://creativecommons.org/licenses/by-nc-nd/4.0/</xocs:sa-user-license></xocs:self-archiving><xocs:copyright-info><xocs:cp-license-lines><xocs:cp-license-line lang="en">This is an open access article under the CC BY license.</xocs:cp-license-line></xocs:cp-license-lines><xocs:cp-notices><xocs:cp-notice lang="en">© 2016 The Authors. Published by Elsevier Ltd.</xocs:cp-notice></xocs:cp-notices></xocs:copyright-info><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S0957-4174(16)30178-6</xocs:pii-formatted><xocs:pii-unformatted>S0957417416301786</xocs:pii-unformatted><xocs:eid>1-s2.0-S0957417416301786</xocs:eid><xocs:doi>10.1016/j.eswa.2016.04.012</xocs:doi><xocs:cid>271506</xocs:cid><xocs:timestamp>2016-05-17T12:40:53.866652-04:00</xocs:timestamp><xocs:cover-date-start>2016-10-15</xocs:cover-date-start><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>NONE</xocs:funding-body-id><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S0957417416301786-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/MAIN/application/pdf/66cd4702871f54965b2a3e51301bca3d/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/MAIN/application/pdf/66cd4702871f54965b2a3e51301bca3d/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>759004</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>9</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S0957417416301786-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/PREVIEW/image/png/48ccd580fe8e2efce0ae72590606f781/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/PREVIEW/image/png/48ccd580fe8e2efce0ae72590606f781/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>57978</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr1.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr1/THUMBNAIL/image/gif/2885f9381b81428f84b907d934583631/gr1.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr1/THUMBNAIL/image/gif/2885f9381b81428f84b907d934583631/gr1.sml</xocs:ucs-locator><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>8499</xocs:filesize><xocs:pixel-height>81</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr2.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr2/THUMBNAIL/image/gif/892db66ebf98cbd9f07d704ee5678629/gr2.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr2/THUMBNAIL/image/gif/892db66ebf98cbd9f07d704ee5678629/gr2.sml</xocs:ucs-locator><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>9224</xocs:filesize><xocs:pixel-height>84</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr3.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr3/THUMBNAIL/image/gif/d948ed26e2e3f6d413f8d9f0c15dc560/gr3.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr3/THUMBNAIL/image/gif/d948ed26e2e3f6d413f8d9f0c15dc560/gr3.sml</xocs:ucs-locator><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>9329</xocs:filesize><xocs:pixel-height>84</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr4.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr4/THUMBNAIL/image/gif/c15a2598c89a47b549bbe3fa20209e5e/gr4.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr4/THUMBNAIL/image/gif/c15a2598c89a47b549bbe3fa20209e5e/gr4.sml</xocs:ucs-locator><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>6979</xocs:filesize><xocs:pixel-height>67</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr5.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr5/THUMBNAIL/image/gif/92b0705865e936c3720b320a3d5419f9/gr5.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr5/THUMBNAIL/image/gif/92b0705865e936c3720b320a3d5419f9/gr5.sml</xocs:ucs-locator><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>8390</xocs:filesize><xocs:pixel-height>89</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr6.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr6/THUMBNAIL/image/gif/524f43b32d56a8fc4b1f01f111d5d3eb/gr6.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr6/THUMBNAIL/image/gif/524f43b32d56a8fc4b1f01f111d5d3eb/gr6.sml</xocs:ucs-locator><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>8454</xocs:filesize><xocs:pixel-height>90</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr1.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr1/DOWNSAMPLED/image/jpeg/498e5088c6fc72d781b354bab67d07b2/gr1.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr1/DOWNSAMPLED/image/jpeg/498e5088c6fc72d781b354bab67d07b2/gr1.jpg</xocs:ucs-locator><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>50640</xocs:filesize><xocs:pixel-height>262</xocs:pixel-height><xocs:pixel-width>708</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr2.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr2/DOWNSAMPLED/image/jpeg/d484207d2b8d40b3d69fbc579406ac2a/gr2.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr2/DOWNSAMPLED/image/jpeg/d484207d2b8d40b3d69fbc579406ac2a/gr2.jpg</xocs:ucs-locator><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>58160</xocs:filesize><xocs:pixel-height>268</xocs:pixel-height><xocs:pixel-width>698</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr3.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr3/DOWNSAMPLED/image/jpeg/d996ff2bcc76dd7456c1c5540a7230df/gr3.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr3/DOWNSAMPLED/image/jpeg/d996ff2bcc76dd7456c1c5540a7230df/gr3.jpg</xocs:ucs-locator><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>56554</xocs:filesize><xocs:pixel-height>267</xocs:pixel-height><xocs:pixel-width>700</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr4.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr4/DOWNSAMPLED/image/jpeg/59501524a58640d52e660c7861de1658/gr4.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr4/DOWNSAMPLED/image/jpeg/59501524a58640d52e660c7861de1658/gr4.jpg</xocs:ucs-locator><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>42356</xocs:filesize><xocs:pixel-height>216</xocs:pixel-height><xocs:pixel-width>712</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr5.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr5/DOWNSAMPLED/image/jpeg/29feab85f1c05d34bef5f731099a3ea3/gr5.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr5/DOWNSAMPLED/image/jpeg/29feab85f1c05d34bef5f731099a3ea3/gr5.jpg</xocs:ucs-locator><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>54802</xocs:filesize><xocs:pixel-height>285</xocs:pixel-height><xocs:pixel-width>701</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-gr6.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/gr6/DOWNSAMPLED/image/jpeg/c309aa64a1c8a2ef559e3de360f299ec/gr6.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/gr6/DOWNSAMPLED/image/jpeg/c309aa64a1c8a2ef559e3de360f299ec/gr6.jpg</xocs:ucs-locator><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>52938</xocs:filesize><xocs:pixel-height>288</xocs:pixel-height><xocs:pixel-width>701</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si10.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/be6b6997d535a09d404f8a57418d841c/si10.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/be6b6997d535a09d404f8a57418d841c/si10.gif</xocs:ucs-locator><xocs:file-basename>si10</xocs:file-basename><xocs:filename>si10.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>666</xocs:filesize><xocs:pixel-height>20</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si20.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/ba75ee9e81c1d0cdc92ae6e686694366/si20.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/ba75ee9e81c1d0cdc92ae6e686694366/si20.gif</xocs:ucs-locator><xocs:file-basename>si20</xocs:file-basename><xocs:filename>si20.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>2265</xocs:filesize><xocs:pixel-height>108</xocs:pixel-height><xocs:pixel-width>254</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si30.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/2d380eeb2a287720d7e9ac4d3582bbf7/si30.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/2d380eeb2a287720d7e9ac4d3582bbf7/si30.gif</xocs:ucs-locator><xocs:file-basename>si30</xocs:file-basename><xocs:filename>si30.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>340</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>79</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si5.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/e54b5ca82292184053a5ad2aa7984fea/si5.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/e54b5ca82292184053a5ad2aa7984fea/si5.gif</xocs:ucs-locator><xocs:file-basename>si5</xocs:file-basename><xocs:filename>si5.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>139</xocs:filesize><xocs:pixel-height>11</xocs:pixel-height><xocs:pixel-width>13</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si6.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/f1dd9795445c98f6e35da67797d33476/si6.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/f1dd9795445c98f6e35da67797d33476/si6.gif</xocs:ucs-locator><xocs:file-basename>si6</xocs:file-basename><xocs:filename>si6.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>259</xocs:filesize><xocs:pixel-height>12</xocs:pixel-height><xocs:pixel-width>63</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si7.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/7c65babe5e6189cd91db206485aca2e6/si7.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/7c65babe5e6189cd91db206485aca2e6/si7.gif</xocs:ucs-locator><xocs:file-basename>si7</xocs:file-basename><xocs:filename>si7.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1177</xocs:filesize><xocs:pixel-height>41</xocs:pixel-height><xocs:pixel-width>226</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si8.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/1a4e0a947902494c2a8b0b87d0ef4898/si8.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/1a4e0a947902494c2a8b0b87d0ef4898/si8.gif</xocs:ucs-locator><xocs:file-basename>si8</xocs:file-basename><xocs:filename>si8.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>944</xocs:filesize><xocs:pixel-height>20</xocs:pixel-height><xocs:pixel-width>274</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si9.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/830ffe3622ffeab7145e936742d45c07/si9.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/830ffe3622ffeab7145e936742d45c07/si9.gif</xocs:ucs-locator><xocs:file-basename>si9</xocs:file-basename><xocs:filename>si9.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>646</xocs:filesize><xocs:pixel-height>20</xocs:pixel-height><xocs:pixel-width>186</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si11.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/0341f78adfccf3ea81356cd60d769b5d/si11.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/0341f78adfccf3ea81356cd60d769b5d/si11.gif</xocs:ucs-locator><xocs:file-basename>si11</xocs:file-basename><xocs:filename>si11.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1249</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>363</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si12.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/7fda3e4e365b55ab9aa7cf4e43541209/si12.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/7fda3e4e365b55ab9aa7cf4e43541209/si12.gif</xocs:ucs-locator><xocs:file-basename>si12</xocs:file-basename><xocs:filename>si12.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>661</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>225</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si13.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/f9e51627840680b6953b74f26ae58e8a/si13.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/f9e51627840680b6953b74f26ae58e8a/si13.gif</xocs:ucs-locator><xocs:file-basename>si13</xocs:file-basename><xocs:filename>si13.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1044</xocs:filesize><xocs:pixel-height>44</xocs:pixel-height><xocs:pixel-width>179</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si14.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/b9b196cc9e92468b655e10a8ee9034f5/si14.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/b9b196cc9e92468b655e10a8ee9034f5/si14.gif</xocs:ucs-locator><xocs:file-basename>si14</xocs:file-basename><xocs:filename>si14.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>644</xocs:filesize><xocs:pixel-height>21</xocs:pixel-height><xocs:pixel-width>145</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si15.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/517b111a1d4b514007597e9285f94821/si15.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/517b111a1d4b514007597e9285f94821/si15.gif</xocs:ucs-locator><xocs:file-basename>si15</xocs:file-basename><xocs:filename>si15.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>905</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>283</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si16.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/764cba5c1f069654db776aece3a97b96/si16.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/764cba5c1f069654db776aece3a97b96/si16.gif</xocs:ucs-locator><xocs:file-basename>si16</xocs:file-basename><xocs:filename>si16.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1024</xocs:filesize><xocs:pixel-height>41</xocs:pixel-height><xocs:pixel-width>170</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si17.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/312b4e7660bb746b4c03a3c8c0d2c69b/si17.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/312b4e7660bb746b4c03a3c8c0d2c69b/si17.gif</xocs:ucs-locator><xocs:file-basename>si17</xocs:file-basename><xocs:filename>si17.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>726</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>194</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si18.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/3821a996d90aef1c577bde150e65cad5/si18.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/3821a996d90aef1c577bde150e65cad5/si18.gif</xocs:ucs-locator><xocs:file-basename>si18</xocs:file-basename><xocs:filename>si18.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>544</xocs:filesize><xocs:pixel-height>20</xocs:pixel-height><xocs:pixel-width>132</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si19.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/8bafab94cc873fc07187c4491617749b/si19.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/8bafab94cc873fc07187c4491617749b/si19.gif</xocs:ucs-locator><xocs:file-basename>si19</xocs:file-basename><xocs:filename>si19.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>120</xocs:filesize><xocs:pixel-height>9</xocs:pixel-height><xocs:pixel-width>10</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si2.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/9f69e3609c599e016c14876e64d2ec05/si2.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/9f69e3609c599e016c14876e64d2ec05/si2.gif</xocs:ucs-locator><xocs:file-basename>si2</xocs:file-basename><xocs:filename>si2.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>400</xocs:filesize><xocs:pixel-height>13</xocs:pixel-height><xocs:pixel-width>108</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si21.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/a9ea8c39d66ab53c0b035712f8ea0752/si21.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/a9ea8c39d66ab53c0b035712f8ea0752/si21.gif</xocs:ucs-locator><xocs:file-basename>si21</xocs:file-basename><xocs:filename>si21.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>3392</xocs:filesize><xocs:pixel-height>143</xocs:pixel-height><xocs:pixel-width>285</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si22.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/96dcc955249392d6cb22faabc3e8b7ee/si22.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/96dcc955249392d6cb22faabc3e8b7ee/si22.gif</xocs:ucs-locator><xocs:file-basename>si22</xocs:file-basename><xocs:filename>si22.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>3615</xocs:filesize><xocs:pixel-height>110</xocs:pixel-height><xocs:pixel-width>404</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si23.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/0ee7ebcc8cbc7795def621e075f9d5df/si23.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/0ee7ebcc8cbc7795def621e075f9d5df/si23.gif</xocs:ucs-locator><xocs:file-basename>si23</xocs:file-basename><xocs:filename>si23.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>4006</xocs:filesize><xocs:pixel-height>170</xocs:pixel-height><xocs:pixel-width>465</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si24.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/27636d95dcc6c909b1a657ea7849e32d/si24.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/27636d95dcc6c909b1a657ea7849e32d/si24.gif</xocs:ucs-locator><xocs:file-basename>si24</xocs:file-basename><xocs:filename>si24.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>828</xocs:filesize><xocs:pixel-height>21</xocs:pixel-height><xocs:pixel-width>187</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si25.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/9ea9d7e664e2eb6e7a75995d3d1c5cdb/si25.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/9ea9d7e664e2eb6e7a75995d3d1c5cdb/si25.gif</xocs:ucs-locator><xocs:file-basename>si25</xocs:file-basename><xocs:filename>si25.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>246</xocs:filesize><xocs:pixel-height>22</xocs:pixel-height><xocs:pixel-width>35</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si26.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/4762b4f4d4aa51e5da5517e316a0aec8/si26.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/4762b4f4d4aa51e5da5517e316a0aec8/si26.gif</xocs:ucs-locator><xocs:file-basename>si26</xocs:file-basename><xocs:filename>si26.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>449</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>115</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si27.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/6952d9890d3e1516bdc563f2a5a3f7c3/si27.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/6952d9890d3e1516bdc563f2a5a3f7c3/si27.gif</xocs:ucs-locator><xocs:file-basename>si27</xocs:file-basename><xocs:filename>si27.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1085</xocs:filesize><xocs:pixel-height>22</xocs:pixel-height><xocs:pixel-width>299</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si28.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/c5bf4ee57c644c44163387b3ec9d8cb4/si28.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/c5bf4ee57c644c44163387b3ec9d8cb4/si28.gif</xocs:ucs-locator><xocs:file-basename>si28</xocs:file-basename><xocs:filename>si28.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>2034</xocs:filesize><xocs:pixel-height>53</xocs:pixel-height><xocs:pixel-width>465</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si29.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/5fe8ded8ea5a700a42fa3fbdddf6b1da/si29.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/5fe8ded8ea5a700a42fa3fbdddf6b1da/si29.gif</xocs:ucs-locator><xocs:file-basename>si29</xocs:file-basename><xocs:filename>si29.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1823</xocs:filesize><xocs:pixel-height>48</xocs:pixel-height><xocs:pixel-width>376</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si3.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/22e7fcd6fb7bffcb96d1005cb29c0af5/si3.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/22e7fcd6fb7bffcb96d1005cb29c0af5/si3.gif</xocs:ucs-locator><xocs:file-basename>si3</xocs:file-basename><xocs:filename>si3.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>835</xocs:filesize><xocs:pixel-height>41</xocs:pixel-height><xocs:pixel-width>159</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si31.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/c4e3a8761c6f7f084e9c863e271c54dc/si31.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/c4e3a8761c6f7f084e9c863e271c54dc/si31.gif</xocs:ucs-locator><xocs:file-basename>si31</xocs:file-basename><xocs:filename>si31.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>151</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>11</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si32.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/2a7a632144d8f2795fed7bf665714bb5/si32.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/2a7a632144d8f2795fed7bf665714bb5/si32.gif</xocs:ucs-locator><xocs:file-basename>si32</xocs:file-basename><xocs:filename>si32.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1355</xocs:filesize><xocs:pixel-height>56</xocs:pixel-height><xocs:pixel-width>226</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si4.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/3a97195859202cca5d6811d4e6733fde/si4.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/3a97195859202cca5d6811d4e6733fde/si4.gif</xocs:ucs-locator><xocs:file-basename>si4</xocs:file-basename><xocs:filename>si4.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>181</xocs:filesize><xocs:pixel-height>11</xocs:pixel-height><xocs:pixel-width>41</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S0957417416301786-si1.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0957417416301786/STRIPIN/image/gif/a9204d54e3fbe52c510737ad6762e5c3/si1.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0957417416301786/STRIPIN/image/gif/a9204d54e3fbe52c510737ad6762e5c3/si1.gif</xocs:ucs-locator><xocs:file-basename>si1</xocs:file-basename><xocs:filename>si1.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>720</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>203</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" docsubtype="fla" version="5.4" xml:lang="en"><item-info><jid>ESWA</jid><aid>10632</aid><ce:pii>S0957-4174(16)30178-6</ce:pii><ce:doi>10.1016/j.eswa.2016.04.012</ce:doi><ce:copyright type="other" year="2016">The Authors</ce:copyright></item-info><ce:floats><ce:figure id="fig0001"><ce:label>Fig. 1</ce:label><ce:caption id="cap0001"><ce:simple-para id="spara0008" view="all">Processing overview of SW-SVR.</ce:simple-para></ce:caption><ce:alt-text id="alt0001" role="short">Fig 1</ce:alt-text><ce:link id="celink0001" locator="gr1" xlink:type="simple" xlink:href="pii:S0957417416301786/gr1"/></ce:figure><ce:figure id="fig0002"><ce:label>Fig. 2</ce:label><ce:caption id="cap0002"><ce:simple-para id="spara0009" view="all">MAPE for prediction after 1<ce:hsp sp="0.2"/>h for each algorithm. Note that (b) and (c) are shown with log scale.</ce:simple-para></ce:caption><ce:alt-text id="alt0002" role="short">Fig 2</ce:alt-text><ce:link id="celink0002" locator="gr2" xlink:type="simple" xlink:href="pii:S0957417416301786/gr2"/></ce:figure><ce:figure id="fig0003"><ce:label>Fig. 3</ce:label><ce:caption id="cap0003"><ce:simple-para id="spara0010" view="all">MAPE for prediction after 6 h for each algorithm. Note that (b) and (c) are shown with log scale.</ce:simple-para></ce:caption><ce:alt-text id="alt0003" role="short">Fig 3</ce:alt-text><ce:link id="celink0003" locator="gr3" xlink:type="simple" xlink:href="pii:S0957417416301786/gr3"/></ce:figure><ce:figure id="fig0004"><ce:label>Fig. 4</ce:label><ce:caption id="cap0004"><ce:simple-para id="spara0011" view="all">Average of each extraction rate by D-SDC in SW-SVR.</ce:simple-para></ce:caption><ce:alt-text id="alt0004" role="short">Fig 4</ce:alt-text><ce:link id="celink0004" locator="gr4" xlink:type="simple" xlink:href="pii:S0957417416301786/gr4"/></ce:figure><ce:figure id="fig0005"><ce:label>Fig. 5</ce:label><ce:caption id="cap0005"><ce:simple-para id="spara0012" view="all">Building time for prediction after 1<ce:hsp sp="0.2"/>h for each model. Note that all figures are shown with log scale.</ce:simple-para></ce:caption><ce:alt-text id="alt0005" role="short">Fig 5</ce:alt-text><ce:link id="celink0005" locator="gr5" xlink:type="simple" xlink:href="pii:S0957417416301786/gr5"/></ce:figure><ce:figure id="fig0006"><ce:label>Fig. 6</ce:label><ce:caption id="cap0006"><ce:simple-para id="spara0013" view="all">Building time for prediction after 6 h for each model. Note that all figures are shown with log scale.</ce:simple-para></ce:caption><ce:alt-text id="alt0006" role="short">Fig 6</ce:alt-text><ce:link id="celink0006" locator="gr6" xlink:type="simple" xlink:href="pii:S0957417416301786/gr6"/></ce:figure><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="tbl0001" rowsep="0" colsep="0" frame="topbot"><ce:label>Table 1</ce:label><ce:caption id="cap0007"><ce:simple-para id="spara0014" view="all">MAPE of 10-fold cross-validation for each algorithm.</ce:simple-para></ce:caption><ce:alt-text id="alt0007" role="short">Table 1</ce:alt-text><tgroup cols="12"><colspec colnum="1" colname="col1" align="left"/><colspec colnum="2" colname="col2" align="left"/><colspec colnum="3" colname="col3" align="left"/><colspec colnum="4" colname="col4" align="left"/><colspec colnum="5" colname="col5" align="left"/><colspec colnum="6" colname="col6" align="left"/><colspec colnum="7" colname="col7" align="left"/><colspec colnum="8" colname="col8" align="left"/><colspec colnum="9" colname="col9" align="left"/><colspec colnum="10" colname="col10" align="left"/><colspec colnum="11" colname="col11" align="left"/><colspec colnum="12" colname="col12" align="left"/><thead><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0001" colname="col1" valign="top"/><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0007" namest="col2" rowsep="1" nameend="col12" align="left">Methods</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0013" colname="col1" valign="top">Prediction horizons</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0014" colname="col2" valign="top">SW-SVR</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0015" colname="col3" valign="top">k-NN</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0016" colname="col4" valign="top">DT</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0017" colname="col5" valign="top">Adaboost</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0018" colname="col6" valign="top">Bagging</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0019" colname="col7" valign="top">RF</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0020" colname="col8" valign="top">GB</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0021" colname="col9" valign="top">Linear SVR</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0022" colname="col10" valign="top">mapped SVR</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0023" colname="col11" valign="top">RBF-SVR</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0024" colname="col12" valign="top">Persistent</entry></row></thead><tbody><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0025" colname="col1" role="rowhead" valign="top">1h
</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0026" colname="col2" valign="top" align="char" char=".">5.18608</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0027" colname="col3" valign="top" align="char" char=".">8.59929</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0028" colname="col4" valign="top" align="char" char=".">5.81042</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0029" colname="col5" valign="top" align="char" char=".">11.10375</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0030" colname="col6" valign="top" align="char" char=".">10.24014</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0031" colname="col7" valign="top" align="char" char=".">5.57213</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0032" colname="col8" valign="top" align="char" char=".">5.27190</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0033" colname="col9" valign="top" align="char" char=".">5.43892</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0034" colname="col10" valign="top" align="char" char=".">5.25274</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0035" colname="col11" valign="top" align="char" char=".">5.16985</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0036" colname="col12" valign="top" align="char" char=".">5.96816</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0037" colname="col1" role="rowhead" valign="top">6h
</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0038" colname="col2" valign="top" align="char" char=".">23.49826</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0039" colname="col3" valign="top" align="char" char=".">26.52433</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0040" colname="col4" valign="top" align="char" char=".">25.99290</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0041" colname="col5" valign="top" align="char" char=".">29.93160</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0042" colname="col6" valign="top" align="char" char=".">29.58125</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0043" colname="col7" valign="top" align="char" char=".">25.55044</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0044" colname="col8" valign="top" align="char" char=".">24.14987</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0045" colname="col9" valign="top" align="char" char=".">24.68383</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0046" colname="col10" valign="top" align="char" char=".">24.26108</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0047" colname="col11" valign="top" align="char" char=".">20.94132</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0048" colname="col12" valign="top" align="char" char=".">24.86800</entry></row></tbody></tgroup></ce:table><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="tbl0002" rowsep="0" colsep="0" frame="topbot"><ce:label>Algorithm 1</ce:label><ce:caption id="cap0008"><ce:simple-para id="spara0015" view="all">Bagging for regression.</ce:simple-para></ce:caption><ce:alt-text id="alt0008" role="short">Algorithm 1</ce:alt-text><tgroup cols="1"><colspec colnum="1" colname="col1" align="left"/><tbody><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0049" colname="col1" role="rowhead" valign="top"><bold>Input:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0050" colname="col1" role="rowhead" valign="top"> Training data: <italic>D</italic><hsp sp="0.12"/>=<hsp sp="0.12"/><mml:math altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math> where <bold>x</bold><inf loc="post">i</inf> ∈ <italic>X</italic>, <italic>y</italic><inf loc="post">i</inf> ∈ <italic>Y</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0051" colname="col1" role="rowhead" valign="top">
 Number of weak learners: <italic>n</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0052" colname="col1" role="rowhead" valign="top"><bold>For</bold><mml:math altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.33em"/><mml:mi>to</mml:mi><mml:mspace width="0.33em"/><mml:mi>n</mml:mi><mml:mspace width="0.33em"/><mml:mi mathvariant="bold">do</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0053" colname="col1" role="rowhead" valign="top"> 1. <italic>D<inf loc="post">t</inf></italic> ← generate sample from <italic>D</italic> with replacement</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0054" colname="col1" role="rowhead" valign="top"> 2. <italic>H<inf loc="post">t</inf></italic>(<italic>X</italic>) ← build a weak learner from <italic>D<inf loc="post">t</inf></italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0055" colname="col1" role="rowhead" valign="top"><bold>Output:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0056" colname="col1" role="rowhead" valign="top">
<mml:math altimg="si3.gif" overflow="scroll"><mml:mrow><mml:mspace width="1em"/><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></entry></row></tbody></tgroup></ce:table><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="tbl0003" rowsep="0" colsep="0" frame="topbot"><ce:label>Algorithm 2</ce:label><ce:caption id="cap0009"><ce:simple-para id="spara0016" view="all">Boosting for regression.</ce:simple-para></ce:caption><ce:alt-text id="alt0009" role="short">Algorithm 2</ce:alt-text><tgroup cols="1"><colspec colnum="1" colname="col1" align="left"/><tbody><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0057" colname="col1" role="rowhead" valign="top"><bold>Input:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0058" colname="col1" role="rowhead" valign="top"> Training data: <italic>D</italic><hsp sp="0.12"/>=<hsp sp="0.12"/><mml:math altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math> where <bold>x</bold><inf loc="post">i</inf> ∈ <italic>X</italic>, <italic>y</italic><inf loc="post">i</inf> ∈ <italic>Y</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0059" colname="col1" role="rowhead" valign="top"> Number of weak learners: <italic>n</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0060" colname="col1" role="rowhead" valign="top"> Weights: <bold>w</bold><inf loc="post"><italic>i</italic></inf><hsp sp="0.12"/>=<hsp sp="0.12"/>1/<italic>N</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0061" colname="col1" role="rowhead" valign="top"><bold>For</bold><mml:math altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.33em"/><mml:mi>to</mml:mi><mml:mspace width="0.33em"/><mml:mi>n</mml:mi><mml:mspace width="0.33em"/><mml:mi mathvariant="bold">do</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0062" colname="col1" role="rowhead" valign="top"> 1. <italic>H<inf loc="post">t</inf></italic>(<italic>X</italic>) ← build a weak learner from <italic>D</italic> by using weights <bold>w</bold><inf loc="post"><italic>t</italic></inf>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0063" colname="col1" role="rowhead" valign="top"> 2. <mml:math altimg="si4.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mspace width="0.33em"/></mml:mrow></mml:math>compute error rate of <italic>H<inf loc="post">t</inf></italic>(<italic>X</italic>)
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0064" colname="col1" role="rowhead" valign="top"> 3. <italic>α</italic><inf loc="post"><italic>t</italic></inf> ← compute reliability of prediction result of <italic>H<inf loc="post">t</inf></italic>(<italic>X</italic>) based on <mml:math altimg="si5.gif" overflow="scroll"><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0065" colname="col1" role="rowhead" valign="top"> 4. <mml:math altimg="si6.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mspace width="0.33em"/></mml:mrow></mml:math>update weights <bold>w</bold><inf loc="post"><italic>t</italic></inf> based on <italic>α</italic><inf loc="post"><italic>t</italic></inf>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0066" colname="col1" role="rowhead" valign="top"><bold>Output:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0067" colname="col1" role="rowhead" valign="top"> 
<mml:math altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></entry></row></tbody></tgroup></ce:table><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="tbl0004" rowsep="0" colsep="0" frame="topbot"><ce:label>Algorithm 3</ce:label><ce:caption id="cap0010"><ce:simple-para id="spara0017" view="all">Sliding window-based support vector regression.</ce:simple-para></ce:caption><ce:alt-text id="alt0010" role="short">Algorithm 3</ce:alt-text><tgroup cols="1"><colspec colnum="1" colname="col1" align="left"/><tbody><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0068" colname="col1" role="rowhead" valign="top"><bold>Input:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0069" colname="col1" role="rowhead" valign="top"> Training data set: <italic>S</italic><hsp sp="0.12"/>=<hsp sp="0.12"/><mml:math altimg="si8.gif" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math> where <mml:math altimg="si9.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0070" colname="col1" role="rowhead" valign="top"> Test data: <bold><italic>P</italic></bold>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0071" colname="col1" role="rowhead" valign="top"> Number of weak learners: <italic>n</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0072" colname="col1" role="rowhead" valign="top"> Weight parameters: <italic>p</italic>, <italic>q</italic>
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0073" colname="col1" role="rowhead" valign="top"><bold>Preprocessing:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0074" colname="col1" role="rowhead" valign="top"> <bold>1.</bold> apply normalization to <italic>X</italic> <italic>and</italic> <italic>X</italic>′
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0075" colname="col1" role="rowhead" valign="top"> <bold>2.</bold> fit kernel approximation and PLS regression to <italic>X</italic> and <italic>X</italic>′
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0076" colname="col1" role="rowhead" valign="top"> <bold>3.</bold><mml:math altimg="si10.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>∥</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>⋯</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0077" colname="col1" role="rowhead" valign="top"> <bold>4.</bold><mml:math altimg="si11.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mspace width="0.33em"/><mml:mo>←</mml:mo><mml:mrow><mml:mi>each</mml:mi><mml:mspace width="0.33em"/><mml:mi>center</mml:mi><mml:mspace width="0.33em"/><mml:mi>of</mml:mi></mml:mrow><mml:mspace width="0.33em"/><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0078" colname="col1" role="rowhead" valign="top"><bold>For</bold><mml:math altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.33em"/><mml:mi>to</mml:mi><mml:mspace width="0.33em"/><mml:mi>n</mml:mi><mml:mspace width="0.33em"/><mml:mi mathvariant="bold">do</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0079" colname="col1" role="rowhead" valign="top"> <bold>1.</bold><mml:math altimg="si12.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi mathvariant="italic">ti</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>⋯</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0080" colname="col1" role="rowhead" valign="top"> <bold>2.</bold><mml:math altimg="si13.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><mml:math altimg="si14.gif" overflow="scroll"><mml:mrow><mml:mi>where</mml:mi><mml:mspace width="0.33em"/><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.33em"/><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0081" colname="col1" role="rowhead" valign="top"> <bold>3.</bold><mml:math altimg="si15.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0082" colname="col1" role="rowhead" valign="top"> <bold>4.</bold> <italic>H<inf loc="post">t</inf></italic>(<italic>X</italic>) ← train <italic>LinearSVR</italic>(<italic>S<inf loc="post">t</inf></italic>)
</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0083" colname="col1" role="rowhead" valign="top"><bold>Output:</bold></entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" id="en0084" colname="col1" role="rowhead" valign="top" align="char" char=".">
 <italic>H</italic>(<bold><italic>P</italic></bold>) = <mml:math altimg="si16.gif" overflow="scroll"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><mml:math altimg="si17.gif" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">where</mml:mi></mml:mrow><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:math><italic><sup loc="post">q</sup></italic></entry></row></tbody></tgroup></ce:table></ce:floats><head><ce:title id="tte0001">Sliding window-based support vector regression for predicting micrometeorological data</ce:title><ce:author-group id="aut0001"><ce:author id="au0001"><ce:given-name>Yukimasa</ce:given-name><ce:surname>Kaneda</ce:surname><ce:cross-ref id="crf0001" refid="aff0001"><ce:sup loc="post">a</ce:sup></ce:cross-ref><ce:cross-ref id="crf0002" refid="cor0001"><ce:sup loc="post">*</ce:sup></ce:cross-ref><ce:e-address id="ead0001" type="email">kaneda@minelab.jp</ce:e-address></ce:author><ce:author id="au0002" orcid="0000-0002-3921-4298"><ce:given-name>Hiroshi</ce:given-name><ce:surname>Mineno</ce:surname><ce:cross-ref id="crf0003" refid="aff0002"><ce:sup loc="post">b</ce:sup></ce:cross-ref><ce:cross-ref id="crf0004" refid="aff0003"><ce:sup loc="post">c</ce:sup></ce:cross-ref></ce:author><ce:affiliation id="aff0001"><ce:label>a</ce:label><ce:textfn id="cetextfn0001">Graduate School of Integrated Science and Technology, Shizuoka University, 3-5-1 Johoku, Naka-ku, Hamamatsu, Shizuoka 432-8011, Japan</ce:textfn><sa:affiliation><sa:organization>Graduate School of Integrated Science and Technology</sa:organization><sa:organization>Shizuoka University</sa:organization><sa:address-line>3-5-1 Johoku, Naka-ku</sa:address-line><sa:city>Hamamatsu</sa:city><sa:state>Shizuoka</sa:state><sa:postal-code>432-8011</sa:postal-code><sa:country>Japan</sa:country></sa:affiliation></ce:affiliation><ce:affiliation id="aff0002"><ce:label>b</ce:label><ce:textfn id="cetextfn0002">College of Informatics, Academic Institute, Shizuoka University, 3-5-1 Johoku, Naka-ku, Hamamatsu, Shizuoka 432-8011, Japan</ce:textfn><sa:affiliation><sa:organization>College of Informatics</sa:organization><sa:organization>Academic Institute</sa:organization><sa:organization>Shizuoka University</sa:organization><sa:address-line>3-5-1 Johoku, Naka-ku</sa:address-line><sa:city>Hamamatsu</sa:city><sa:state>Shizuoka</sa:state><sa:postal-code>432-8011</sa:postal-code><sa:country>Japan</sa:country></sa:affiliation></ce:affiliation><ce:affiliation id="aff0003"><ce:label>c</ce:label><ce:textfn id="cetextfn0003">JST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama, 332-0012, Japan</ce:textfn><sa:affiliation><sa:organization>JST</sa:organization><sa:organization>PRESTO</sa:organization><sa:address-line>4-1-8 Honcho</sa:address-line><sa:city>Kawaguchi</sa:city><sa:state>Saitama</sa:state><sa:postal-code>332-0012</sa:postal-code><sa:country>Japan</sa:country></sa:affiliation></ce:affiliation><ce:correspondence id="cor0001"><ce:label>*</ce:label><ce:text id="cetext0001">Corresponding author.</ce:text></ce:correspondence></ce:author-group><ce:date-received day="4" month="2" year="2016"/><ce:date-revised day="29" month="3" year="2016"/><ce:date-accepted day="13" month="4" year="2016"/><ce:abstract id="abs0001" class="author-highlights" view="all"><ce:section-title id="cesectitle0001">Highlights</ce:section-title><ce:abstract-sec id="abss0001" view="all"><ce:simple-para id="spara0001" view="all"><ce:list id="celist0001"><ce:list-item id="celistitem0001"><ce:label>•</ce:label><ce:para id="para0001" view="all">A new methodology for predicting micrometeorological data is proposed.</ce:para></ce:list-item><ce:list-item id="celistitem0002"><ce:label>•</ce:label><ce:para id="para0002" view="all">Our proposed method involves a novel combination of SVR and ensemble learning.</ce:para></ce:list-item><ce:list-item id="celistitem0003"><ce:label>•</ce:label><ce:para id="para0003" view="all">Weak learners built from efficient extracted data is aggregated dynamically.</ce:para></ce:list-item><ce:list-item id="celistitem0004"><ce:label>•</ce:label><ce:para id="para0004" view="all">Large-scale micrometeorological data to compare other methods is used.</ce:para></ce:list-item><ce:list-item id="celistitem0005"><ce:label>•</ce:label><ce:para id="para0005" view="all">The best prediction performance and the lowest time complexity are achieved.</ce:para></ce:list-item></ce:list></ce:simple-para></ce:abstract-sec></ce:abstract><ce:abstract id="abs0002" view="all" class="author"><ce:section-title id="cesectitle0002">Abstract</ce:section-title><ce:abstract-sec id="abss0002" view="all"><ce:simple-para id="spara0007" view="all">Sensor network technology is becoming more widespread and sophisticated, and devices with many sensors, such as smartphones and sensor nodes, have been used extensively. Since these devices have more easily accumulated various kinds of micrometeorological data, such as temperature, humidity, and wind speed, an enormous amount of micrometeorological data has been accumulated. In recent years, it has been expected that such an enormous amount of data, called big data, will produce novel knowledge and value. Accordingly, many current applications have used data mining technology or machine learning to exploit big data. However, micrometeorological data has a complicated correlation among different features, and its characteristics change variously with time. Therefore, it is difficult to predict micrometeorological data accurately with low computational complexity even if state-of-the-art machine learning algorithms are used. In this paper, we propose a new methodology for predicting micrometeorological data, sliding window-based support vector regression (SW-SVR) that involves a novel combination of support vector regression (SVR) and ensemble learning. To represent complicated micrometeorological data easily, SW-SVR builds several SVRs specialized for each representative data group in various natural environments, such as different seasons and climates, and changes weights to aggregate the SVRs dynamically depending on the characteristics of test data. In our experiment, we predicted the temperature after 1<ce:hsp sp="0.2"/>h and 6 h by using large-scale micrometeorological data in Tokyo. As a result, regardless of testing periods, training periods, and prediction horizons, the prediction performance of SW-SVR was always greater than or equal to other general methods such as SVR, random forest, and gradient boosting. At the same time, SW-SVR reduced the building time remarkably compared with those of complicated models that have high prediction performance.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="keys0001" view="all" class="keyword"><ce:section-title id="cesectitle0003">Keywords</ce:section-title><ce:keyword id="key0001"><ce:text id="cetext0002">Predicting micrometeorological data</ce:text></ce:keyword><ce:keyword id="key0002"><ce:text id="cetext0003">Data extraction</ce:text></ce:keyword><ce:keyword id="key0003"><ce:text id="cetext0004">Dynamic aggregation</ce:text></ce:keyword><ce:keyword id="key0004"><ce:text id="cetext0005">Support vector regression</ce:text></ce:keyword><ce:keyword id="key0005"><ce:text id="cetext0006">Ensemble learning</ce:text></ce:keyword></ce:keywords></head><body view="all"><ce:sections><ce:section id="sec0001" role="introduction" view="all"><ce:label>1</ce:label><ce:section-title id="cesectitle0004">Introduction</ce:section-title><ce:para id="para0006" view="all">Sensor network technology is becoming more widespread and sophisticated, and devices with many sensors have been used extensively. The devices can very easily obtain various kinds of micrometeorological data such as temperature, humidity, and wind speed. Micrometeorological data is affected strongly by the surface of the earth and is related to our lives and industrial activity. Accordingly, the data has been used by many applications such as environmental control systems for greenhouses (<ce:cross-refs id="crf0005" refid="bib0017 bib0018">Othman &amp; Shazali, 2012; Park &amp; Park, 2011</ce:cross-refs>). Moreover, more advanced applications exploit the data to a greater extent by using machine learning and data mining technology. Furthermore, an enormous amount of micrometeorological data has been accumulated by many devices, and it has been expected that analyzing such an enormous amount of data, called big data, will produce novel knowledge and value.</ce:para><ce:para id="para0007" view="all">To predict micrometeorological data effectively, a number of researchers have studied machine learning (<ce:cross-ref id="crf0007" refid="bib0023">Smith, Hoogenboom, &amp; McClendon, 2009</ce:cross-ref>). These researchers described prediction methods for micrometeorological data; particularly, prediction performance and computational complexity were often mentioned. Meanwhile, micrometeorological data has a complex correlation among different features such as temperature and humidity. Moreover, its characteristics change variously with time. Therefore, even if big data is given as training data, it is not easy to predict micrometeorological data accurately. Furthermore, in many cases, so that models can have high prediction performance, they have to become complicated, and the computational complexity increases. Accordingly, some models probably cannot be built from big data in a practical amount of computing time. In other words, there is a trade-off relationship between high prediction performance and low computational complexity. However, compatibility is required in some practical use. As the prediction performance in applications becomes higher, the quality provided by the applications becomes better. For example, in the case of environmental control systems based on prediction (<ce:cross-ref id="crf0008" refid="bib0012">Kolokotsa, Pouliezos, Stavrakakis, &amp; Lazos, 2009</ce:cross-ref>), the higher prediction performance enables the systems to provide precise control, precise management, and better environments. On the other hand, models that need a long time for training are worthless in practical use. In current situations where the amount of usable data has increased remarkably, this trade-off relationship has become a more critical issue.</ce:para><ce:para id="para0008" view="all">Recently, one type of machine learning algorithm, support vector machines (SVMs), have been used successfully in various fields. The basic theory is a more efficient learning method based on probably approximately correct (PAC) learning. Moreover, SVMs can separate non-linear data with low computational complexity. Since most data observed in the real world is likely to have non-linear relationships, SVMs have also been applied to micrometeorological data prediction (<ce:cross-refs id="crf0009" refid="bib0001 bib0016 bib0028">Antonanzas, Urraca, Martinez-de-Pison, &amp; Antonanzas-Torres, 2015; Mohammadi, Shamshirband, Anisi, Alam, &amp; Petković, 2015; Urraca, Antonanzas, Martinez-de-Pison, &amp; Antonanzas-Torres, 2015</ce:cross-refs>). Moreover, SVMs led to better prediction performance than other algorithms such as artificial neural networks (ANNs) and the autoregressive integrated moving average (ARIMA) model (<ce:cross-refs id="crf0012" refid="bib0005 bib0015">Chevalier, Hoogenboom, McClendon, &amp; Paz, 2011; Maity, Bhagwat, &amp; Bhatnagar, 2010</ce:cross-refs>). However, when SVMs learn big data, the computational complexity is still a matter of concern. Another alternative learning method, ensemble learning, has also been used more widely for predicting micrometeorological data (<ce:cross-ref id="crf0014" refid="bib0022">Singh, Gupta, &amp; Rai, 2013</ce:cross-ref>). The prediction performance of ensemble learning is greater than or equal to that of SVMs. The basic methodology is a combination of weak learners built from different kinds of training data. The combination yields a higher generalizing capability that a single model cannot represent. In particular, some researchers proposed improved methods that could be applied to micrometeorological data prediction (<ce:cross-refs id="crf0015" refid="bib0030 bib0031">Wang &amp; Japkowicz, 2009; Xie, Li, Ngai, &amp; Ying, 2009</ce:cross-refs>). However, it is difficult to apply the methods to regression, and it is possible that the models will not be able to follow micrometeorological data whose characteristics always change with time.</ce:para><ce:para id="para0009" view="all">In this paper, we propose a new methodology for predicting micrometeorological data, sliding window-based support vector regression (SW-SVR). SW-SVR involves a novel combination of support vector regression (SVR) and ensemble learning. To represent complicated micrometeorological data easily, SW-SVR builds several SVRs specialized for each representative data group in various natural environments, such as different seasons and climates. The specialized SVRs are built based on our previous proposed method, dynamic short-distance data collection (D-SDC) that extracts effective data for specific data prediction by taking account of movements: changes in data during prediction horizons. Each weak learner built from each extracted data specializes on specific data and predicts accurately the data similar to the specialized data. Then, SW-SVR aggregates all the predicted values based on weights decided by the similarity between test data and each data specialized by weak learners. This new ensemble learning methodology that changes weights dynamically enables following micrometeorological data whose characteristics hardly change with time. Our results demonstrated that the prediction performance of SW-SVR was always greater than or equal to that of other general methods such as SVR, random forest, and gradient boosting. At the same time, SW-SVR reduced the building time remarkably compared with that of complicated models that have high prediction performance.</ce:para></ce:section><ce:section id="sec0002" view="all"><ce:label>2</ce:label><ce:section-title id="cesectitle0005">Related work</ce:section-title><ce:para id="para0010" view="all">As mentioned in the introduction, to predict micrometeorological data effectively, SVMs and ensemble learning have generally been used. These algorithms have higher prediction performance for micrometeorological data than traditional methods because SVMs use not only a margin maximizing algorithm whose great performance was proved by PAC learning but also the kernel trick that enables non-linear separation. On the other hand, ensemble learning provides higher generalizing capability that a single model cannot represent. In this section, a brief summary of these algorithms and some improved algorithms are given. Moreover, so that SW-SVR can draw advantages from both SVMs and ensemble learning, several problems of these algorithms for practical use are discussed.</ce:para><ce:section id="sec0003" view="all"><ce:label>2.1</ce:label><ce:section-title id="cesectitle0006">Support vector regression</ce:section-title><ce:para id="para0011" view="all">SVMs, introduced by <ce:cross-ref id="crf0017" refid="bib0029">Vapnik,(1995</ce:cross-ref>), have been used successfully in various fields. In the simplest case, binary classification, SVMs obtain a separating hyperplane decided by maximizing the margin. The margin means the norms between different classes. PAC learning proved that maximizing the margin produces high generalization ability. Moreover, the kernel trick enables SVMs to separate data non-linearly with low computational complexity. Various kinds of data observed in the real world are likely to have non-linear relationships. Accordingly, SVMs are used in many applications such as micrometeorological data prediction (<ce:cross-refs id="crf0018" refid="bib0011 bib0015">Kisi &amp; Cimen, 2012; Maity et al., 2010</ce:cross-refs>). Meanwhile, SVMs for regression, support vector regression (SVR), uses the same methodology as SVMs that have the highest generalization ability. In this section, a brief summary of SVR is given as follows.</ce:para><ce:para id="para0012" view="all">First, the linear function for regression is given as follows:
<ce:display><ce:formula id="eqn0001"><mml:math altimg="si18.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0013" view="all">Then, as with SVMs, SVR also minimizes the norm of the weight vector <ce:bold>w</ce:bold>; the L<ce:sup loc="post">2</ce:sup> norm ‖<ce:bold>w</ce:bold>‖<ce:sup loc="post">2</ce:sup> is often used, and minimizing ‖<ce:bold>w</ce:bold>‖<ce:sup loc="post">2</ce:sup> corresponds to maximizing the margin. Meanwhile, SVR tolerates prediction error<mml:math altimg="si19.gif" overflow="scroll"><mml:mrow><mml:mspace width="0.33em"/><mml:mi>ϵ</mml:mi></mml:mrow></mml:math>. Therefore, the primal problem of SVR is shown as follows:
<ce:display><ce:formula id="eqn0002"><mml:math altimg="si20.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>minimize</mml:mi><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>subject</mml:mi><mml:mspace width="0.16em"/><mml:mrow><mml:mi>to</mml:mi><mml:mspace width="0.33em"/></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0014" view="all">Moreover, to take some errors into account further, the same slack variables <ce:italic>ξ</ce:italic> as soft margin SVMs are introduced. The slack variables mean penalties and increase in proportion to errors between true values and predicted values. The problem that the slack variables are introduced into is shown as follows:
<ce:display><ce:formula id="eqn0003"><mml:math altimg="si21.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>minimize</mml:mi><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>subject</mml:mi><mml:mspace width="0.16em"/><mml:mi>to</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where the constant <ce:italic>C</ce:italic> means the balance between the effect of maximizing the margin and penalties. To minimize the above formula, the slack variables in the formula must also be minimized. Accordingly, the slack variables depending on the errors are shown as follows:
<ce:display><ce:formula id="eqn0004"><mml:math altimg="si22.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>otherwise</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>otherwise</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0015" view="all">The above formulas mean that a penalty is not given when the error is lower than<mml:math altimg="si19.gif" overflow="scroll"><mml:mrow><mml:mspace width="0.33em"/><mml:mi>ϵ</mml:mi></mml:mrow></mml:math>, but the error is regarded as a penalty that cannot be tolerated when the error is higher than<mml:math altimg="si19.gif" overflow="scroll"><mml:mrow><mml:mspace width="0.33em"/><mml:mi>ϵ</mml:mi></mml:mrow></mml:math>. In other words, SVR tolerates errors less than<mml:math altimg="si19.gif" overflow="scroll"><mml:mrow><mml:mspace width="0.33em"/><mml:mi>ϵ</mml:mi></mml:mrow></mml:math>, but errors over <mml:math altimg="si19.gif" overflow="scroll"><mml:mi>ϵ</mml:mi></mml:math> are solely taken into account as penalties. Finally, the dual problem is derived from the above primal problem by Lagrange multiplier and corresponds to a quadratic programming problem as with SVMs. As a result, since a unique global optimal solution is solved, SVR is superior to traditional algorithms that might fall into a local optimal solution, such as ANNs. The dual problem derived by Lagrange multiplier is shown as follows:
<ce:display><ce:formula id="eqn0005"><mml:math altimg="si23.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>maximize</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:mspace width="0.33em"/><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>subject</mml:mi><mml:mspace width="0.16em"/><mml:mi>to</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0016" view="all">Moreover, the above dual problem can easily involve non-linear map φ to consider a higher dimension. To introduce non-linear map φ in the above problem, kernel function <mml:math altimg="si24.gif" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">K</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is defined and used instead of<mml:math altimg="si25.gif" overflow="scroll"><mml:mrow><mml:mspace width="0.33em"/><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi mathvariant="normal">T</mml:mi></mml:msubsup><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math>. Then <ce:italic>φ</ce:italic><ce:sup loc="post"><ce:italic>t</ce:italic></ce:sup>(x<ce:inf loc="post"><ce:italic>i</ce:italic></ce:inf>)<ce:italic>φ</ce:italic>(x<ce:inf loc="post"><ce:italic>j</ce:italic></ce:inf>) is determined based on K(x<ce:inf loc="post"><ce:italic>i</ce:italic></ce:inf>,  x<ce:inf loc="post"><ce:italic>j</ce:italic></ce:inf>) without calculation on a mapped higher dimension; this method is called the kernel trick. SVR based on maximizing the margin and the kernel trick yields high prediction performance.</ce:para><ce:para id="para0017" view="all">Meanwhile, conventional quadratic programming solvers, such as the steepest descent method, have very high computational complexity; the computational complexity is approximately <ce:italic>O</ce:italic>(<ce:italic>N<ce:sup loc="post">3</ce:sup></ce:italic>) where <ce:italic>N</ce:italic> is the number of training data. Accordingly, a quadratic programming solver for SVMs, sequential minimal optimization (SMO), has become de facto standard (<ce:cross-ref id="crf0020" refid="bib0020">Platt, 1998</ce:cross-ref>). SMO specialized for SVM reduce the computational complexity of SVM to approximately <ce:italic>O</ce:italic>(<ce:italic>N<ce:sup loc="post">2</ce:sup></ce:italic>). Nevertheless, when an enormous amount of data is inputted as training data, the computational complexity increases substantially. To solve the problem, a theory that regards the quadratic programming problem as a computational geometry problem, core vector machine (CVM), was proposed (<ce:cross-ref id="crf0021" refid="bib0027">Tsang, Kwok, &amp; Cheung, 2005</ce:cross-ref>). The prediction performance of CVM is comparable to that of SVMs, and the computational complexity decreases substantially. However, according to a paper (<ce:cross-ref id="crf0022" refid="bib0013">Loosli, 2007</ce:cross-ref>), prediction performance and computational complexity of CVM strongly depend on the values of parameters. Therefore, when essential parameter tuning for practical use is taken into account, CVM does not always satisfy both high prediction performance and low computational complexity.</ce:para><ce:para id="para0018" view="all">SVR is one of the best algorithms in machine learning from the viewpoint of prediction performance. In particular, it has been expected that the kernel trick used in the dual problem is effective for predicting micrometeorological data that has a complex correlation among different features. However, the computational complexity to solve the dual problem is often still long for practical use. Thus, it is difficult to apply conventional SVR directly to micrometeorological data prediction.</ce:para></ce:section><ce:section id="sec0004" view="all"><ce:label>2.2</ce:label><ce:section-title id="cesectitle0007">Ensemble learning</ce:section-title><ce:para id="para0019" view="all">Ensemble learning has been studied recently and used increasingly. The basic methodology of ensemble learning is a combination of weak learners built from different kinds of training data. The combination yields a higher generalizing capability that a single model cannot represent. As with SVMs, ensemble learning can represent non-linear relationships and has been used for predicting micrometeorological data. In particular, the two kinds of approaches, bagging and boosting, have often been used in ensemble learning. The approaches differ greatly on the method to build weak learners and aggregate them.</ce:para><ce:para id="para0020" view="all">Bagging uses several training data generated by bootstrap sampling. The algorithm of basic bagging for regression is shown in <ce:cross-ref id="crf0023" refid="tbl0002">Algorithm. 1</ce:cross-ref><ce:float-anchor refid="tbl0002"/>. In bagging, different kinds of training data are created by sampling inputted original training data with replacement. Then, weak learners are built from each sampled training data. Finally, each predicted value is aggregated by majority vote or arithmetic average. In particular, random forest, introduced by Breiman (<ce:cross-ref id="crf0024" refid="bib0002">Breiman, 2001</ce:cross-ref>), to which randomness in feature selection is also applied, often demonstrates better prediction performance than conventional models such as SVMs. Random forest is used in various applications and has been extended to other improved versions. For example, to predict imbalanced data observed frequently in the real world more accurately, improved balanced random forest (IBRF) has been proposed (<ce:cross-ref id="crf0025" refid="bib0031">Xie et al., 2009</ce:cross-ref>). IBRF involves an efficient sampling method for imbalanced data and cost-sensitive learning that penalizes misclassification of minority class more strongly. The authors showed that IBRF was more effective to predict imbalanced data than class-weighted SVMs and conventional improved random forest for imbalanced data prediction.</ce:para><ce:para id="para0021" view="all">Boosting builds repeatedly weak learners by using weights based on the error rate. The algorithm of basic boosting for regression such as Adaboost (<ce:cross-ref id="crf0026" refid="bib0007">Freund &amp; Schapire, 1997</ce:cross-ref>) is shown in <ce:cross-ref id="crf0027" refid="tbl0003">Algorithm. 2</ce:cross-ref><ce:float-anchor refid="tbl0003"/>. Unlike bagging, almost all boosting algorithms use the same training data, but the training data is weighted repeatedly. Boosting alternates between building weak learners by using weights and updating weights. Finally, each predicted value is aggregated by weighted average. Various kinds of algorithms in boosting have been studied and proposed; gradient boosting (<ce:cross-ref id="crf0028" refid="bib0008">Friedman, 2001</ce:cross-ref>) in particular has shown the best prediction performance in many competitions. Meanwhile, as with IBRF, the boosting algorithm for imbalanced data, boosting-SVM, has also been proposed (<ce:cross-ref id="crf0029" refid="bib0030">Wang &amp; Japkowicz, 2009</ce:cross-ref>). The main characteristic of boosting-SVM is using asymmetric misclassification cost. The authors demonstrated that boosting-SVM enabled more accurate prediction of both the majority class and minority class.</ce:para><ce:para id="para0022" view="all">When micrometeorological data including many unusual natural environments is regarded as imbalanced data, the above methods are likely to classify micrometeorological data more accurately. However, these approaches cannot be applied to regression. Moreover, according to our previous research (<ce:cross-ref id="crf0030" refid="bib0025">Suzuki, Kaneda, &amp; Mineno, 2015</ce:cross-ref>), there is proper training data depending on test data. In other words, weights to aggregate weak learners built from different kinds of training data should depend on test data.</ce:para></ce:section></ce:section><ce:section id="sec0005" view="all"><ce:label>3</ce:label><ce:section-title id="cesectitle0008">SW-SVR: Sliding window-based support vector regression</ce:section-title><ce:para id="para0023" view="all">We propose a new methodology for predicting micrometeorological data, sliding window-based support vector regression, combining methodologies of SVR and ensemble learning. The basic theories are based on D-SDC, our previous proposed method to extract effective data for specific data prediction, and novel weighted ensemble learning as shown in <ce:cross-ref id="crf0031" refid="fig0001">Fig. 1</ce:cross-ref><ce:float-anchor refid="fig0001"/>. First, to represent complicated micrometeorological data easily, SW-SVR builds several SVRs specialized for each representative data group in various natural environments, such as different seasons and climates. The specialized SVRs are built based on D-SDC that extracts effective data for specific data prediction by taking account of movements: changes of data during prediction horizons (<ce:cross-ref id="crf0032" refid="fig0001">Fig. 1</ce:cross-ref>(a)). Each weak learner built from each extracted data specializes on specific data and accurately predicts the data similar to the specialized data. Afterward, each weak learner is aggregated with weights determined dynamically at the time of prediction so as to maintain the prediction performance of micrometeorological data whose characteristics always change with time (<ce:cross-ref id="crf0033" refid="fig0001">Fig. 1</ce:cross-ref>(b)). The weights are decided by the similarity between test data and each data specialized by weak learners. Even if the characteristics of micrometeorological data always change with time, SW-SVR always gives priority to weak learners that are more suitable for predicting test data. The details of the SW-SVR algorithm are shown in <ce:cross-ref id="crf0034" refid="tbl0004">Algorithm. 3</ce:cross-ref><ce:float-anchor refid="tbl0004"/>. The procedure for training consists of two kinds of preprocessing, iterated learning, and dynamic aggregation. The procedures of each part are shown as follows.</ce:para><ce:para id="para0024" view="all">The below-mentioned algorithms in SW-SVR use the L<ce:sup loc="post">2</ce:sup> norm: the Euclid distance, and the performance is related to feature space. For example, if feature space includes noisy features or non-linear relationships between features, the performance will probably be reduced substantially. In particular, micrometeorological data has a complex correlation among different features such as temperature and humidity. Accordingly, feature space must be mapped into other feature space that takes into account the presence of noise and non-linear relationships. In our approach, we use kernel approximation (<ce:cross-ref id="crf0035" refid="bib0021">Rahimi &amp; Recht, 2007</ce:cross-ref>) and partial least squares (PLS) regression (<ce:cross-ref id="crf0036" refid="bib0026">Tenenhaus, Vinzi, Chatelin, &amp; Lauro, 2005</ce:cross-ref>) to map into new feature space. Kernel approximation generates new feature space and involves higher dimensions that represent non-linear data as linear data with a very low computational complexity. Actually, a combination of kernel approximation and linear SVMs led to faster prediction performance that is comparable to that of exact SVM (<ce:cross-ref id="crf0037" refid="bib0003">Cao, Naito, &amp; Ninomiya, 2008</ce:cross-ref>). On the other hand, PLS regression is a supervised dimension reduction methodology. This method can reduce dimensions by extracting latent variables that have a strong relationship with a dependent variable. If feature space includes noisy features, the effect is reduced because of PLS regression. The combination of kernel approximation and PLS regression enables SW-SVR to use effective feature space for calculation of the L<ce:sup loc="post">2</ce:sup> norm in micrometeorological data.</ce:para><ce:para id="para0025" view="all">According to our previous research, to accurately predict particular specific data in micrometeorological data, it is necessary to extract effective training data for specific data prediction (<ce:cross-ref id="crf0038" refid="bib0025">Suzuki et al., 2015</ce:cross-ref>). In SW-SVR, these several specific data is selected in advance, and weak learners are built from extracted effective training data for predicting each specific data. Meanwhile, micrometeorological data involves various natural environments such as different seasons and climates. Therefore, each selected specific data must represent more varied natural environments that probably will appear so as to represent micrometeorological data by several models. In SW-SVR, each specific data is selected by a clustering algorithm, k-means (<ce:cross-ref id="crf0039" refid="bib0014">Macqueen, 1967</ce:cross-ref>). The k-means is one of the most famous non-hierarchical clustering algorithms and classifies data faster under several clusters than other clustering algorithms. In SW-SVR, the k-means classifies all training data into the same number of clusters as the number of weak learners given by users. Then, each center of clusters is used as specific data that represents various natural environments.</ce:para><ce:para id="para0026" view="all">After selecting several specific data, SW-SVR iterates data extraction and building a model. First, SW-SVR extracts effective training data for predicting each specific data by D-SDC (<ce:cross-ref id="crf0040" refid="bib0024">Suzuki, Kaneda, &amp; Mineno, 2014</ce:cross-ref>). The theory of D-SDC is similar to that of the k-nearest neighbor (k-NN) algorithm, and D-SDC also extracts some training data similar to a specialized object. However, in our D-SDC, the amount of extracted data depends on the movement of a specialized object with time. The movement <ce:italic>r</ce:italic> means the change of a specialized object during prediction horizons as shown in the following equation:
<ce:display><ce:formula id="eqn0006"><mml:math altimg="si26.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:mo>∥</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:bold><ce:italic>G</ce:italic></ce:bold> is a specialized object, and <ce:bold><ce:italic>G′</ce:italic></ce:bold> is a specialized object after prediction horizons. D-SDC extracts training data whose norm from a specialized object is shorter than the movement <ce:italic>r</ce:italic>. Accordingly, extracted training data <ce:italic>S</ce:italic> by D-SDC is given as follows:
<ce:display><ce:formula id="eqn0007"><mml:math altimg="si27.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mphantom><mml:mrow><mml:mn>0.33</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:mo>∥</mml:mo><mml:mo>&lt;</mml:mo><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:mo>∥</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:bold>x</ce:bold> is the feature of training data and <ce:italic>y</ce:italic> is the dependent variable of training data. D-SDC is based on the movement <ce:italic>r</ce:italic> because the movement <ce:italic>r</ce:italic> is strongly related to autocorrelation of data surrounding a specialized object. In micrometeorological data, movements in specific natural environments are mutually similar, and the autocorrelation becomes lower when these movements are bigger. For example, in Japan, the change of weather is drastic every spring, and the natural environments change various other natural environments with time. Meanwhile, when we predict time series data such as micrometeorological data, autocorrelation means correlation between features and a dependent variable, and more training data is required for highly accurate prediction when autocorrelation is lower. Since D-SDC extracts the amount of data surrounding a specialized object in proportion to the movement <ce:italic>r</ce:italic>, extraction that considers autocorrelation of data surrounding a specialized object is achieved. However, the movement <ce:italic>r</ce:italic> is unknown because <ce:bold><ce:italic>G′ </ce:italic></ce:bold>is not observed. Meanwhile, as mentioned above, movements of data surrounding a specialized object are mutually similar. Therefore, D-SDC estimates the movement <ce:italic>r</ce:italic> based on movements of training data similar to a specialized object by weighted average, where the weights are reciprocals of norms between a specialized object and each training data. Movements of training data can be calculated by referring to the time when each training data is observed. The estimated movement <ce:italic>r</ce:italic> is given as follows:
<ce:display><ce:formula id="eqn0008"><mml:math altimg="si28.gif" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:mo>∥</mml:mo><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">where</mml:mi></mml:mrow><mml:mphantom><mml:mrow><mml:mn>0.16</mml:mn><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mphantom><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>∥</mml:mo><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="-0.16em"/><mml:mspace width="-0.16em"/><mml:msup><mml:mo>∥</mml:mo><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0027" view="all"><ce:italic>N</ce:italic> is the number of training data, and <ce:italic>p</ce:italic> is a weighted parameter. Afterward, SW-SVR builds several linear SVRs as weak learners based on the extracted data. As described above, a combination of linear SVR and kernel approximation is comparable to SVR using a kernel method. Moreover, linear SVR can be built much faster by using liblinear (<ce:cross-ref id="crf0041" refid="bib0006">Fan, Chang, Hsieh, Wang, &amp; Lin, 2008</ce:cross-ref>), an optimized implementation for linear SVMs, instead of other general implementations of SVMs such as libSVM (<ce:cross-ref id="crf0042" refid="bib0004">Chang &amp; Lin, 2011</ce:cross-ref>). Although a usable kernel in liblinear is restricted to the linear kernel, liblinear can build the model much faster by solving the primal problem instead of the dual problem. Furthermore, since all training data is divided into smaller amounts of extracted data, each model can be built faster, and it is easier to learn each extracted data by parallel processing.</ce:para><ce:para id="para0028" view="all">The predicted values of SW-SVR take into account the change of natural environments with time. In general ensemble learning, prediction for regression depends on the weighted average, and the weights are determined at the time of training. However, SW-SVR determines weights dynamically at the time of prediction. The weights are determined by the norm between test data and each data specialized by weak learners. A final hypothesis of SW-SVR is shown as follows:
<ce:display><ce:formula id="eqn0009"><mml:math altimg="si29.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="0.33em"/><mml:mi>where</mml:mi><mml:mspace width="0.16em"/><mml:msub><mml:mi>w</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow><mml:mi>q</mml:mi></mml:msup></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="para0029" view="all">
<ce:bold><ce:italic>P</ce:italic></ce:bold> is the test data, <ce:italic>n</ce:italic> is the number of weak learners, <ce:italic>H</ce:italic>(<ce:italic>X</ce:italic>) is a hypothesis, and <ce:italic>q</ce:italic> is a weighted parameter. In our approach, since the weights of ensemble learning are determined dynamically for every prediction, SW-SVR can follow micrometeorological data whose characteristics always change with time.</ce:para><ce:para id="para0030" view="all">Finally, we describe the computational complexity of SW-SVR. To represent complicated micrometeorological data easily, SW-SVR uses the various conventional methods besides D-SDC we proposed: kernel approximation, PLS regression, k-means, and linear SVR. The computational complexity of these methods in general increases linearly; in other words, the computational complexity is approximately equal to <ce:italic>O</ce:italic>(<ce:italic>N</ce:italic>) where the number of training data <ce:italic>N</ce:italic> is even bigger than the number of the dimensions and each parameter of these methods. Moreover, the computational complexity of D-SDC corresponds to <ce:italic>O</ce:italic>(<ce:italic>nN</ce:italic>) because D-SDC just iterates <ce:italic>N</ce:italic> times of distance calculation <ce:italic>n</ce:italic><ce:hsp sp="0.12"/>+<ce:hsp sp="0.12"/>1 times where <ce:italic>n</ce:italic> is the number of weak learners in SW-SVR. Therefore, if <ce:italic>N</ce:italic> is even bigger than <ce:italic>n</ce:italic>, the computational complexity of D-SDC also increases linearly. The total computational complexity of SW-SVR is approximately equal to <ce:italic>O</ce:italic>(<ce:italic>N</ce:italic>) that is even less than that of SVR.</ce:para></ce:section><ce:section id="sec0006" view="all"><ce:label>4</ce:label><ce:section-title id="cesectitle0009">Evaluation</ce:section-title><ce:section id="sec0007" view="all"><ce:label>4.1</ce:label><ce:section-title id="cesectitle0010">Experiment</ce:section-title><ce:para id="para0031" view="all">We compared the performance of SW-SVR with other standard methods for regression: k-NN, decision tree (DT), Adaboost, bagging, random forest (RF), gradient boosting (GB), linear SVR, and SVR using a radial basis function (RBF) kernel that shows higher performance in various fields (RBF-SVR). Note that the kernel of kernel approximation in SW-SVR is also the RBF kernel, and the base learner in Adaboost and bagging is the decision tree that has been used generally. Moreover, to evaluate SW-SVR in more detail, we evaluated the performance of linear SVR with mapping: standard linear SVR to which the same mapping as SW-SVR is applied (“mapped SVR”). Mapped SVR clarifies each performance of mapping feature space and ensemble learning based on D-SDC. All parameters of the used models were adjusted by the grid search method. Baseline for this evaluation was the performance of the naivest persistent model as shown in the following formula:
<ce:display><ce:formula id="eqn0010"><mml:math altimg="si30.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>Δ</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <mml:math altimg="si31.gif" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math> is the predicted value, <ce:italic>y</ce:italic> is the true value, and <ce:italic>Δ</ce:italic>t is the prediction horizons.</ce:para><ce:para id="para0032" view="all">We evaluated the performance by two ways: hold-out validation and 10-fold cross-validation. We predicted the temperature after 1<ce:hsp sp="0.2"/>h and 6 h by using large-scale micrometeorological data in Tokyo (<ce:cross-ref id="crf0043" refid="bib0010">Japan Meteorological Agency, n.d.</ce:cross-ref>). The data consists of atmospheric pressure, temperature, relative humidity, wind speed, and irradiance. In hold-out validation, training periods are limited to the earlier periods than testing periods so as to assume practical use; test data is always predicted based on past training data in practical use. The training periods were from 3 months to 5 years before September 1, 2014, and testing periods were from 1 month to 1 year later the same day. By varying the training periods and the testing periods, the performance under the various usage scenarios is evaluated. On the other hand, the periods for 10-fold cross-validation were 6 years from September 1, 2009 to September 1, 2015. Note that the amount of data per month was approximately 4000 because the data was accumulated every 10 minutes. In this evaluation, we used the mean absolute percentage error (MAPE) as the index of prediction error and building time calculated based on the CPU clock time as the index of computational complexity. MAPE is shown as follows:
<ce:display><ce:formula id="eqn0011"><mml:math altimg="si32.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mspace width="0.33em"/><mml:mfrac><mml:mn>100</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mspace width="0.33em"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>N</ce:italic> is the number of test data, <ce:italic>y</ce:italic> is the true value, and <mml:math altimg="si31.gif" overflow="scroll"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math> is the predicted value. Moreover, we evaluated the average of each extraction rate by D-SDC in each experimental condition so as to analyze the performance of SW-SVR and D-SDC further. All implementations for this evaluation are in Python, and implementations in scikit-learn (<ce:cross-ref id="crf0044" refid="bib0019">Pedregosa et al., 2012</ce:cross-ref>) were used for all methods except SW-SVR. This evaluation was performed on a single core of a machine with an Intel Core i5-2500<ce:hsp sp="0.2"/>K Processor and 12GB of RAM; even though several methods, such random forest and SW-SVR, can be performed on parallel processing, the methods were performed on a single core so as to evaluate the building time of all methods fairly.</ce:para></ce:section><ce:section id="sec0008" role="results" view="all"><ce:label>4.2</ce:label><ce:section-title id="cesectitle0011">Results and discussion</ce:section-title><ce:para id="para0033" view="all">
<ce:cross-ref id="crf0045" refid="fig0002">Fig. 2</ce:cross-ref><ce:float-anchor refid="fig0002"/> and <ce:cross-ref id="crf0046" refid="fig0003">3</ce:cross-ref><ce:float-anchor refid="fig0003"/> show the prediction error in the prediction horizons of 1<ce:hsp sp="0.2"/>h and 6 h, respectively. Note that a log scale is used in <ce:cross-ref id="crf0047" refid="fig0002">Figs. 2</ce:cross-ref>(b), (c), <ce:cross-ref id="crf0048" refid="fig0003">3</ce:cross-ref>(b), and (c). The results indicate that SW-SVR produced the best average performance in all models during the whole testing periods, training periods, and prediction horizons. In particular, the effect occurs noticeably when testing periods are longer than training periods. On the other hand, in this situation, almost all methods except SW-SVR have often lower performance than the naivest persistent model as baseline. The results demonstrate that the conventional superior methods do not always display the great performance for micrometeorological data prediction depending on difficulty of the prediction caused by training periods and testing periods and prediction horizons. Moreover, in algorithms based on SVR, the prediction performance of SW-SVR is almost the best, followed in order by those of RBF-SVR, mapped SVR, and linear SVR. The difference between mapped SVR and linear SVR is due to the effect of mapping feature space. On the other hand, the difference between SW-SVR and mapped SVR is due to the effect of ensemble learning based on D-SDC. These comparisons demonstrated that both mapping feature space and ensemble learning based on D-SDC are effective for improving prediction performance. Meanwhile, mapped SVR also tended to have lower prediction performance than that of SW-SVR when the testing periods are longer than the training periods. Accordingly, under this condition, ensemble learning based on D-SDC is particularly effective. When the testing periods are longer than the training periods, the effective training data for predicting the test data is reduced. We considered that a little training data that D-SDC extracted for building models corresponded to the effective training data for predicting the test data. Actually, <ce:cross-ref id="crf0049" refid="fig0004">Fig. 4</ce:cross-ref><ce:float-anchor refid="fig0004"/> indicates the average of each extraction rate by D-SDC and demonstrates that weak learners of SW-SVR are always built from a very small proportion of the whole training data. SW-SVR that always predicts micrometeorological data accurately regardless of the amount of training data is very practical and useful.</ce:para><ce:para id="para0034" view="all">
<ce:cross-ref id="crf0050" refid="tbl0001">Table 1</ce:cross-ref><ce:float-anchor refid="tbl0001"/> shows the results of 10-fold cross-validation in the prediction horizons of 1<ce:hsp sp="0.2"/>h and 6 h. SW-SVR was often superior to all methods including RBF-SVM in hold-out validation. However, in 10-fold cross-validation, although SW-SVR had higher the prediction performance than that of all methods except RBF-SVR, RBF-SVR was superior to SW-SVR slightly. The results demonstrate that the prediction performance of SW-SVR is affected by temporal order between training data and test data, and SW-SVR is particularly suited to be used for practical use in which test data is always predicted based on past training data. Meanwhile, even in 10-fold cross-validation, the magnitude relation of the prediction error between mapped SVR and linear SVR and SW-SVR was same as the case of hold-out validation. Therefore, both mapping feature space and ensemble learning based on D-SDC are effective for improving prediction performance in cross-validation.</ce:para><ce:para id="para0035" view="all">
<ce:cross-ref id="crf0054" refid="fig0005">Fig. 5</ce:cross-ref><ce:float-anchor refid="fig0005"/> and <ce:cross-ref id="crf0055" refid="fig0006">6</ce:cross-ref><ce:float-anchor refid="fig0006"/> show the building time in the prediction horizons of 1<ce:hsp sp="0.2"/>h and 6 h, respectively. <ce:cross-ref id="crf0056" refid="fig0005">Figs. 5</ce:cross-ref>(a) and <ce:cross-ref id="crf0057" refid="fig0006">6</ce:cross-ref>(a) show the building time of models that have high prediction performance as shown in <ce:cross-ref id="crf0058" refid="fig0002">Figs. 2</ce:cross-ref> and <ce:cross-ref id="crf0059" refid="fig0003">3</ce:cross-ref>, RF, GB, RBF-SVR, and SW-SVR, when training periods were varied. Note that the number of weak learners was 1000 in the ensemble learning series, cost parameter was 1 in the SVR series, and <ce:italic>σ</ce:italic> of SW-SVR was 0.00001; <ce:italic>σ</ce:italic> of SW-SVR was a parameter of the RBF kernel in kernel approximation. These results demonstrated that the building time of ensemble learning, such as SW-SVR, increases more gently than that of SVR. In particular, the building time of SW-SVR is shortest when the training periods become longer. In other words, the rate of building time increase of SW-SVR is the gentlest in all the methods when training data increases. These results indicate that, as mentioned above, the computational complexity of SW-SVR is less than that of conventional methods including random forest and gradient boosting. SW-SVR is effective for training of an enormous amount of data in terms of building time.</ce:para><ce:para id="para0036" view="all">Next, <ce:cross-ref id="crf0060" refid="fig0005">Figs. 5</ce:cross-ref>(b) and <ce:cross-ref id="crf0061" refid="fig0006">6</ce:cross-ref>(b) show the building time of the models with better performance in ensemble learning, RF, GB, and SW-SVR, when the number of weak learners was varied. Note that the cost parameter of SW-SVR was 1, <ce:italic>σ</ce:italic> of SW-SVR was 0.00001, and training periods were 12 months. SW-SVR needs a longer building time than RF and GB using shallow DT when the number of weak learners is lower. However, when the depth of DT becomes deeper or the number of weak learners becomes higher, SW-SVR can build the model faster than or at the same speed as RF and GB. Moreover, SW-SVR, as with RF, can be run easily in parallel environments, and it is expected that the building time of SW-SVR will become even shorter.</ce:para><ce:para id="para0037" view="all">Finally, <ce:cross-ref id="crf0062" refid="fig0005">Figs. 5</ce:cross-ref>(c) and <ce:cross-ref id="crf0063" refid="fig0006">6</ce:cross-ref>(c) show the building time of the models based on SVR when the parameters of SVR were varied. Note that the number of weak learners was 100, and the training periods were 12 months. These results indicate that the building time of SW-SVR is significantly shorter than that of RBF-SVR but longer than linear SVR. Meanwhile, <ce:cross-ref id="crf0064" refid="fig0004">Fig. 4</ce:cross-ref> demonstrates that weak learners of SW-SVR are always built from a very small proportion of the whole training data. In particular, when prediction horizons were 1<ce:hsp sp="0.2"/>h, the average of each extraction rate was 0.47 percent at best and 1.82 percent at worst. On the other hand, when prediction horizons were 6 h, the average of each extraction rate was 7.57 percent at best and 16.25 percent at worst. Nevertheless, the reason the computational complexity of SW-SVR is larger than linear SVR is that the increase of computational complexity due to building several models is larger. However, since the amount of training data of each weak learner reduces substantially, the computational complexity to build one model in SW-SVR reduces also. Accordingly, when the number of models one CPU builds reduces by using parallel processing, the computational complexity of the overall SW-SVR is lower than or equal to that of linear SVR. Meanwhile, as with linear SVR, SW-SVR never depends on the change of parameters related to SVR, and the building time is always a constant. As mentioned in the above discussion, the building time of SW-SVR solely depends on the number of weak learners and training periods. Therefore, SW-SVR can avoid an unexpected long building time in parameter tuning that changes each parameter variously.</ce:para><ce:para id="para0038" view="all">These results demonstrate that SW-SVR predicts complicated micrometeorological data with the best prediction performance and the lowest computational complexity compared with standard algorithms. In particular, we found that dynamic aggregation of models built from very little extracted data by D-SDC is effective for compatibility of high prediction performance and low computational complexity. However, there are problems to be solved in SW-SVR. Firstly, the prediction performance of SW-SVR sometimes deteriorates despite an increase of training data. In particular, this problem occurred under the conditions that prediction horizons are 6 h as shown in <ce:cross-ref id="crf0065" refid="fig0003">Fig. 3</ce:cross-ref>. This is because data extracted by D-SDC involves unnecessary training data for highly accurate prediction. If D-SDC extracts the same data as the extracted data when training periods are shorter, the prediction performance of SW-SVR never deteriorates due to an increase of training data. Therefore, we must review both feature mapping and algorithms of D-SDC so as to avoid extracting unnecessary training data. Meanwhile, SW-SVR is based on a combination of several algorithms: kernel approximation, PLS regression, k-means, D-SDC, and linear SVR. Moreover, each algorithm has several parameters. Therefore, SW-SVR has more varied parameters, and it takes more time to tune the parameters. In this experiment, we used a grid search roughly so as to decide the parameters in a certain time. However, there is still room for improvement in the prediction performance by using other approaches such as a genetic algorithm instead of a grid search (<ce:cross-ref id="crf0066" refid="bib0009">Huang &amp; Wang, 2006</ce:cross-ref>).</ce:para></ce:section></ce:section><ce:section id="sec0009" role="conclusion" view="all"><ce:label>5</ce:label><ce:section-title id="cesectitle0012">Conclusion and future work</ce:section-title><ce:para id="para0039" view="all">In this paper, we proposed a new methodology for predicting micrometeorological data, SW-SVR that involves a novel combination of SVR and ensemble learning. To take the advantages of SVR and ensemble learning, SW-SVR builds several SVRs specialized for each representative data group in various natural environments by using D-SDC that extracts effective training data for specific data prediction. Moreover, to follow micrometeorological data whose characteristics always change with time, prediction of SW-SVR is based on dynamically weighted ensemble learning depending on the similarity between test data and each data specialized by weak learners. As a result of evaluation experiments using large-scale micrometeorological data, the prediction performance of SW-SVR is greater than or equal to other general methods such as SVR, RF, and GB. Moreover, SW-SVR reduces the building time substantially compared with complicated models that have high prediction performance. We anticipate that dynamic aggregation of models built from various kinds of extracted data by D-SDC can contribute to more sophisticated studies of micrometeorological data prediction.</ce:para><ce:para id="para0040" view="all">In future work, we should evaluate SW-SVR in more varied situations to show that SW-SVR works effectively. In particular, we will use more complicated data that consists of many features. Furthermore, when SW-SVR is applied to applications such as environmental control systems, the performance of overall applications should be evaluated. Currently, we have developed an agricultural support system using SW-SVR, which controls environments in greenhouses depending on the activity of the plants. The evaluation of the applications will describe the superiority of SW-SVR in practical use.</ce:para></ce:section></ce:sections><ce:acknowledgment id="ack0001" view="all"><ce:section-title id="cesectitle0013">Acknowledgements</ce:section-title><ce:para id="para0041" view="all">This study was partially supported by <ce:grant-sponsor id="gs0001" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">JST</ce:grant-sponsor>, <ce:grant-sponsor id="gs0002" sponsor-id="http://dx.doi.org/10.13039/100005197" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">PRESTO</ce:grant-sponsor>, and <ce:grant-sponsor id="gs0003" xlink:type="simple" xlink:role="http://www.elsevier.com/xml/linking-roles/grant-sponsor">JSPS KAKENHI</ce:grant-sponsor> (<ce:grant-number refid="gs0003" id="gn0001">26660198</ce:grant-number>), Japan.</ce:para></ce:acknowledgment></body><tail view="all"><ce:bibliography id="cebibl1" view="all"><ce:section-title id="cesectitle0014">References</ce:section-title><ce:bibliography-sec id="cebibsec1" view="all"><ce:bib-reference id="bib0001"><ce:label>Antonanzas et al., 2015</ce:label><sb:reference id="sbref0001"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Antonanzas</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Urraca</ce:surname></sb:author><sb:author><ce:given-name>F.J.</ce:given-name><ce:surname>Martinez-de-Pison</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Antonanzas-Torres</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Solar irradiation mapping with exogenous data from support vector regression machines estimations</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Energy Conversion and Management</sb:maintitle></sb:title><sb:volume-nr>100</sb:volume-nr></sb:series><sb:date>2015</sb:date></sb:issue><sb:pages><sb:first-page>380</sb:first-page><sb:last-page>390</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0002"><ce:label>Breiman, 2001</ce:label><sb:reference id="sbref0002"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Breiman</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Random forests</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Machine Learning</sb:maintitle></sb:title><sb:volume-nr>45</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2001</sb:date></sb:issue><sb:pages><sb:first-page>5</sb:first-page><sb:last-page>32</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0001" xlink:href="http://doi.org/10.1023/A:1010933404324" xlink:type="simple">http://doi.org/10.1023/A:1010933404324</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0003"><ce:label>Cao et al., 2008</ce:label><sb:reference id="sbref0003"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Cao</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Naito</ce:surname></sb:author><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Ninomiya</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Approximate RBF kernel SVM and its applications in pedestrian classification</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>The 1st International Workshop on Machine Learning for Visionbased Motion Analysis - MLVMA’08</sb:maintitle></sb:title></sb:series><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>9</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0002" xlink:href="http://hal.archives-ouvertes.fr/inria-00325810/" xlink:type="simple">http://hal.archives-ouvertes.fr/inria-00325810/</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0004"><ce:label>Chang and Lin, 2011</ce:label><sb:reference id="sbref0004"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Chang</ce:surname><ce:given-name>C.</ce:given-name></sb:author><sb:author><ce:surname>Lin</ce:surname><ce:given-name>C.</ce:given-name></sb:author></sb:authors><sb:title><sb:maintitle>LIBSVM : A library for support vector machines</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>ACM Transactions on Intelligent Systems and Technology (TIST)</sb:maintitle></sb:title><sb:volume-nr>2</sb:volume-nr></sb:series><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>39</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0003" xlink:href="http://doi.org/10.1145/1961189.1961199" xlink:type="simple">http://doi.org/10.1145/1961189.1961199</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0005"><ce:label>Chevalier et al., 2011</ce:label><sb:reference id="sbref0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.F.</ce:given-name><ce:surname>Chevalier</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Hoogenboom</ce:surname></sb:author><sb:author><ce:given-name>R.W.</ce:given-name><ce:surname>McClendon</ce:surname></sb:author><sb:author><ce:given-name>J.A.</ce:given-name><ce:surname>Paz</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Support vector regression with reduced training sets for air temperature prediction: A comparison with artificial neural networks</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Neural Computing &amp; Applications</sb:maintitle></sb:title><sb:volume-nr>20</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>151</sb:first-page><sb:last-page>159</sb:last-page></sb:pages></sb:host><sb:comment>Retrieved from &lt;Go to ISI&gt;://WOS:000286674800015</sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0006"><ce:label>Fan et al., 2008</ce:label><sb:reference id="sbref0006"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Fan</ce:surname><ce:given-name>R.-E.</ce:given-name></sb:author><sb:author><ce:surname>Chang</ce:surname><ce:given-name>K.-W.</ce:given-name></sb:author><sb:author><ce:given-name>C.-J.</ce:given-name><ce:surname>Hsieh</ce:surname></sb:author><sb:author><ce:surname>Wang</ce:surname><ce:given-name>X.-R.</ce:given-name></sb:author><sb:author><ce:surname>Lin</ce:surname><ce:given-name>C.-J.</ce:given-name></sb:author></sb:authors><sb:title><sb:maintitle>LIBLINEAR: A library for large linear classification</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>The Journal of Machine Learning</sb:maintitle></sb:title><sb:volume-nr>9</sb:volume-nr></sb:series><sb:issue-nr>2008</sb:issue-nr><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>1871</sb:first-page><sb:last-page>1874</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0004" xlink:href="http://doi.org/10.1038/oby.2011.351" xlink:type="simple">http://doi.org/10.1038/oby.2011.351</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0007"><ce:label>Freund and Schapire, 1997</ce:label><sb:reference id="sbref0007"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Freund</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Schapire</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A desicion-theoretic generalization of on-line learning and an application to boosting</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computational Learning Theory</sb:maintitle></sb:title><sb:volume-nr>55</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>1997</sb:date></sb:issue><sb:pages><sb:first-page>119</sb:first-page><sb:last-page>139</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0005" xlink:href="http://doi.org/10.1006/jcss.1997.1504" xlink:type="simple">http://doi.org/10.1006/jcss.1997.1504</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0008"><ce:label>Friedman, 2001</ce:label><sb:reference id="sbref0008"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.H.</ce:given-name><ce:surname>Friedman</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Greedy function approximation: A gradient boosting machine</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Annals of Statistics</sb:maintitle></sb:title><sb:volume-nr>29</sb:volume-nr></sb:series><sb:issue-nr>5</sb:issue-nr><sb:date>2001</sb:date></sb:issue><sb:pages><sb:first-page>1189</sb:first-page><sb:last-page>1232</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0009"><ce:label>Huang and Wang, 2006</ce:label><sb:reference id="sbref0009"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Huang</ce:surname><ce:given-name>C.L.</ce:given-name></sb:author><sb:author><ce:surname>Wang</ce:surname><ce:given-name>C.J.</ce:given-name></sb:author></sb:authors><sb:title><sb:maintitle>A GA-based feature selection and parameters optimizationfor support vector machines</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Expert Systems with Applications</sb:maintitle></sb:title><sb:volume-nr>31</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>231</sb:first-page><sb:last-page>240</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0006" xlink:href="http://doi.org/10.1016/j.eswa.2005.09.024" xlink:type="simple">http://doi.org/10.1016/j.eswa.2005.09.024</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>Japan Meteorological Agency. (n.d.) 2015</ce:label><sb:reference id="sbref0010"><sb:contribution langtype="en"><sb:authors><sb:collaboration>Japan Meteorological Agency. (n.d.)</sb:collaboration></sb:authors><sb:title><sb:maintitle>Japan meteorological agency</sb:maintitle></sb:title></sb:contribution><sb:host><sb:e-host><ce:inter-ref id="interref0007" xlink:href="http://www.jma.go.jp/jma/indexe.html" xlink:type="simple">http://www.jma.go.jp/jma/indexe.html</ce:inter-ref><sb:date>2015</sb:date></sb:e-host></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0011"><ce:label>Kisi and Cimen, 2012</ce:label><sb:reference id="sbref0011"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>O.</ce:given-name><ce:surname>Kisi</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Cimen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Precipitation forecasting by using wavelet-support vector machine conjunction model</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Engineering Applications of Artificial Intelligence</sb:maintitle></sb:title><sb:volume-nr>25</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>783</sb:first-page><sb:last-page>792</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0008" xlink:href="http://doi.org/10.1016/j.engappai.2011.11.003" xlink:type="simple">http://doi.org/10.1016/j.engappai.2011.11.003</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0012"><ce:label>Kolokotsa et al., 2009</ce:label><sb:reference id="sbref0012"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Kolokotsa</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Pouliezos</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Stavrakakis</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Lazos</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Predictive control techniques for energy and indoor environmental quality management in buildings</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Building and Environment</sb:maintitle></sb:title><sb:volume-nr>44</sb:volume-nr></sb:series><sb:issue-nr>9</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>1850</sb:first-page><sb:last-page>1863</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0009" xlink:href="http://doi.org/10.1016/j.buildenv.2008.12.007" xlink:type="simple">http://doi.org/10.1016/j.buildenv.2008.12.007</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0013"><ce:label>Loosli, 2007</ce:label><sb:reference id="sbref0012a"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Loosli</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Comments on the core vector machines : fast SVM training on very large data sets</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>The Journal of Machine Learning Research</sb:maintitle></sb:title><sb:volume-nr>8</sb:volume-nr></sb:series><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>291</sb:first-page><sb:last-page>301</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0014"><ce:label>Macqueen, 1967</ce:label><sb:reference id="sbref0013"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Macqueen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Some methods for classification and analysis of multivariate observations</sb:maintitle></sb:title></sb:contribution><sb:host><sb:edited-book><sb:title><sb:maintitle>Proceedings of the fifth berkeley symposium on mathematical statistics and probability</sb:maintitle></sb:title><sb:book-series><sb:series><sb:volume-nr>1</sb:volume-nr></sb:series></sb:book-series><sb:date>1967</sb:date></sb:edited-book><sb:pages><sb:first-page>281</sb:first-page><sb:last-page>297</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0010" xlink:href="http://doi.org/citeulike-article-id:6083430" xlink:type="simple">http://doi.org/citeulike-article-id:6083430</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>Maity et al., 2010</ce:label><sb:reference id="sbref0014"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Maity</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Bhagwat</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Bhatnagar</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Potential of support vector regression for prediction of monthly streamflow using endogenous property</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Hydrological Processes</sb:maintitle></sb:title><sb:volume-nr>24</sb:volume-nr></sb:series><sb:issue-nr>7</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>917</sb:first-page><sb:last-page>923</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0016"><ce:label>Mohammadi et al., 2015</ce:label><sb:reference id="sbref0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Mohammadi</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Shamshirband</ce:surname></sb:author><sb:author><ce:given-name>M.H.</ce:given-name><ce:surname>Anisi</ce:surname></sb:author><sb:author><ce:given-name>K.A.</ce:given-name><ce:surname>Alam</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Petković</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Support vector regression based prediction of global solar radiation on a horizontal surface</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Energy Conversion and Management</sb:maintitle></sb:title><sb:volume-nr>91</sb:volume-nr></sb:series><sb:date>2015</sb:date></sb:issue><sb:pages><sb:first-page>433</sb:first-page><sb:last-page>441</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0017"><ce:label>Othman and Shazali, 2012</ce:label><sb:reference id="sbref0016"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.F.</ce:given-name><ce:surname>Othman</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Shazali</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Wireless sensor network applications: A study in environment monitoring system</sb:maintitle></sb:title></sb:contribution><sb:host><sb:edited-book><sb:title><sb:maintitle>Procedia Engineering</sb:maintitle></sb:title><sb:book-series><sb:series><sb:volume-nr>41</sb:volume-nr></sb:series></sb:book-series><sb:date>2012</sb:date></sb:edited-book><sb:pages><sb:first-page>1204</sb:first-page><sb:last-page>1210</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0011" xlink:href="http://doi.org/10.1016/j.proeng.2012.07.302" xlink:type="simple">http://doi.org/10.1016/j.proeng.2012.07.302</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0018"><ce:label>Park and Park, 2011</ce:label><sb:reference id="sbref0017"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.H.</ce:given-name><ce:surname>Park</ce:surname></sb:author><sb:author><ce:given-name>J.W.</ce:given-name><ce:surname>Park</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Wireless sensor network-based greenhouse environment monitoring and automatic control system for dew condensation prevention</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Sensors</sb:maintitle></sb:title><sb:volume-nr>11</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>3640</sb:first-page><sb:last-page>3651</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0012" xlink:href="http://doi.org/10.3390/s110403640" xlink:type="simple">http://doi.org/10.3390/s110403640</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0019"><ce:label>Pedregosa et al., 2012</ce:label><ce:other-ref id="othref0002"><ce:textref>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M. &amp; Duchesnay, É. (2011). Scikit-learn: machine learning in python. <ce:italic>The Journal of Machine Learning Research</ce:italic> 12, 2825–2830. <ce:inter-ref id="interref0013" xlink:href="http://doi.org/10.1007/s13398-014-0173-7.2" xlink:type="simple">http://doi.org/10.1007/s13398-014-0173-7.2</ce:inter-ref>
</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0020"><ce:label>Platt, 1998</ce:label><sb:reference id="sbref0018"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.C.</ce:given-name><ce:surname>Platt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Fast training of support vector machines using sequential minimal optimization</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Advances in Kernel Methods</sb:maintitle></sb:title></sb:series><sb:date>1998</sb:date></sb:issue><sb:pages><sb:first-page>185</sb:first-page><sb:last-page>208</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0014" xlink:href="http://doi.org/10.1109/ISKE.2008.4731075" xlink:type="simple">http://doi.org/10.1109/ISKE.2008.4731075</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0021"><ce:label>Rahimi and Recht, 2007</ce:label><sb:reference id="sbref0019"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Rahimi</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Recht</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Random features for large-scale kernel machines</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Advances in Neural Information Processing Systems</sb:maintitle></sb:title><sb:volume-nr>20</sb:volume-nr></sb:series><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>1177</sb:first-page><sb:last-page>1184</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0015" xlink:href="http://doi.org/10.1.1.145.8736" xlink:type="simple">http://doi.org/10.1.1.145.8736</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0022"><ce:label>Singh et al., 2013</ce:label><sb:reference id="sbref0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>K.P.</ce:given-name><ce:surname>Singh</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Gupta</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Rai</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Identifying pollution sources and predicting urban air quality using ensemble learning methods</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Atmospheric Environment</sb:maintitle></sb:title><sb:volume-nr>80</sb:volume-nr></sb:series><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>426</sb:first-page><sb:last-page>437</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0016" xlink:href="http://doi.org/10.1016/j.atmosenv.2013.08.023" xlink:type="simple">http://doi.org/10.1016/j.atmosenv.2013.08.023</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0023"><ce:label>Smith et al., 2009</ce:label><sb:reference id="sbref0021"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.A.</ce:given-name><ce:surname>Smith</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Hoogenboom</ce:surname></sb:author><sb:author><ce:given-name>R.W.</ce:given-name><ce:surname>McClendon</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Artificial neural networks for automated year-round temperature prediction</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computers and Electronics in Agriculture</sb:maintitle></sb:title><sb:volume-nr>68</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>52</sb:first-page><sb:last-page>61</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0017" xlink:href="http://doi.org/10.1016/j.compag.2009.04.003" xlink:type="simple">http://doi.org/10.1016/j.compag.2009.04.003</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0024"><ce:label>Suzuki et al., 2014</ce:label><sb:reference id="sbref0022"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Suzuki</ce:surname></sb:author><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Kaneda</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Mineno</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>SW-SVR improved by short-distance data collection method</sb:maintitle></sb:title></sb:contribution><sb:comment><ce:italic>IPSJ SIG Technical Report, 2014-MBL-73(9)</ce:italic></sb:comment><sb:host><sb:book class="report"><sb:date>2014</sb:date></sb:book><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>8</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0025"><ce:label>Suzuki et al., 2015</ce:label><sb:reference id="sbref0023"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Suzuki</ce:surname></sb:author><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Kaneda</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Mineno</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Analysis of support vector regression model for micrometeorological data prediction</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computer Science and Information Technology</sb:maintitle></sb:title><sb:volume-nr>3</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2015</sb:date></sb:issue><sb:pages><sb:first-page>37</sb:first-page><sb:last-page>48</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0018" xlink:href="http://doi.org/10.13189/csit.2015.030202" xlink:type="simple">http://doi.org/10.13189/csit.2015.030202</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0026"><ce:label>Tenenhaus et al., 2005</ce:label><sb:reference id="sbref0024"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Tenenhaus</ce:surname></sb:author><sb:author><ce:given-name>V.E.</ce:given-name><ce:surname>Vinzi</ce:surname></sb:author><sb:author><ce:given-name>Y.M.</ce:given-name><ce:surname>Chatelin</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Lauro</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>PLS path modeling</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computational Statistics and Data Analysis</sb:maintitle></sb:title><sb:volume-nr>48</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>159</sb:first-page><sb:last-page>205</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0019" xlink:href="http://doi.org/10.1016/j.csda.2004.03.005" xlink:type="simple">http://doi.org/10.1016/j.csda.2004.03.005</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0027"><ce:label>Tsang et al., 2005</ce:label><sb:reference id="sbref0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Tsang</ce:surname><ce:given-name>I.W.</ce:given-name></sb:author><sb:author><ce:surname>Kwok</ce:surname><ce:given-name>J.T.</ce:given-name></sb:author><sb:author><ce:surname>Cheung</ce:surname><ce:given-name>P.-M.</ce:given-name></sb:author></sb:authors><sb:title><sb:maintitle>Core vector machines: Fast SVM training on very large data sets</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Journal of Machine Learning Research</sb:maintitle></sb:title><sb:volume-nr>6</sb:volume-nr></sb:series><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>363</sb:first-page><sb:last-page>392</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0020" xlink:href="http://doi.org/10.1111/j.1442-9993.2007.01810.x" xlink:type="simple">http://doi.org/10.1111/j.1442-9993.2007.01810.x</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0028"><ce:label>Urraca et al., 2015</ce:label><sb:reference id="sbref0026"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Urraca</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Antonanzas</ce:surname></sb:author><sb:author><ce:given-name>F.J.</ce:given-name><ce:surname>Martinez-de-Pison</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Antonanzas-Torres</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Estimation of solar global irradiation in remote areas</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Journal of Renewable and Sustainable Energy</sb:maintitle></sb:title><sb:volume-nr>7</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2015</sb:date></sb:issue><sb:article-number>023136</sb:article-number></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0029"><ce:label>Vapnik, 1995</ce:label><sb:reference id="sbref0027"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>V.N.</ce:given-name><ce:surname>Vapnik</ce:surname></sb:author></sb:authors></sb:contribution><sb:host><sb:book><sb:book-series><sb:series><sb:title><sb:maintitle>The Nature of Statistical Learning Theory</sb:maintitle></sb:title><sb:volume-nr>Vol. 8</sb:volume-nr></sb:series></sb:book-series><sb:date>1995</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book></sb:host><sb:comment><ce:inter-ref id="interref0021" xlink:href="http://doi.org/10.1109/TNN.1997.641482" xlink:type="simple">http://doi.org/10.1109/TNN.1997.641482</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0030"><ce:label>Wang and Japkowicz, 2009</ce:label><sb:reference id="sbref0028"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.X.</ce:given-name><ce:surname>Wang</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Japkowicz</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Boosting support vector machines for imbalanced data sets</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Knowledge and Information Systems</sb:maintitle></sb:title><sb:volume-nr>25</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>20</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0022" xlink:href="http://doi.org/10.1007/s10115-009-0198-y" xlink:type="simple">http://doi.org/10.1007/s10115-009-0198-y</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference><ce:bib-reference id="bib0031"><ce:label>Xie et al., 2009</ce:label><sb:reference id="sbref0029"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Xie</ce:surname><ce:given-name>Y.</ce:given-name></sb:author><sb:author><ce:surname>Li</ce:surname><ce:given-name>X.</ce:given-name></sb:author><sb:author><ce:surname>Ngai</ce:surname><ce:given-name>E.W.T.</ce:given-name></sb:author><sb:author><ce:surname>Ying</ce:surname><ce:given-name>W.</ce:given-name></sb:author></sb:authors><sb:title><sb:maintitle>Customer churn prediction using improved balanced random forests</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Expert Systems with Applications</sb:maintitle></sb:title><sb:volume-nr>36</sb:volume-nr></sb:series><sb:issue-nr>3 PART 1</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>5445</sb:first-page><sb:last-page>5449</sb:last-page></sb:pages></sb:host><sb:comment><ce:inter-ref id="interref0023" xlink:href="http://doi.org/10.1016/j.eswa.2008.06.121" xlink:type="simple">http://doi.org/10.1016/j.eswa.2008.06.121</ce:inter-ref></sb:comment></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
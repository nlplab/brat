<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S1361841516300822</prism:url><dc:identifier>doi:10.1016/j.media.2016.06.005</dc:identifier><eid>1-s2.0-S1361841516300822</eid><prism:doi>10.1016/j.media.2016.06.005</prism:doi><pii>S1361-8415(16)30082-2</pii><dc:title>Autoadaptive motion modelling for MR-based respiratory motion estimation </dc:title><prism:publicationName>Medical Image Analysis</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>13618415</prism:issn><prism:volume>35</prism:volume><prism:startingPage>83</prism:startingPage><prism:endingPage>100</prism:endingPage><prism:pageRange>83-100</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2017-01-31</prism:coverDate><prism:coverDisplayDate>January 2017</prism:coverDisplayDate><prism:copyright>© 2016 The Author(s). Published by Elsevier B.V.</prism:copyright><prism:publisher>The Author(s). Published by Elsevier B.V.</prism:publisher><dc:creator>Baumgartner, Christian F.</dc:creator><dc:creator>Kolbitsch, Christoph</dc:creator><dc:creator>McClelland, Jamie R.</dc:creator><dc:creator>Rueckert, Daniel</dc:creator><dc:creator>King, Andrew P.</dc:creator><dc:description>AbstractRespiratory motion poses significant challenges in image-guided interventions. In emerging treatments such as MR-guided HIFU or MR-guided radiotherapy, it may cause significant misalignments between interventional road maps obtained pre-procedure and the anatomy during the treatment, and may affect intra-procedural imaging such as MR-thermometry. Patient specific respiratory motion models provide a solution to this problem. They establish a correspondence between the patient motion and simpler surrogate data which can be acquired easily during the treatment. Patient motion can then be estimated during the treatment by acquiring only the simpler surrogate data.In the majority of classical motion modelling approaches once the correspondence between the surrogate data and the patient motion is established it cannot be changed unless the model is recalibrated. However, breathing patterns are known to significantly change in the time frame of MR-guided interventions. Thus, the classical motion modelling approach may yield inaccurate motion estimations when the relation between the motion and the surrogate data changes over the duration of the treatment and frequent recalibration may not be feasible.We propose a novel methodology for motion modelling which has the ability to automatically adapt to new breathing patterns. This is achieved by choosing the surrogate data in such a way that it can be used to estimate the current motion in 3D as well as to update the motion model. In particular, in this work, we use 2D MR slices from different slice positions to build as well as to apply the motion model. We implemented such an autoadaptive motion model by extending our previous work on manifold alignment.We demonstrate a proof-of-principle of the proposed technique on cardiac gated data of the thorax and evaluate its adaptive behaviour on realistic synthetic data containing two breathing types generated from 6 volunteers, and real data from 4 volunteers. On synthetic data the autoadaptive motion model yielded 21.45% more accurate motion estimations compared to a non-adaptive motion model 10 min after a change in breathing pattern. On real data we demonstrated the method’s ability to maintain motion estimation accuracy despite a drift in the respiratory baseline. Due to the cardiac gating of the imaging data, the method is currently limited to one update per heart beat and the calibration requires approximately 12 min of scanning. Furthermore, the method has a prediction latency of 800 ms. These limitations may be overcome in future work by altering the acquisition protocol.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName>Engineering and Physical Sciences Research Council</openaccessSponsorName><openaccessSponsorType>FundingBody</openaccessSponsorType><openaccessUserLicense>http://creativecommons.org/licenses/by/4.0/</openaccessUserLicense><dcterms:subject>MR-guided interventions</dcterms:subject><dcterms:subject>Respiratory motion correction</dcterms:subject><dcterms:subject>Motion modelling</dcterms:subject><dcterms:subject>Manifold learning</dcterms:subject><dcterms:subject>Manifold alignment</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S1361841516300822"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S1361841516300822"/></coredata><objects><object ref="gr1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="207" height="164" size="13274">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr1.sml?httpAccept=%2A%2F%2A</object><object ref="gr10" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="156" size="15165">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr10.sml?httpAccept=%2A%2F%2A</object><object ref="gr11" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="142" size="15553">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr11.sml?httpAccept=%2A%2F%2A</object><object ref="gr2" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="94" size="7605">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr2.sml?httpAccept=%2A%2F%2A</object><object ref="gr3" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="104" size="14640">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr3.sml?httpAccept=%2A%2F%2A</object><object ref="gr4" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="104" size="13078">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr4.sml?httpAccept=%2A%2F%2A</object><object ref="gr5" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="118" size="9205">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr5.sml?httpAccept=%2A%2F%2A</object><object ref="gr6" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="136" size="7256">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr6.sml?httpAccept=%2A%2F%2A</object><object ref="gr7" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="209" height="164" size="12234">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr7.sml?httpAccept=%2A%2F%2A</object><object ref="gr8" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="152" height="164" size="13524">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr8.sml?httpAccept=%2A%2F%2A</object><object ref="gr9" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="152" height="164" size="15283">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr9.sml?httpAccept=%2A%2F%2A</object><object ref="fx1" category="thumbnail" type="IMAGE-THUMBNAIL" multimediatype="GIF image file" mimetype="image/gif" width="219" height="127" size="13776">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-fx1.sml?httpAccept=%2A%2F%2A</object><object ref="gr1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="713" height="566" size="106669">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr1.jpg?httpAccept=%2A%2F%2A</object><object ref="gr10" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="813" height="580" size="112025">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr10.jpg?httpAccept=%2A%2F%2A</object><object ref="gr11" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="562" height="364" size="76946">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr11.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="282" height="121" size="16063">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr2.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="605" height="289" size="58346">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr3.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="579" height="275" size="48486">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr4.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="565" height="305" size="46191">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr5.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="243" height="150" size="11873">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr6.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="689" height="539" size="94996">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr7.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="812" height="876" size="169884">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr8.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="813" height="876" size="194202">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr9.jpg?httpAccept=%2A%2F%2A</object><object ref="fx1" category="standard" type="IMAGE-DOWNSAMPLED" multimediatype="JPEG image file" mimetype="image/jpeg" width="346" height="200" size="29001">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-fx1.jpg?httpAccept=%2A%2F%2A</object><object ref="gr1" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="3155" height="2503" size="822257">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr1_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr10" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="3599" height="2566" size="764403">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr10_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr11" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2490" height="1612" size="691996">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr11_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr2" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1250" height="536" size="109424">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr2_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr3" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2681" height="1279" size="560169">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr3_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr4" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2564" height="1216" size="471347">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr4_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr5" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="2501" height="1351" size="320588">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr5_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr6" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1079" height="668" size="60067">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr6_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr7" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="3053" height="2389" size="846352">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr7_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr8" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="3597" height="3879" size="1175743">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr8_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="gr9" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="3600" height="3881" size="1356006">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-gr9_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="fx1" category="high" type="IMAGE-HIGH-RES" multimediatype="JPEG image file" mimetype="image/jpeg" width="1532" height="886" size="255818">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-fx1_lrg.jpg?httpAccept=%2A%2F%2A</object><object ref="mmc1" category="standard" type="APPLICATION" multimediatype="Acrobat PDF file" mimetype="application/pdf" size="80064">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-mmc1.pdf?httpAccept=%2A%2F%2A</object><object ref="si33" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="39" height="23" size="326">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si33.gif?httpAccept=%2A%2F%2A</object><object ref="si20" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="23" height="24" size="221">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si20.gif?httpAccept=%2A%2F%2A</object><object ref="si30" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="127" height="25" size="680">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si30.gif?httpAccept=%2A%2F%2A</object><object ref="si40" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="50" height="26" size="459">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si40.gif?httpAccept=%2A%2F%2A</object><object ref="si50" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="81" height="16" size="459">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si50.gif?httpAccept=%2A%2F%2A</object><object ref="si60" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="24" height="16" size="188">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si60.gif?httpAccept=%2A%2F%2A</object><object ref="si70" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="261" height="16" size="969">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si70.gif?httpAccept=%2A%2F%2A</object><object ref="si9" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="44" height="13" size="177">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si9.gif?httpAccept=%2A%2F%2A</object><object ref="si71" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="41" height="17" size="253">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si71.gif?httpAccept=%2A%2F%2A</object><object ref="si1" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="25" height="24" size="259">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si1.gif?httpAccept=%2A%2F%2A</object><object ref="si11" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="17" height="24" size="203">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si11.gif?httpAccept=%2A%2F%2A</object><object ref="si12" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="24" size="206">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si12.gif?httpAccept=%2A%2F%2A</object><object ref="si13" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="14" height="1" size="52">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si13.gif?httpAccept=%2A%2F%2A</object><object ref="si14" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="17" height="24" size="179">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si14.gif?httpAccept=%2A%2F%2A</object><object ref="si15" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="20" height="18" size="188">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si15.gif?httpAccept=%2A%2F%2A</object><object ref="si16" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="12" height="13" size="143">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si16.gif?httpAccept=%2A%2F%2A</object><object ref="si17" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="48" height="16" size="273">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si17.gif?httpAccept=%2A%2F%2A</object><object ref="si18" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="89" height="22" size="454">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si18.gif?httpAccept=%2A%2F%2A</object><object ref="si19" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="65" height="24" size="379">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si19.gif?httpAccept=%2A%2F%2A</object><object ref="si2" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="24" size="187">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si2.gif?httpAccept=%2A%2F%2A</object><object ref="si21" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="21" height="15" size="182">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si21.gif?httpAccept=%2A%2F%2A</object><object ref="si22" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="25" height="24" size="233">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si22.gif?httpAccept=%2A%2F%2A</object><object ref="si23" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="84" height="22" size="431">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si23.gif?httpAccept=%2A%2F%2A</object><object ref="si24" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="380" height="44" size="1812">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si24.gif?httpAccept=%2A%2F%2A</object><object ref="si3" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="24" size="195">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si3.gif?httpAccept=%2A%2F%2A</object><object ref="si25" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="198" height="22" size="795">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si25.gif?httpAccept=%2A%2F%2A</object><object ref="si26" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="74" height="24" size="372">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si26.gif?httpAccept=%2A%2F%2A</object><object ref="si27" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="43" height="15" size="212">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si27.gif?httpAccept=%2A%2F%2A</object><object ref="si28" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="299" height="33" size="1556">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si28.gif?httpAccept=%2A%2F%2A</object><object ref="si29" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="236" height="46" size="1230">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si29.gif?httpAccept=%2A%2F%2A</object><object ref="si31" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="254" height="57" size="1493">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si31.gif?httpAccept=%2A%2F%2A</object><object ref="si32" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="84" height="16" size="318">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si32.gif?httpAccept=%2A%2F%2A</object><object ref="si34" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="16" height="16" size="159">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si34.gif?httpAccept=%2A%2F%2A</object><object ref="si35" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="19" height="18" size="190">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si35.gif?httpAccept=%2A%2F%2A</object><object ref="si36" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="50" height="25" size="349">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si36.gif?httpAccept=%2A%2F%2A</object><object ref="si37" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="49" height="27" size="350">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si37.gif?httpAccept=%2A%2F%2A</object><object ref="si38" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="49" height="25" size="334">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si38.gif?httpAccept=%2A%2F%2A</object><object ref="si39" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="48" height="27" size="345">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si39.gif?httpAccept=%2A%2F%2A</object><object ref="si4" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="19" height="15" size="180">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si4.gif?httpAccept=%2A%2F%2A</object><object ref="si41" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="56" height="26" size="473">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si41.gif?httpAccept=%2A%2F%2A</object><object ref="si42" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="434" height="87" size="3030">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si42.gif?httpAccept=%2A%2F%2A</object><object ref="si43" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="50" height="25" size="347">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si43.gif?httpAccept=%2A%2F%2A</object><object ref="si44" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="38" height="26" size="335">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si44.gif?httpAccept=%2A%2F%2A</object><object ref="si45" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="326" height="27" size="1401">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si45.gif?httpAccept=%2A%2F%2A</object><object ref="si46" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="99" height="27" size="536">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si46.gif?httpAccept=%2A%2F%2A</object><object ref="si47" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="15" size="168">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si47.gif?httpAccept=%2A%2F%2A</object><object ref="si48" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="20" height="15" size="185">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si48.gif?httpAccept=%2A%2F%2A</object><object ref="si49" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="15" size="177">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si49.gif?httpAccept=%2A%2F%2A</object><object ref="si5" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="76" height="16" size="443">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si5.gif?httpAccept=%2A%2F%2A</object><object ref="si51" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="75" height="16" size="440">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si51.gif?httpAccept=%2A%2F%2A</object><object ref="si52" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="67" height="16" size="408">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si52.gif?httpAccept=%2A%2F%2A</object><object ref="si53" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="67" height="16" size="398">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si53.gif?httpAccept=%2A%2F%2A</object><object ref="si54" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="41" height="23" size="321">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si54.gif?httpAccept=%2A%2F%2A</object><object ref="si55" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="41" height="23" size="304">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si55.gif?httpAccept=%2A%2F%2A</object><object ref="si56" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="39" height="23" size="328">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si56.gif?httpAccept=%2A%2F%2A</object><object ref="si57" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="47" height="23" size="323">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si57.gif?httpAccept=%2A%2F%2A</object><object ref="si58" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="81" height="16" size="446">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si58.gif?httpAccept=%2A%2F%2A</object><object ref="si59" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="68" height="16" size="410">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si59.gif?httpAccept=%2A%2F%2A</object><object ref="si6" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="56" height="17" size="272">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si6.gif?httpAccept=%2A%2F%2A</object><object ref="si61" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="76" height="16" size="435">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si61.gif?httpAccept=%2A%2F%2A</object><object ref="si62" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="166" height="57" size="1096">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si62.gif?httpAccept=%2A%2F%2A</object><object ref="si63" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="42" height="24" size="398">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si63.gif?httpAccept=%2A%2F%2A</object><object ref="si64" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="24" size="203">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si64.gif?httpAccept=%2A%2F%2A</object><object ref="si65" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="61" height="26" size="278">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si65.gif?httpAccept=%2A%2F%2A</object><object ref="si66" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="35" height="23" size="280">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si66.gif?httpAccept=%2A%2F%2A</object><object ref="si67" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="84" height="16" size="321">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si67.gif?httpAccept=%2A%2F%2A</object><object ref="si68" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="199" height="17" size="674">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si68.gif?httpAccept=%2A%2F%2A</object><object ref="si69" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="137" height="19" size="636">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si69.gif?httpAccept=%2A%2F%2A</object><object ref="si7" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="54" height="17" size="267">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si7.gif?httpAccept=%2A%2F%2A</object><object ref="si72" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="81" height="13" size="330">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si72.gif?httpAccept=%2A%2F%2A</object><object ref="si73" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="83" height="15" size="306">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si73.gif?httpAccept=%2A%2F%2A</object><object ref="si10" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="24" height="16" size="195">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si10.gif?httpAccept=%2A%2F%2A</object><object ref="si74" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="77" height="15" size="295">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si74.gif?httpAccept=%2A%2F%2A</object><object ref="si8" category="thumbnail" type="ALTIMG" multimediatype="GIF image file" mimetype="image/gif" width="18" height="24" size="196">http://api.elsevier.com/content/object/eid/1-s2.0-S1361841516300822-si8.gif?httpAccept=%2A%2F%2A</object></objects><scopus-id>84975121926</scopus-id><scopus-eid>2-s2.0-84975121926</scopus-eid><link rel="abstract" href="http://api.elsevier.com/content/abstract/scopus_id/84975121926"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>272154</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291703</xocs:ssid><xocs:ssid type="subj">291868</xocs:ssid><xocs:ssid type="subj">291870</xocs:ssid><xocs:ssid type="subj">291872</xocs:ssid><xocs:ssid type="subj">291880</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>Medical Image Analysis</xocs:srctitle><xocs:normalized-srctitle>MEDICALIMAGEANALYSIS</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20160609">2016-06-09</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20160609">2016-06-09</xocs:available-online-date><xocs:vor-load-date yyyymmdd="20160622">2016-06-22</xocs:vor-load-date><xocs:vor-available-online-date yyyymmdd="20160622">2016-06-22</xocs:vor-available-online-date><xocs:ew-transaction-id>2016-08-04T09:58:36</xocs:ew-transaction-id><xocs:eid>1-s2.0-S1361841516300822</xocs:eid><xocs:pii-formatted>S1361-8415(16)30082-2</xocs:pii-formatted><xocs:pii-unformatted>S1361841516300822</xocs:pii-unformatted><xocs:doi>10.1016/j.media.2016.06.005</xocs:doi><xocs:item-stage>S250</xocs:item-stage><xocs:item-version-number>S250.1</xocs:item-version-number><xocs:item-weight>FULL-TEXT</xocs:item-weight><xocs:hub-eid>1-s2.0-S1361841516X00072</xocs:hub-eid><xocs:timestamp yyyymmdd="20160805">2016-08-05T16:17:28.978125-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20170101</xocs:date-search-begin><xocs:date-search-end>20170131</xocs:date-search-end><xocs:year-nav>2017</xocs:year-nav><xocs:indexeddate epoch="1465495853">2016-06-09T18:10:53.889102Z</xocs:indexeddate><xocs:articleinfo>absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast highlightsabst orcid primabst ref specialabst</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>1361-8415</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>13618415</xocs:issn-primary-unformatted></xocs:issns><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>EPSRC</xocs:funding-body-id><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>35</xocs:vol-first><xocs:volume-list><xocs:volume>35</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 35</xocs:vol-iss-suppl-text><xocs:sort-order>7</xocs:sort-order><xocs:first-fp>83</xocs:first-fp><xocs:last-lp>100</xocs:last-lp><xocs:pages><xocs:first-page>83</xocs:first-page><xocs:last-page>100</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>201701</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>January 2017</xocs:cover-date-text><xocs:cover-date-start>2017-01-01</xocs:cover-date-start><xocs:cover-date-end>2017-01-31</xocs:cover-date-end><xocs:cover-date-year>2017</xocs:cover-date-year><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>© 2016 The Author(s). Published by Elsevier B.V.</xocs:copyright-line><xocs:normalized-article-title>AUTOADAPTIVEMOTIONMODELLINGFORMRBASEDRESPIRATORYMOTIONESTIMATION</xocs:normalized-article-title><xocs:normalized-first-auth-surname>BAUMGARTNER</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>C</xocs:normalized-first-auth-initial><xocs:item-toc><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>1</xocs:item-toc-label><xocs:item-toc-section-title>Introduction</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>1.1</xocs:item-toc-label><xocs:item-toc-section-title>Motion modelling</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>1.2</xocs:item-toc-label><xocs:item-toc-section-title>Manifold learning and manifold alignment</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2</xocs:item-toc-label><xocs:item-toc-section-title>Background</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2.1</xocs:item-toc-label><xocs:item-toc-section-title>Manifold learning on one dataset</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2.2</xocs:item-toc-label><xocs:item-toc-section-title>Simultaneous embedding of two datasets</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>2.3</xocs:item-toc-label><xocs:item-toc-section-title>Embedding data from many slice positions</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3</xocs:item-toc-label><xocs:item-toc-section-title>Materials and methods</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.1</xocs:item-toc-label><xocs:item-toc-section-title>Calibration scan</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.2</xocs:item-toc-label><xocs:item-toc-section-title>Motion model formation</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.2.1</xocs:item-toc-label><xocs:item-toc-section-title>Distance functions for neighbouring slices of the same orientation</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.2.2</xocs:item-toc-label><xocs:item-toc-section-title>Distance function for slices with different orientation</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.2.3</xocs:item-toc-label><xocs:item-toc-section-title>Group connectivity and propagation of respiratory information</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.3</xocs:item-toc-label><xocs:item-toc-section-title>Model updating and adaptivity</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.3.1</xocs:item-toc-label><xocs:item-toc-section-title>Obtaining a 2D update motion estimate</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.3.2</xocs:item-toc-label><xocs:item-toc-section-title>Estimating current 3D motion</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.3.3</xocs:item-toc-label><xocs:item-toc-section-title>Interpolating motion fields on the manifold and 3D reconstruction</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>3.3.4</xocs:item-toc-label><xocs:item-toc-section-title>Updating the model and adaptivity</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4</xocs:item-toc-label><xocs:item-toc-section-title>Experiments and results</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.1</xocs:item-toc-label><xocs:item-toc-section-title>Parameter choices</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.2</xocs:item-toc-label><xocs:item-toc-section-title>Experiments on synthetic data</xocs:item-toc-section-title><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.2.1</xocs:item-toc-label><xocs:item-toc-section-title>Generation of realistic synthetic data</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.2.2</xocs:item-toc-label><xocs:item-toc-section-title>Experiment 1: synthetic training adaptivity</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.2.3</xocs:item-toc-label><xocs:item-toc-section-title>Experiment 2: synthetic adaptivity to a new breathing pattern</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>4.3</xocs:item-toc-label><xocs:item-toc-section-title>Experiment 3: adaptivity on real data</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>5</xocs:item-toc-label><xocs:item-toc-section-title>Discussion</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-label>6</xocs:item-toc-label><xocs:item-toc-section-title>Conclusion</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:sections"><xocs:item-toc-section-title>Data download</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:acknowledgment"><xocs:item-toc-section-title>Acknowledgements</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:appendices"><xocs:item-toc-label>Appendix A</xocs:item-toc-label><xocs:item-toc-section-title>Supplementary materials</xocs:item-toc-section-title></xocs:item-toc-entry><xocs:item-toc-entry ref-elem="ce:bibliography"><xocs:item-toc-section-title>References</xocs:item-toc-section-title></xocs:item-toc-entry></xocs:item-toc><xocs:references><xocs:ref-info refid="sbref0001"><xocs:ref-normalized-surname>ARNOLD</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>623</xocs:ref-first-fp><xocs:ref-last-lp>630</xocs:ref-last-lp><xocs:ref-normalized-initial>P</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCMICCAI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>3DORGANMOTIONPREDICTIONFORMRGUIDEDHIGHINTENSITYFOCUSEDULTRASOUND</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0002"><xocs:ref-normalized-surname>BAUMGARTNER</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>939</xocs:ref-first-fp><xocs:ref-last-lp>952</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0003"><xocs:ref-normalized-surname>BAUMGARTNER</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>232</xocs:ref-first-fp><xocs:ref-last-lp>243</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIPMI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>GROUPWISESIMULTANEOUSMANIFOLDALIGNMENTFORHIGHRESOLUTIONDYNAMICMRIMAGINGRESPIRATORYMOTION</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0004"><xocs:ref-normalized-surname>BAUMGARTNER</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>457</xocs:ref-first-fp><xocs:ref-last-lp>460</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIEEEISBI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>AUTOADAPTIVEMOTIONMODELLING</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0005"><xocs:ref-normalized-surname>BHATIA</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>512</xocs:ref-first-fp><xocs:ref-last-lp>519</xocs:ref-last-lp><xocs:ref-normalized-initial>K</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCMICCAI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>HIERARCHICALMANIFOLDLEARNING</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0006"><xocs:ref-normalized-surname>BLACKALL</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>4147</xocs:ref-first-fp><xocs:ref-last-lp>4169</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0007"><xocs:ref-normalized-surname>BRIX</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>042302</xocs:ref-first-fp><xocs:ref-normalized-initial>L</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0008"><xocs:ref-normalized-surname>CHO</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>3299</xocs:ref-first-fp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0009"><xocs:ref-normalized-surname>CRIJNS</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>7863</xocs:ref-first-fp><xocs:ref-normalized-initial>S</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0010"><xocs:ref-normalized-surname>DESENNEVILLE</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-first-fp>974</xocs:ref-first-fp><xocs:ref-last-lp>982</xocs:ref-last-lp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0011"><xocs:ref-normalized-surname>DIKAIOS</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>439</xocs:ref-first-fp><xocs:ref-last-lp>446</xocs:ref-last-lp><xocs:ref-normalized-initial>N</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0012"><xocs:ref-normalized-surname>FASSI</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>182</xocs:ref-first-fp><xocs:ref-last-lp>188</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0013"><xocs:ref-normalized-surname>FISCHER</xocs:ref-normalized-surname><xocs:ref-pub-year>2014</xocs:ref-pub-year><xocs:ref-first-fp>915</xocs:ref-first-fp><xocs:ref-last-lp>918</xocs:ref-last-lp><xocs:ref-normalized-initial>P</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIEEEISBI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>REALTIMERESPIRATORYSIGNALEXTRACTINOXRAYSEQUENCESUSINGINCREMENTALMANIFOLDLEARNING</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0014"><xocs:ref-normalized-surname>FOLEY</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>357</xocs:ref-first-fp><xocs:ref-last-lp>370</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0015"><xocs:ref-normalized-surname>GEORG</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>1</xocs:ref-first-fp><xocs:ref-last-lp>8</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIEEECVPRW</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>MANIFOLDLEARNINGFOR4DCTRECONSTRUCTIONLUNG</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0016"><xocs:ref-normalized-surname>HOOGEMAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>297</xocs:ref-first-fp><xocs:ref-last-lp>303</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0017"><xocs:ref-normalized-surname>HYNYNEN</xocs:ref-normalized-surname><xocs:ref-pub-year>1996</xocs:ref-pub-year><xocs:ref-first-fp>185</xocs:ref-first-fp><xocs:ref-last-lp>195</xocs:ref-last-lp><xocs:ref-normalized-initial>K</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0018"><xocs:ref-normalized-surname>ISAKSSON</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>3801</xocs:ref-first-fp><xocs:ref-last-lp>3809</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0019"><xocs:ref-normalized-surname>KING</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>252</xocs:ref-first-fp><xocs:ref-last-lp>264</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0020"><xocs:ref-normalized-surname>KING</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>2020</xocs:ref-first-fp><xocs:ref-last-lp>2032</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0021"><xocs:ref-normalized-surname>KINI</xocs:ref-normalized-surname><xocs:ref-pub-year>2003</xocs:ref-pub-year><xocs:ref-first-fp>7</xocs:ref-first-fp><xocs:ref-last-lp>11</xocs:ref-last-lp><xocs:ref-normalized-initial>V</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0022"><xocs:ref-normalized-surname>KUHN</xocs:ref-normalized-surname><xocs:ref-pub-year>1955</xocs:ref-pub-year><xocs:ref-first-fp>83</xocs:ref-first-fp><xocs:ref-last-lp>97</xocs:ref-last-lp><xocs:ref-normalized-initial>H</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0023"><xocs:ref-normalized-surname>LOW</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>921</xocs:ref-first-fp><xocs:ref-last-lp>929</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0024"><xocs:ref-normalized-surname>MCCLELLAND</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>19</xocs:ref-first-fp><xocs:ref-last-lp>42</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0025"><xocs:ref-normalized-surname>MCCLELLAND</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>251</xocs:ref-first-fp><xocs:ref-last-lp>272</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0026"><xocs:ref-normalized-surname>MODAT</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>278</xocs:ref-first-fp><xocs:ref-last-lp>284</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0027"><xocs:ref-normalized-surname>PARK</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>6431</xocs:ref-first-fp><xocs:ref-last-lp>6442</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0028"><xocs:ref-normalized-surname>PERESSUTTI</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>488</xocs:ref-first-fp><xocs:ref-last-lp>502</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0029"><xocs:ref-normalized-surname>PERESSUTTI</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>262</xocs:ref-first-fp><xocs:ref-last-lp>265</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIEEEISBI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>ESTIMATINGRESOLVINGUNCERTAINTYINCARDIACRESPIRATORYMOTIONMODELLING</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0030"><xocs:ref-normalized-surname>RAAYMAKERS</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>N229</xocs:ref-first-fp><xocs:ref-normalized-initial>B</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0031"><xocs:ref-normalized-surname>RAO</xocs:ref-normalized-surname><xocs:ref-pub-year>2002</xocs:ref-pub-year><xocs:ref-first-fp>722</xocs:ref-first-fp><xocs:ref-last-lp>729</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCMICCAI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>COMPARISONCARDIACMOTIONACROSSSUBJECTSUSINGNONRIGIDREGISTRATION</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0032"><xocs:ref-normalized-surname>RIES</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>1704</xocs:ref-first-fp><xocs:ref-last-lp>1712</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0033"><xocs:ref-normalized-surname>RIJKHORST</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>113</xocs:ref-first-fp><xocs:ref-last-lp>123</xocs:ref-last-lp><xocs:ref-normalized-initial>E</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIPCAI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>SIMULATINGDYNAMICULTRASOUNDUSINGMRDERIVEDMOTIONMODELSASSESSRESPIRATORYSYNCHRONISATIONFORIMAGEGUIDEDLIVERINTERVENTIONS</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0034"><xocs:ref-normalized-surname>RIJKHORST</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>605</xocs:ref-first-fp><xocs:ref-last-lp>612</xocs:ref-last-lp><xocs:ref-normalized-initial>E</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCMICCAI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>EFFECTSRESPIRATORYLIVERMOTIONHEATINGFORGATEDMODELBASEDMOTIONCOMPENSATEDHIGHINTENSITYFOCUSEDULTRASOUNDABLATION</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0035"><xocs:ref-normalized-surname>ROSENBLATT</xocs:ref-normalized-surname><xocs:ref-pub-year>1956</xocs:ref-pub-year><xocs:ref-first-fp>832</xocs:ref-first-fp><xocs:ref-last-lp>837</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0036"><xocs:ref-normalized-surname>ROWEIS</xocs:ref-normalized-surname><xocs:ref-pub-year>2000</xocs:ref-pub-year><xocs:ref-first-fp>2323</xocs:ref-first-fp><xocs:ref-last-lp>2326</xocs:ref-last-lp><xocs:ref-normalized-initial>S</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0037"><xocs:ref-normalized-surname>SAVILL</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>1698</xocs:ref-first-fp><xocs:ref-last-lp>1701</xocs:ref-last-lp><xocs:ref-normalized-initial>F</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCISBI</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>ASSESSMENTINPUTSIGNALPOSITIONINGFORCARDIACRESPIRATORYMOTIONMODELSDURINGDIFFERENTBREATHINGPATTERNS</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0038"><xocs:ref-normalized-surname>SAWANT</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>575</xocs:ref-first-fp><xocs:ref-last-lp>582</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0039"><xocs:ref-normalized-surname>SCHWEIKARD</xocs:ref-normalized-surname><xocs:ref-pub-year>2000</xocs:ref-pub-year><xocs:ref-first-fp>263</xocs:ref-first-fp><xocs:ref-last-lp>277</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0040"><xocs:ref-normalized-surname>SCHWEIKARD</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>19</xocs:ref-first-fp><xocs:ref-last-lp>27</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0041"><xocs:ref-normalized-surname>SEPPENWOOLDE</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-first-fp>2774</xocs:ref-first-fp><xocs:ref-last-lp>2784</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0042"><xocs:ref-normalized-surname>SEPPENWOOLDE</xocs:ref-normalized-surname><xocs:ref-pub-year>2002</xocs:ref-pub-year><xocs:ref-first-fp>822</xocs:ref-first-fp><xocs:ref-last-lp>834</xocs:ref-last-lp><xocs:ref-normalized-initial>Y</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0043"><xocs:ref-normalized-surname>SHARP</xocs:ref-normalized-surname><xocs:ref-pub-year>2004</xocs:ref-pub-year><xocs:ref-first-fp>425</xocs:ref-first-fp><xocs:ref-normalized-initial>G</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0044"><xocs:ref-normalized-surname>SOUVENIR</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>1437</xocs:ref-first-fp><xocs:ref-last-lp>1440</xocs:ref-last-lp><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>PROCIEEEIMAGEPROC</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>IMAGEMANIFOLDINTERPOLATIONUSINGFREEFORMDEFORMATIONS</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="sbref0045"><xocs:ref-normalized-surname>TEMPANY</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>39</xocs:ref-first-fp><xocs:ref-last-lp>56</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0046"><xocs:ref-normalized-surname>VONSIEBENTHAL</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-first-fp>1547</xocs:ref-first-fp><xocs:ref-last-lp>1564</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0047"><xocs:ref-normalized-surname>WACHINGER</xocs:ref-normalized-surname><xocs:ref-pub-year>2011</xocs:ref-pub-year><xocs:ref-first-fp>806</xocs:ref-first-fp><xocs:ref-last-lp>818</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0048"><xocs:ref-normalized-surname>WURSLIN</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>464</xocs:ref-first-fp><xocs:ref-last-lp>471</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0049"><xocs:ref-normalized-surname>ZACHIU</xocs:ref-normalized-surname><xocs:ref-pub-year>2015</xocs:ref-pub-year><xocs:ref-first-fp>4137</xocs:ref-first-fp><xocs:ref-last-lp>4148</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:refkeys><xocs:refkey3>BAUMGARTNERX2017X83</xocs:refkey3><xocs:refkey4lp>BAUMGARTNERX2017X83X100</xocs:refkey4lp><xocs:refkey4ai>BAUMGARTNERX2017X83XC</xocs:refkey4ai><xocs:refkey5>BAUMGARTNERX2017X83X100XC</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2016-06-08T10:56:39Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>FundingBody</xocs:oa-sponsor-type><xocs:oa-sponsor-name>Engineering and Physical Sciences Research Council</xocs:oa-sponsor-name></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by/4.0/</xocs:oa-user-license></xocs:open-access><xocs:self-archiving><xocs:sa-start-date>2018-06-22T00:00:00Z</xocs:sa-start-date><xocs:sa-embargo-status>UnderEmbargo</xocs:sa-embargo-status><xocs:sa-user-license>http://creativecommons.org/licenses/by-nc-nd/4.0/</xocs:sa-user-license></xocs:self-archiving><xocs:copyright-info><xocs:cp-license-lines><xocs:cp-license-line lang="en">This is an open access article under the CC BY license.</xocs:cp-license-line></xocs:cp-license-lines><xocs:cp-notices><xocs:cp-notice lang="en">© 2016 The Author(s). Published by Elsevier B.V.</xocs:cp-notice></xocs:cp-notices></xocs:copyright-info><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S1361-8415(16)30082-2</xocs:pii-formatted><xocs:pii-unformatted>S1361841516300822</xocs:pii-unformatted><xocs:eid>1-s2.0-S1361841516300822</xocs:eid><xocs:doi>10.1016/j.media.2016.06.005</xocs:doi><xocs:cid>272154</xocs:cid><xocs:timestamp>2016-08-05T16:17:28.978125-04:00</xocs:timestamp><xocs:cover-date-start>2017-01-01</xocs:cover-date-start><xocs:cover-date-end>2017-01-31</xocs:cover-date-end><xocs:sponsored-access-type>UNLIMITED</xocs:sponsored-access-type><xocs:funding-body-id>EPSRC</xocs:funding-body-id><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S1361841516300822-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/MAIN/application/pdf/74b795182dc490d8056efb62deca2a84/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/MAIN/application/pdf/74b795182dc490d8056efb62deca2a84/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>2560100</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>18</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S1361841516300822-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/PREVIEW/image/png/66277befab6b540b29306c91f7e75ec0/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/PREVIEW/image/png/66277befab6b540b29306c91f7e75ec0/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>51048</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr1.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr1/THUMBNAIL/image/gif/7290fe2f87a91d418f721d211623983c/gr1.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr1/THUMBNAIL/image/gif/7290fe2f87a91d418f721d211623983c/gr1.sml</xocs:ucs-locator><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>13274</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>207</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr10.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr10/THUMBNAIL/image/gif/ec12b112c6e627c38bc7af3003618b9f/gr10.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr10/THUMBNAIL/image/gif/ec12b112c6e627c38bc7af3003618b9f/gr10.sml</xocs:ucs-locator><xocs:file-basename>gr10</xocs:file-basename><xocs:filename>gr10.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>15165</xocs:filesize><xocs:pixel-height>156</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr11.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr11/THUMBNAIL/image/gif/7854bf91862f6205905623487cb0c145/gr11.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr11/THUMBNAIL/image/gif/7854bf91862f6205905623487cb0c145/gr11.sml</xocs:ucs-locator><xocs:file-basename>gr11</xocs:file-basename><xocs:filename>gr11.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>15553</xocs:filesize><xocs:pixel-height>142</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr2.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr2/THUMBNAIL/image/gif/39b3177f02d93005158f266e876b10c3/gr2.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr2/THUMBNAIL/image/gif/39b3177f02d93005158f266e876b10c3/gr2.sml</xocs:ucs-locator><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>7605</xocs:filesize><xocs:pixel-height>94</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr3.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr3/THUMBNAIL/image/gif/781cf84b3250865159b400145f25ed03/gr3.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr3/THUMBNAIL/image/gif/781cf84b3250865159b400145f25ed03/gr3.sml</xocs:ucs-locator><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>14640</xocs:filesize><xocs:pixel-height>104</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr4.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr4/THUMBNAIL/image/gif/87b4b7441eeae32b60baffd9c96f1ddc/gr4.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr4/THUMBNAIL/image/gif/87b4b7441eeae32b60baffd9c96f1ddc/gr4.sml</xocs:ucs-locator><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>13078</xocs:filesize><xocs:pixel-height>104</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr5.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr5/THUMBNAIL/image/gif/bf19fd77162419eebc7228ea0976a6c3/gr5.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr5/THUMBNAIL/image/gif/bf19fd77162419eebc7228ea0976a6c3/gr5.sml</xocs:ucs-locator><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>9205</xocs:filesize><xocs:pixel-height>118</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr6.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr6/THUMBNAIL/image/gif/c2e85e8183d8107625be883aed52a7fe/gr6.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr6/THUMBNAIL/image/gif/c2e85e8183d8107625be883aed52a7fe/gr6.sml</xocs:ucs-locator><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>7256</xocs:filesize><xocs:pixel-height>136</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr7.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr7/THUMBNAIL/image/gif/d40f2fd5c5d99631854cb75f6b60dc30/gr7.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr7/THUMBNAIL/image/gif/d40f2fd5c5d99631854cb75f6b60dc30/gr7.sml</xocs:ucs-locator><xocs:file-basename>gr7</xocs:file-basename><xocs:filename>gr7.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>12234</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>209</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr8.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr8/THUMBNAIL/image/gif/1a44eae8410d801222ec27826e8edfa0/gr8.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr8/THUMBNAIL/image/gif/1a44eae8410d801222ec27826e8edfa0/gr8.sml</xocs:ucs-locator><xocs:file-basename>gr8</xocs:file-basename><xocs:filename>gr8.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>13524</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>152</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr9.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr9/THUMBNAIL/image/gif/7b5a8b48db774f77f909f836eba279f3/gr9.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr9/THUMBNAIL/image/gif/7b5a8b48db774f77f909f836eba279f3/gr9.sml</xocs:ucs-locator><xocs:file-basename>gr9</xocs:file-basename><xocs:filename>gr9.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>15283</xocs:filesize><xocs:pixel-height>164</xocs:pixel-height><xocs:pixel-width>152</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-fx1.sml</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/fx1/THUMBNAIL/image/gif/89b42895e6eefdea796bdf46753351db/fx1.sml</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/fx1/THUMBNAIL/image/gif/89b42895e6eefdea796bdf46753351db/fx1.sml</xocs:ucs-locator><xocs:file-basename>fx1</xocs:file-basename><xocs:abstract-attachment>true</xocs:abstract-attachment><xocs:filename>fx1.sml</xocs:filename><xocs:extension>sml</xocs:extension><xocs:filesize>13776</xocs:filesize><xocs:pixel-height>127</xocs:pixel-height><xocs:pixel-width>219</xocs:pixel-width><xocs:attachment-type>IMAGE-THUMBNAIL</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr1.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr1/DOWNSAMPLED/image/jpeg/ae8eaa707c5cd48096909e03f2b15232/gr1.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr1/DOWNSAMPLED/image/jpeg/ae8eaa707c5cd48096909e03f2b15232/gr1.jpg</xocs:ucs-locator><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>106669</xocs:filesize><xocs:pixel-height>566</xocs:pixel-height><xocs:pixel-width>713</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr10.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr10/DOWNSAMPLED/image/jpeg/4b8a0eebb9752c5f2d89f2ccac9e7dd2/gr10.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr10/DOWNSAMPLED/image/jpeg/4b8a0eebb9752c5f2d89f2ccac9e7dd2/gr10.jpg</xocs:ucs-locator><xocs:file-basename>gr10</xocs:file-basename><xocs:filename>gr10.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>112025</xocs:filesize><xocs:pixel-height>580</xocs:pixel-height><xocs:pixel-width>813</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr11.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr11/DOWNSAMPLED/image/jpeg/3511ead8dfcd410f5293f80d59b994ff/gr11.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr11/DOWNSAMPLED/image/jpeg/3511ead8dfcd410f5293f80d59b994ff/gr11.jpg</xocs:ucs-locator><xocs:file-basename>gr11</xocs:file-basename><xocs:filename>gr11.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>76946</xocs:filesize><xocs:pixel-height>364</xocs:pixel-height><xocs:pixel-width>562</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr2.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr2/DOWNSAMPLED/image/jpeg/653713862cdbd5e7d1977156ecdea36c/gr2.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr2/DOWNSAMPLED/image/jpeg/653713862cdbd5e7d1977156ecdea36c/gr2.jpg</xocs:ucs-locator><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>16063</xocs:filesize><xocs:pixel-height>121</xocs:pixel-height><xocs:pixel-width>282</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr3.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr3/DOWNSAMPLED/image/jpeg/598f26a8124633bf575fbdcad9e8fc26/gr3.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr3/DOWNSAMPLED/image/jpeg/598f26a8124633bf575fbdcad9e8fc26/gr3.jpg</xocs:ucs-locator><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>58346</xocs:filesize><xocs:pixel-height>289</xocs:pixel-height><xocs:pixel-width>605</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr4.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr4/DOWNSAMPLED/image/jpeg/feb0730bfd243dfa16bb2322c07279e1/gr4.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr4/DOWNSAMPLED/image/jpeg/feb0730bfd243dfa16bb2322c07279e1/gr4.jpg</xocs:ucs-locator><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>48486</xocs:filesize><xocs:pixel-height>275</xocs:pixel-height><xocs:pixel-width>579</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr5.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr5/DOWNSAMPLED/image/jpeg/ea06fc7ebc520da9d182c215e98d2da6/gr5.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr5/DOWNSAMPLED/image/jpeg/ea06fc7ebc520da9d182c215e98d2da6/gr5.jpg</xocs:ucs-locator><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>46191</xocs:filesize><xocs:pixel-height>305</xocs:pixel-height><xocs:pixel-width>565</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr6.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr6/DOWNSAMPLED/image/jpeg/04b16b04d6b298e6e542dfb1b88ba1f3/gr6.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr6/DOWNSAMPLED/image/jpeg/04b16b04d6b298e6e542dfb1b88ba1f3/gr6.jpg</xocs:ucs-locator><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>11873</xocs:filesize><xocs:pixel-height>150</xocs:pixel-height><xocs:pixel-width>243</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr7.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr7/DOWNSAMPLED/image/jpeg/63bd502946e1a5a5af57e1236775a3df/gr7.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr7/DOWNSAMPLED/image/jpeg/63bd502946e1a5a5af57e1236775a3df/gr7.jpg</xocs:ucs-locator><xocs:file-basename>gr7</xocs:file-basename><xocs:filename>gr7.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>94996</xocs:filesize><xocs:pixel-height>539</xocs:pixel-height><xocs:pixel-width>689</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr8.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr8/DOWNSAMPLED/image/jpeg/c9a376fe266f65b7b3810180adfe5160/gr8.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr8/DOWNSAMPLED/image/jpeg/c9a376fe266f65b7b3810180adfe5160/gr8.jpg</xocs:ucs-locator><xocs:file-basename>gr8</xocs:file-basename><xocs:filename>gr8.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>169884</xocs:filesize><xocs:pixel-height>876</xocs:pixel-height><xocs:pixel-width>812</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr9.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr9/DOWNSAMPLED/image/jpeg/b81bba295bd31bc3e2add22b8def6c68/gr9.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr9/DOWNSAMPLED/image/jpeg/b81bba295bd31bc3e2add22b8def6c68/gr9.jpg</xocs:ucs-locator><xocs:file-basename>gr9</xocs:file-basename><xocs:filename>gr9.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>194202</xocs:filesize><xocs:pixel-height>876</xocs:pixel-height><xocs:pixel-width>813</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-fx1.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/fx1/DOWNSAMPLED/image/jpeg/e4b80c0b7050ea1d6515f49d8921ae45/fx1.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/fx1/DOWNSAMPLED/image/jpeg/e4b80c0b7050ea1d6515f49d8921ae45/fx1.jpg</xocs:ucs-locator><xocs:file-basename>fx1</xocs:file-basename><xocs:abstract-attachment>true</xocs:abstract-attachment><xocs:filename>fx1.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>29001</xocs:filesize><xocs:pixel-height>200</xocs:pixel-height><xocs:pixel-width>346</xocs:pixel-width><xocs:attachment-type>IMAGE-DOWNSAMPLED</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr1_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr1/HIGHRES/image/jpeg/5c78929d1adca73bbd530e99cbf12b61/gr1_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr1/HIGHRES/image/jpeg/5c78929d1adca73bbd530e99cbf12b61/gr1_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr1</xocs:file-basename><xocs:filename>gr1_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>822257</xocs:filesize><xocs:pixel-height>2503</xocs:pixel-height><xocs:pixel-width>3155</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr10_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr10/HIGHRES/image/jpeg/de9675b0e8b10dc39c812459aed22a13/gr10_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr10/HIGHRES/image/jpeg/de9675b0e8b10dc39c812459aed22a13/gr10_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr10</xocs:file-basename><xocs:filename>gr10_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>764403</xocs:filesize><xocs:pixel-height>2566</xocs:pixel-height><xocs:pixel-width>3599</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr11_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr11/HIGHRES/image/jpeg/828549b0a4911d0817544f904f694846/gr11_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr11/HIGHRES/image/jpeg/828549b0a4911d0817544f904f694846/gr11_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr11</xocs:file-basename><xocs:filename>gr11_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>691996</xocs:filesize><xocs:pixel-height>1612</xocs:pixel-height><xocs:pixel-width>2490</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr2_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr2/HIGHRES/image/jpeg/f5b7f7897685db259548773f023a21f9/gr2_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr2/HIGHRES/image/jpeg/f5b7f7897685db259548773f023a21f9/gr2_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr2</xocs:file-basename><xocs:filename>gr2_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>109424</xocs:filesize><xocs:pixel-height>536</xocs:pixel-height><xocs:pixel-width>1250</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr3_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr3/HIGHRES/image/jpeg/b2ff00a5ff4401fe31d951693aa16369/gr3_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr3/HIGHRES/image/jpeg/b2ff00a5ff4401fe31d951693aa16369/gr3_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr3</xocs:file-basename><xocs:filename>gr3_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>560169</xocs:filesize><xocs:pixel-height>1279</xocs:pixel-height><xocs:pixel-width>2681</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr4_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr4/HIGHRES/image/jpeg/5e408bf033a54339b33d07c1a8d0bf92/gr4_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr4/HIGHRES/image/jpeg/5e408bf033a54339b33d07c1a8d0bf92/gr4_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr4</xocs:file-basename><xocs:filename>gr4_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>471347</xocs:filesize><xocs:pixel-height>1216</xocs:pixel-height><xocs:pixel-width>2564</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr5_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr5/HIGHRES/image/jpeg/01b115d2b7527ba46fe63cf45e9eea7e/gr5_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr5/HIGHRES/image/jpeg/01b115d2b7527ba46fe63cf45e9eea7e/gr5_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr5</xocs:file-basename><xocs:filename>gr5_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>320588</xocs:filesize><xocs:pixel-height>1351</xocs:pixel-height><xocs:pixel-width>2501</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr6_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr6/HIGHRES/image/jpeg/86e44ffe6d43c763e8ceab529495cc00/gr6_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr6/HIGHRES/image/jpeg/86e44ffe6d43c763e8ceab529495cc00/gr6_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr6</xocs:file-basename><xocs:filename>gr6_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>60067</xocs:filesize><xocs:pixel-height>668</xocs:pixel-height><xocs:pixel-width>1079</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr7_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr7/HIGHRES/image/jpeg/eff5bc0755789adf25005941b5c62b9f/gr7_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr7/HIGHRES/image/jpeg/eff5bc0755789adf25005941b5c62b9f/gr7_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr7</xocs:file-basename><xocs:filename>gr7_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>846352</xocs:filesize><xocs:pixel-height>2389</xocs:pixel-height><xocs:pixel-width>3053</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr8_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr8/HIGHRES/image/jpeg/bdbc10baaa54f0206c288f7ffaee627d/gr8_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr8/HIGHRES/image/jpeg/bdbc10baaa54f0206c288f7ffaee627d/gr8_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr8</xocs:file-basename><xocs:filename>gr8_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>1175743</xocs:filesize><xocs:pixel-height>3879</xocs:pixel-height><xocs:pixel-width>3597</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-gr9_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/gr9/HIGHRES/image/jpeg/94412fad050bab0ca8c44f61f81b162e/gr9_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/gr9/HIGHRES/image/jpeg/94412fad050bab0ca8c44f61f81b162e/gr9_lrg.jpg</xocs:ucs-locator><xocs:file-basename>gr9</xocs:file-basename><xocs:filename>gr9_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>1356006</xocs:filesize><xocs:pixel-height>3881</xocs:pixel-height><xocs:pixel-width>3600</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-fx1_lrg.jpg</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/fx1/HIGHRES/image/jpeg/27c7239803fc0ed17129b5533f4c8099/fx1_lrg.jpg</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/fx1/HIGHRES/image/jpeg/27c7239803fc0ed17129b5533f4c8099/fx1_lrg.jpg</xocs:ucs-locator><xocs:file-basename>fx1</xocs:file-basename><xocs:abstract-attachment>true</xocs:abstract-attachment><xocs:filename>fx1_lrg.jpg</xocs:filename><xocs:extension>jpg</xocs:extension><xocs:filesize>255818</xocs:filesize><xocs:pixel-height>886</xocs:pixel-height><xocs:pixel-width>1532</xocs:pixel-width><xocs:attachment-type>IMAGE-HIGH-RES</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-mmc1.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/mmc1/MAIN/application/pdf/da65d61f8e25c6ef9ddd900ef385e579/mmc1.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/mmc1/MAIN/application/pdf/da65d61f8e25c6ef9ddd900ef385e579/mmc1.pdf</xocs:ucs-locator><xocs:file-basename>mmc1</xocs:file-basename><xocs:filename>mmc1.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>false</xocs:pdf-optimized><xocs:filesize>80064</xocs:filesize><xocs:attachment-type>APPLICATION</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si33.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/875f6ee81c4ab57643b40780cf3ace0c/si33.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/875f6ee81c4ab57643b40780cf3ace0c/si33.gif</xocs:ucs-locator><xocs:file-basename>si33</xocs:file-basename><xocs:filename>si33.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>326</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>39</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si20.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6547e750919919de072c7978d8f41122/si20.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6547e750919919de072c7978d8f41122/si20.gif</xocs:ucs-locator><xocs:file-basename>si20</xocs:file-basename><xocs:filename>si20.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>221</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>23</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si30.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/afda07ac33eb2a05a5314e3ce3f695bf/si30.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/afda07ac33eb2a05a5314e3ce3f695bf/si30.gif</xocs:ucs-locator><xocs:file-basename>si30</xocs:file-basename><xocs:filename>si30.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>680</xocs:filesize><xocs:pixel-height>25</xocs:pixel-height><xocs:pixel-width>127</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si40.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/17ff4d4f1cfd2dae5b2750f9968ba881/si40.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/17ff4d4f1cfd2dae5b2750f9968ba881/si40.gif</xocs:ucs-locator><xocs:file-basename>si40</xocs:file-basename><xocs:filename>si40.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>459</xocs:filesize><xocs:pixel-height>26</xocs:pixel-height><xocs:pixel-width>50</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si50.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/0aa27c6ed0278bfb14bcb90b564b87d8/si50.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/0aa27c6ed0278bfb14bcb90b564b87d8/si50.gif</xocs:ucs-locator><xocs:file-basename>si50</xocs:file-basename><xocs:filename>si50.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>459</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>81</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si60.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/5ace11594f052bb946cdc7b0e4684c4e/si60.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/5ace11594f052bb946cdc7b0e4684c4e/si60.gif</xocs:ucs-locator><xocs:file-basename>si60</xocs:file-basename><xocs:filename>si60.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>188</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>24</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si70.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/e473e14a9b3515008b711a9dea534953/si70.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/e473e14a9b3515008b711a9dea534953/si70.gif</xocs:ucs-locator><xocs:file-basename>si70</xocs:file-basename><xocs:filename>si70.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>969</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>261</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si9.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6a3f051eb30297d5772a83032e54e230/si9.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6a3f051eb30297d5772a83032e54e230/si9.gif</xocs:ucs-locator><xocs:file-basename>si9</xocs:file-basename><xocs:filename>si9.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>177</xocs:filesize><xocs:pixel-height>13</xocs:pixel-height><xocs:pixel-width>44</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si71.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6cb845e2c525079cdfa130124bc0dcc5/si71.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6cb845e2c525079cdfa130124bc0dcc5/si71.gif</xocs:ucs-locator><xocs:file-basename>si71</xocs:file-basename><xocs:filename>si71.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>253</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>41</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si1.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/75620ff823cf917f3faa4b9660ee18cb/si1.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/75620ff823cf917f3faa4b9660ee18cb/si1.gif</xocs:ucs-locator><xocs:file-basename>si1</xocs:file-basename><xocs:filename>si1.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>259</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>25</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si11.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/64ef25c2b9025b001d4de29b8c705aa5/si11.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/64ef25c2b9025b001d4de29b8c705aa5/si11.gif</xocs:ucs-locator><xocs:file-basename>si11</xocs:file-basename><xocs:filename>si11.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>203</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>17</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si12.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/d8dc2a56371aedfd649c2369b44e7d91/si12.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/d8dc2a56371aedfd649c2369b44e7d91/si12.gif</xocs:ucs-locator><xocs:file-basename>si12</xocs:file-basename><xocs:filename>si12.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>206</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si13.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/647eb4208cbece13f8623708160dea10/si13.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/647eb4208cbece13f8623708160dea10/si13.gif</xocs:ucs-locator><xocs:file-basename>si13</xocs:file-basename><xocs:filename>si13.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>52</xocs:filesize><xocs:pixel-height>1</xocs:pixel-height><xocs:pixel-width>14</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si14.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/5443fc6ae265e858bd1e54d7687672b8/si14.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/5443fc6ae265e858bd1e54d7687672b8/si14.gif</xocs:ucs-locator><xocs:file-basename>si14</xocs:file-basename><xocs:filename>si14.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>179</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>17</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si15.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/0f4c032a9e2142fc77d74dcaceec1590/si15.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/0f4c032a9e2142fc77d74dcaceec1590/si15.gif</xocs:ucs-locator><xocs:file-basename>si15</xocs:file-basename><xocs:filename>si15.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>188</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>20</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si16.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/4226422097dee29d08e64fd3851ef654/si16.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/4226422097dee29d08e64fd3851ef654/si16.gif</xocs:ucs-locator><xocs:file-basename>si16</xocs:file-basename><xocs:filename>si16.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>143</xocs:filesize><xocs:pixel-height>13</xocs:pixel-height><xocs:pixel-width>12</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si17.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6bb05b41c0140744af2b565c11770638/si17.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6bb05b41c0140744af2b565c11770638/si17.gif</xocs:ucs-locator><xocs:file-basename>si17</xocs:file-basename><xocs:filename>si17.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>273</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>48</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si18.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/9b1bb2b17cea0843e6a547c1936b3ede/si18.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/9b1bb2b17cea0843e6a547c1936b3ede/si18.gif</xocs:ucs-locator><xocs:file-basename>si18</xocs:file-basename><xocs:filename>si18.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>454</xocs:filesize><xocs:pixel-height>22</xocs:pixel-height><xocs:pixel-width>89</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si19.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/c1cf48f98a3e07f1769aadbae086ed2a/si19.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/c1cf48f98a3e07f1769aadbae086ed2a/si19.gif</xocs:ucs-locator><xocs:file-basename>si19</xocs:file-basename><xocs:filename>si19.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>379</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>65</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si2.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/7ac9dc33983935e8973ff49c933428c9/si2.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/7ac9dc33983935e8973ff49c933428c9/si2.gif</xocs:ucs-locator><xocs:file-basename>si2</xocs:file-basename><xocs:filename>si2.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>187</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si21.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/a5083e4bf6b7a77ec0dde8b41bf26439/si21.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/a5083e4bf6b7a77ec0dde8b41bf26439/si21.gif</xocs:ucs-locator><xocs:file-basename>si21</xocs:file-basename><xocs:filename>si21.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>182</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>21</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si22.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/726415657f1d8fd9334cf6a36cb1865c/si22.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/726415657f1d8fd9334cf6a36cb1865c/si22.gif</xocs:ucs-locator><xocs:file-basename>si22</xocs:file-basename><xocs:filename>si22.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>233</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>25</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si23.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/d93e874cdd34376e2974e839a5bbdb75/si23.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/d93e874cdd34376e2974e839a5bbdb75/si23.gif</xocs:ucs-locator><xocs:file-basename>si23</xocs:file-basename><xocs:filename>si23.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>431</xocs:filesize><xocs:pixel-height>22</xocs:pixel-height><xocs:pixel-width>84</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si24.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/da1707b239f4e7f5a098966f4cf33978/si24.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/da1707b239f4e7f5a098966f4cf33978/si24.gif</xocs:ucs-locator><xocs:file-basename>si24</xocs:file-basename><xocs:filename>si24.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1812</xocs:filesize><xocs:pixel-height>44</xocs:pixel-height><xocs:pixel-width>380</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si3.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/e2f81547bec451b0af31b2c2d54d4272/si3.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/e2f81547bec451b0af31b2c2d54d4272/si3.gif</xocs:ucs-locator><xocs:file-basename>si3</xocs:file-basename><xocs:filename>si3.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>195</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si25.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/ca072aa3d86b9df861cedfa450681aa0/si25.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/ca072aa3d86b9df861cedfa450681aa0/si25.gif</xocs:ucs-locator><xocs:file-basename>si25</xocs:file-basename><xocs:filename>si25.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>795</xocs:filesize><xocs:pixel-height>22</xocs:pixel-height><xocs:pixel-width>198</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si26.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/484469afb3c4db39f5a270d250de1c79/si26.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/484469afb3c4db39f5a270d250de1c79/si26.gif</xocs:ucs-locator><xocs:file-basename>si26</xocs:file-basename><xocs:filename>si26.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>372</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>74</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si27.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/2f0f86e5dacf90640825b8d55a6715ec/si27.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/2f0f86e5dacf90640825b8d55a6715ec/si27.gif</xocs:ucs-locator><xocs:file-basename>si27</xocs:file-basename><xocs:filename>si27.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>212</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>43</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si28.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/9114d3cb7408bc7637f74c35d8b5e19a/si28.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/9114d3cb7408bc7637f74c35d8b5e19a/si28.gif</xocs:ucs-locator><xocs:file-basename>si28</xocs:file-basename><xocs:filename>si28.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1556</xocs:filesize><xocs:pixel-height>33</xocs:pixel-height><xocs:pixel-width>299</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si29.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/664adab7635ce4651720886fa15b9bbf/si29.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/664adab7635ce4651720886fa15b9bbf/si29.gif</xocs:ucs-locator><xocs:file-basename>si29</xocs:file-basename><xocs:filename>si29.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1230</xocs:filesize><xocs:pixel-height>46</xocs:pixel-height><xocs:pixel-width>236</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si31.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/88c62088852d3b24b47097a2471c9d5c/si31.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/88c62088852d3b24b47097a2471c9d5c/si31.gif</xocs:ucs-locator><xocs:file-basename>si31</xocs:file-basename><xocs:filename>si31.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1493</xocs:filesize><xocs:pixel-height>57</xocs:pixel-height><xocs:pixel-width>254</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si32.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/53ea1d65e5384c4f9d36e7a5cd993f01/si32.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/53ea1d65e5384c4f9d36e7a5cd993f01/si32.gif</xocs:ucs-locator><xocs:file-basename>si32</xocs:file-basename><xocs:filename>si32.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>318</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>84</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si34.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/88a263fb00bfb665ab9da38251c24690/si34.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/88a263fb00bfb665ab9da38251c24690/si34.gif</xocs:ucs-locator><xocs:file-basename>si34</xocs:file-basename><xocs:filename>si34.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>159</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>16</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si35.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/85685b813557ce0da007507fd228a708/si35.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/85685b813557ce0da007507fd228a708/si35.gif</xocs:ucs-locator><xocs:file-basename>si35</xocs:file-basename><xocs:filename>si35.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>190</xocs:filesize><xocs:pixel-height>18</xocs:pixel-height><xocs:pixel-width>19</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si36.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/56372774153a8c758e64001270ca84ad/si36.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/56372774153a8c758e64001270ca84ad/si36.gif</xocs:ucs-locator><xocs:file-basename>si36</xocs:file-basename><xocs:filename>si36.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>349</xocs:filesize><xocs:pixel-height>25</xocs:pixel-height><xocs:pixel-width>50</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si37.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/7cf723b59a1f648d4b5b2b9ed995348a/si37.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/7cf723b59a1f648d4b5b2b9ed995348a/si37.gif</xocs:ucs-locator><xocs:file-basename>si37</xocs:file-basename><xocs:filename>si37.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>350</xocs:filesize><xocs:pixel-height>27</xocs:pixel-height><xocs:pixel-width>49</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si38.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/9e68f62de973d553b1c682ec6a6f89d3/si38.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/9e68f62de973d553b1c682ec6a6f89d3/si38.gif</xocs:ucs-locator><xocs:file-basename>si38</xocs:file-basename><xocs:filename>si38.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>334</xocs:filesize><xocs:pixel-height>25</xocs:pixel-height><xocs:pixel-width>49</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si39.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/5c31337b7d2ceb087ad07a265959720e/si39.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/5c31337b7d2ceb087ad07a265959720e/si39.gif</xocs:ucs-locator><xocs:file-basename>si39</xocs:file-basename><xocs:filename>si39.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>345</xocs:filesize><xocs:pixel-height>27</xocs:pixel-height><xocs:pixel-width>48</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si4.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/100ccb93fdf7830fb05413b9cdade3a1/si4.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/100ccb93fdf7830fb05413b9cdade3a1/si4.gif</xocs:ucs-locator><xocs:file-basename>si4</xocs:file-basename><xocs:filename>si4.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>180</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>19</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si41.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/a11addff0fac71923f621f0e94e57ec6/si41.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/a11addff0fac71923f621f0e94e57ec6/si41.gif</xocs:ucs-locator><xocs:file-basename>si41</xocs:file-basename><xocs:filename>si41.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>473</xocs:filesize><xocs:pixel-height>26</xocs:pixel-height><xocs:pixel-width>56</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si42.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/d56907c9b052a6fa42ad26b199ec934a/si42.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/d56907c9b052a6fa42ad26b199ec934a/si42.gif</xocs:ucs-locator><xocs:file-basename>si42</xocs:file-basename><xocs:filename>si42.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>3030</xocs:filesize><xocs:pixel-height>87</xocs:pixel-height><xocs:pixel-width>434</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si43.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/5f3530f679add838524db78b3529bf2c/si43.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/5f3530f679add838524db78b3529bf2c/si43.gif</xocs:ucs-locator><xocs:file-basename>si43</xocs:file-basename><xocs:filename>si43.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>347</xocs:filesize><xocs:pixel-height>25</xocs:pixel-height><xocs:pixel-width>50</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si44.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/bcc4b0a3b821998c5736338aed87de80/si44.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/bcc4b0a3b821998c5736338aed87de80/si44.gif</xocs:ucs-locator><xocs:file-basename>si44</xocs:file-basename><xocs:filename>si44.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>335</xocs:filesize><xocs:pixel-height>26</xocs:pixel-height><xocs:pixel-width>38</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si45.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/fd25b02a0ccdc91594259bac33480033/si45.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/fd25b02a0ccdc91594259bac33480033/si45.gif</xocs:ucs-locator><xocs:file-basename>si45</xocs:file-basename><xocs:filename>si45.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1401</xocs:filesize><xocs:pixel-height>27</xocs:pixel-height><xocs:pixel-width>326</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si46.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/65710e70a7a3d0f386ebebdf1861263f/si46.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/65710e70a7a3d0f386ebebdf1861263f/si46.gif</xocs:ucs-locator><xocs:file-basename>si46</xocs:file-basename><xocs:filename>si46.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>536</xocs:filesize><xocs:pixel-height>27</xocs:pixel-height><xocs:pixel-width>99</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si47.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/102c2556086f97c6d1c5d11c28328e21/si47.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/102c2556086f97c6d1c5d11c28328e21/si47.gif</xocs:ucs-locator><xocs:file-basename>si47</xocs:file-basename><xocs:filename>si47.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>168</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si48.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/5bffadca3adba45e79769de44d658837/si48.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/5bffadca3adba45e79769de44d658837/si48.gif</xocs:ucs-locator><xocs:file-basename>si48</xocs:file-basename><xocs:filename>si48.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>185</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>20</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si49.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/20156da004dc20826f646532cef38de4/si49.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/20156da004dc20826f646532cef38de4/si49.gif</xocs:ucs-locator><xocs:file-basename>si49</xocs:file-basename><xocs:filename>si49.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>177</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si5.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/105a945cba3e04fef5b495c12ca0bd3a/si5.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/105a945cba3e04fef5b495c12ca0bd3a/si5.gif</xocs:ucs-locator><xocs:file-basename>si5</xocs:file-basename><xocs:filename>si5.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>443</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>76</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si51.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/15e7a3d4b5e1ac3748c5470341e6cc7d/si51.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/15e7a3d4b5e1ac3748c5470341e6cc7d/si51.gif</xocs:ucs-locator><xocs:file-basename>si51</xocs:file-basename><xocs:filename>si51.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>440</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>75</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si52.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/8377d00caeb5dea3149cd329d5c7a736/si52.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/8377d00caeb5dea3149cd329d5c7a736/si52.gif</xocs:ucs-locator><xocs:file-basename>si52</xocs:file-basename><xocs:filename>si52.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>408</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>67</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si53.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/d3d885ab4da6cb01f6c58577e8eb6785/si53.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/d3d885ab4da6cb01f6c58577e8eb6785/si53.gif</xocs:ucs-locator><xocs:file-basename>si53</xocs:file-basename><xocs:filename>si53.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>398</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>67</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si54.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/7e5ee5337ea6e936fec41bac2be06c17/si54.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/7e5ee5337ea6e936fec41bac2be06c17/si54.gif</xocs:ucs-locator><xocs:file-basename>si54</xocs:file-basename><xocs:filename>si54.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>321</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>41</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si55.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/eeb566baac96a79a7d54a4fd90a55f74/si55.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/eeb566baac96a79a7d54a4fd90a55f74/si55.gif</xocs:ucs-locator><xocs:file-basename>si55</xocs:file-basename><xocs:filename>si55.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>304</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>41</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si56.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/699f06eb27cb0b58d519e31a5a9ff7db/si56.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/699f06eb27cb0b58d519e31a5a9ff7db/si56.gif</xocs:ucs-locator><xocs:file-basename>si56</xocs:file-basename><xocs:filename>si56.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>328</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>39</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si57.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/d257aebee8f6724c1ee9ad591b0b181b/si57.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/d257aebee8f6724c1ee9ad591b0b181b/si57.gif</xocs:ucs-locator><xocs:file-basename>si57</xocs:file-basename><xocs:filename>si57.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>323</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>47</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si58.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/470dfde203466b6b13766173d4b83c15/si58.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/470dfde203466b6b13766173d4b83c15/si58.gif</xocs:ucs-locator><xocs:file-basename>si58</xocs:file-basename><xocs:filename>si58.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>446</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>81</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si59.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6ee770c8cdfc7d413168c9dfd81a9ec1/si59.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6ee770c8cdfc7d413168c9dfd81a9ec1/si59.gif</xocs:ucs-locator><xocs:file-basename>si59</xocs:file-basename><xocs:filename>si59.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>410</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>68</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si6.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/8bb2a4fe7c5dc86a3c271b8d21f3bb90/si6.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/8bb2a4fe7c5dc86a3c271b8d21f3bb90/si6.gif</xocs:ucs-locator><xocs:file-basename>si6</xocs:file-basename><xocs:filename>si6.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>272</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>56</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si61.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/9d9f9e67a69c9bc269eb3dc9e14b2af7/si61.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/9d9f9e67a69c9bc269eb3dc9e14b2af7/si61.gif</xocs:ucs-locator><xocs:file-basename>si61</xocs:file-basename><xocs:filename>si61.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>435</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>76</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si62.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/32f89e5dd23c25385c613d7235aa9ca4/si62.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/32f89e5dd23c25385c613d7235aa9ca4/si62.gif</xocs:ucs-locator><xocs:file-basename>si62</xocs:file-basename><xocs:filename>si62.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>1096</xocs:filesize><xocs:pixel-height>57</xocs:pixel-height><xocs:pixel-width>166</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si63.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/68d9f856afd2621bedad5c685874d6a3/si63.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/68d9f856afd2621bedad5c685874d6a3/si63.gif</xocs:ucs-locator><xocs:file-basename>si63</xocs:file-basename><xocs:filename>si63.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>398</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>42</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si64.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/cccd02b540764b54285a75ed21f75842/si64.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/cccd02b540764b54285a75ed21f75842/si64.gif</xocs:ucs-locator><xocs:file-basename>si64</xocs:file-basename><xocs:filename>si64.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>203</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si65.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/6a2394082e555377fdca0034e4cd7e20/si65.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/6a2394082e555377fdca0034e4cd7e20/si65.gif</xocs:ucs-locator><xocs:file-basename>si65</xocs:file-basename><xocs:filename>si65.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>278</xocs:filesize><xocs:pixel-height>26</xocs:pixel-height><xocs:pixel-width>61</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si66.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/735903c55b1b42f5d89485827a26fbe2/si66.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/735903c55b1b42f5d89485827a26fbe2/si66.gif</xocs:ucs-locator><xocs:file-basename>si66</xocs:file-basename><xocs:filename>si66.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>280</xocs:filesize><xocs:pixel-height>23</xocs:pixel-height><xocs:pixel-width>35</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si67.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/4752ced358053e0a43758f96cfa386b3/si67.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/4752ced358053e0a43758f96cfa386b3/si67.gif</xocs:ucs-locator><xocs:file-basename>si67</xocs:file-basename><xocs:filename>si67.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>321</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>84</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si68.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/13b8b9a24f0a04e862f1e4152c692139/si68.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/13b8b9a24f0a04e862f1e4152c692139/si68.gif</xocs:ucs-locator><xocs:file-basename>si68</xocs:file-basename><xocs:filename>si68.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>674</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>199</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si69.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/910537f17f9b3403348ec7717f0a7468/si69.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/910537f17f9b3403348ec7717f0a7468/si69.gif</xocs:ucs-locator><xocs:file-basename>si69</xocs:file-basename><xocs:filename>si69.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>636</xocs:filesize><xocs:pixel-height>19</xocs:pixel-height><xocs:pixel-width>137</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si7.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/42aeed66e43bb091742a6928bba5cf79/si7.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/42aeed66e43bb091742a6928bba5cf79/si7.gif</xocs:ucs-locator><xocs:file-basename>si7</xocs:file-basename><xocs:filename>si7.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>267</xocs:filesize><xocs:pixel-height>17</xocs:pixel-height><xocs:pixel-width>54</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si72.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/c1591d683aed648dd1d9d75416fc7420/si72.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/c1591d683aed648dd1d9d75416fc7420/si72.gif</xocs:ucs-locator><xocs:file-basename>si72</xocs:file-basename><xocs:filename>si72.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>330</xocs:filesize><xocs:pixel-height>13</xocs:pixel-height><xocs:pixel-width>81</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si73.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/40a44c9a11abaaa866092c3cb75bc208/si73.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/40a44c9a11abaaa866092c3cb75bc208/si73.gif</xocs:ucs-locator><xocs:file-basename>si73</xocs:file-basename><xocs:filename>si73.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>306</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>83</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si10.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/801088928df7eba48e922bcdd625019f/si10.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/801088928df7eba48e922bcdd625019f/si10.gif</xocs:ucs-locator><xocs:file-basename>si10</xocs:file-basename><xocs:filename>si10.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>195</xocs:filesize><xocs:pixel-height>16</xocs:pixel-height><xocs:pixel-width>24</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si74.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/2b7c17b154715d0b69155323c1288823/si74.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/2b7c17b154715d0b69155323c1288823/si74.gif</xocs:ucs-locator><xocs:file-basename>si74</xocs:file-basename><xocs:filename>si74.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>295</xocs:filesize><xocs:pixel-height>15</xocs:pixel-height><xocs:pixel-width>77</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment><xocs:attachment><xocs:attachment-eid>1-s2.0-S1361841516300822-si8.gif</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1361841516300822/STRIPIN/image/gif/57d330b591f81fb38b26c07fe73a236e/si8.gif</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1361841516300822/STRIPIN/image/gif/57d330b591f81fb38b26c07fe73a236e/si8.gif</xocs:ucs-locator><xocs:file-basename>si8</xocs:file-basename><xocs:filename>si8.gif</xocs:filename><xocs:extension>gif</xocs:extension><xocs:filesize>196</xocs:filesize><xocs:pixel-height>24</xocs:pixel-height><xocs:pixel-width>18</xocs:pixel-width><xocs:attachment-type>ALTIMG</xocs:attachment-type></xocs:attachment></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" docsubtype="fla" xml:lang="en" version="5.4"><item-info><jid>MEDIMA</jid><aid>1124</aid><ce:pii>S1361-8415(16)30082-2</ce:pii><ce:doi>10.1016/j.media.2016.06.005</ce:doi><ce:copyright type="other" year="2016">The Authors</ce:copyright></item-info><ce:floats><ce:figure id="fig0001"><ce:label>Fig. 1</ce:label><ce:caption id="cap0001"><ce:simple-para id="spara0008" view="all">Schematic representation of (a) the traditional subject-specific motion model paradigm and (b) our autoadaptive subject-specific motion model allowing for continuous adaptivity to changing breathing patterns. The red arrow indicates our proposed change to the motion model paradigm allowing for new surrogate/calibration data to be incorporated into the motion model without interrupting the application phase. In this new paradigm the model is initially formed pre-treatment, but is updated continually during the treatment.</ce:simple-para></ce:caption><ce:alt-text id="at0001" role="short">Fig. 1</ce:alt-text><ce:link id="celink0001" locator="gr1" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr1"/></ce:figure><ce:figure id="fig0002"><ce:label>Fig. 2</ce:label><ce:caption id="cap0002"><ce:simple-para id="spara0009" view="all">Graph sparsification of similarity kernel <ce:italic>U<ce:inf loc="post">pq</ce:inf></ce:italic>. The two columns of circles in (a) and (b) represent all the data points acquired from the respective slice positions <ce:italic>p</ce:italic> and <ce:italic>q</ce:italic>. (a) shows a fully connected similarity kernel where all of the edges <mml:math altimg="si1.gif" overflow="scroll"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math> exist. (b) shows the sparsified similarity kernel where each <mml:math altimg="si2.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> is connected to exactly one <mml:math altimg="si3.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math> and the sum over the remaining edge weights <mml:math altimg="si1.gif" overflow="scroll"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math> is maximised.</ce:simple-para></ce:caption><ce:alt-text id="at0002" role="short">Fig. 2</ce:alt-text><ce:link id="celink0002" locator="gr2" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr2"/></ce:figure><ce:figure id="fig0003"><ce:label>Fig. 3</ce:label><ce:caption id="cap0003"><ce:simple-para id="spara0010" view="all">Schematic of group connections through simultaneous manifold embeddings. Motion fields from neighbouring and orthogonal slices can be embedded simultaneously using appropriate similarity kernels leading to aligned embeddings. Two close-up views of aligned manifold embeddings, originating from a dataset with 50 motion fields per slice position, are shown on the right hand side.</ce:simple-para></ce:caption><ce:alt-text id="at0003" role="short">Fig. 3</ce:alt-text><ce:link id="celink0003" locator="gr3" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr3"/></ce:figure><ce:figure id="fig0004"><ce:label>Fig. 4</ce:label><ce:caption id="cap0004"><ce:simple-para id="spara0011" view="all">Derivation of similarity kernel based on motion in slice overlap. (a) Illustration of the overlap of two orthogonal slices, (b) S-I motion components derived from the overlapping area from a coronal (left) and sagittal (right) slice position. We show two possible S-I motion components originating from the sagittal slice: One that is similar to the one derived from the coronal slice (blue) and hence corresponds to a similar motion state, and one that is dissimilar (red) and consequently corresponds to a different motion state . (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</ce:simple-para></ce:caption><ce:alt-text id="at0004" role="short">Fig. 4</ce:alt-text><ce:link id="celink0004" locator="gr4" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr4"/></ce:figure><ce:figure id="fig0005"><ce:label>Fig. 5</ce:label><ce:caption id="cap0005"><ce:simple-para id="spara0012" view="all">Schematic of the connection of slice positions by means of pairwise embedding and propagation of respiratory information through the manifolds. Assuming a new input slice at <mml:math altimg="si4.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math> the neighbouring groups can be directly updated as indicated by the squares with yellow background. Then through a combination of nearest neighbour searches (dotted arrows) and group transitions based on shared data (solid arrows) low-dimensional coordinates, which correspond to the respiratory state, can be propagated to all remaining slice positions. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</ce:simple-para></ce:caption><ce:alt-text id="at0005" role="short">Fig. 5</ce:alt-text><ce:link id="celink0005" locator="gr5" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr5"/></ce:figure><ce:figure id="fig0006"><ce:label>Fig. 6</ce:label><ce:caption id="cap0006"><ce:simple-para id="spara0013" view="all">Close-up view of the right-hand side of group <mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> in <ce:cross-ref id="crf0001" refid="fig0005">Fig. 5</ce:cross-ref>. Here <mml:math altimg="si6.gif" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math> and <mml:math altimg="si7.gif" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math>. In addition to the nearest neighbour in the manifold embedding <mml:math altimg="si8.gif" overflow="scroll"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> (blue dot in solid circle), the figure shows the other <mml:math altimg="si9.gif" overflow="scroll"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> nearest neighbours (blue dots in dotted circles), the original point belonging to the manifold of <mml:math altimg="si10.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> i.e. <mml:math altimg="si11.gif" overflow="scroll"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math> (red dot in yellow box), and the distances <ce:italic>ω<ce:inf loc="post">i</ce:inf></ce:italic> from which the similarities <ce:italic>s<ce:inf loc="post">i</ce:inf></ce:italic> are derived. The similarities are then used to form a weighted average of the corresponding motion fields. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</ce:simple-para></ce:caption><ce:alt-text id="at0006" role="short">Fig. 6</ce:alt-text><ce:link id="celink0006" locator="gr6" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr6"/></ce:figure><ce:figure id="fig0007"><ce:label>Fig. 7</ce:label><ce:caption id="cap0007"><ce:simple-para id="spara0014" view="all">Generation of synthetic slice-by-slice data. (a) Generation of ground truth motion fields from a 3D low-resolution MR scan, (b) generation of synthetic slice-by-slice data by applying the ground truth motion to slice data acquired at end-exhale. The procedure was performed twice, once for normal breathing data and once for deep breathing data.</ce:simple-para></ce:caption><ce:alt-text id="at0007" role="short">Fig. 7</ce:alt-text><ce:link id="celink0007" locator="gr7" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr7"/></ce:figure><ce:figure id="fig0008"><ce:label>Fig. 8</ce:label><ce:caption id="cap0008"><ce:simple-para id="spara0015" view="all">Results of synthetic validation on normal breathing data. The figure shows average 3D motion estimation errors in mm for all volunteers over the entire duration of the synthetic application phase.</ce:simple-para></ce:caption><ce:alt-text id="at0008" role="short">Fig. 8</ce:alt-text><ce:link id="celink0008" locator="gr8" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr8"/></ce:figure><ce:figure id="fig0009"><ce:label>Fig. 9</ce:label><ce:caption id="cap0009"><ce:simple-para id="spara0016" view="all">Average 3D motion estimation errors in mm for all volunteers over the entire duration of the synthetic application phase when the breathing type was changed to deep breathing. The entire interval shown contains only deep breathing.</ce:simple-para></ce:caption><ce:alt-text id="at0009" role="short">Fig. 9</ce:alt-text><ce:link id="celink0009" locator="gr9" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr9"/></ce:figure><ce:figure id="fig0010"><ce:label>Fig. 10</ce:label><ce:caption id="cap0010"><ce:simple-para id="spara0017" view="all">NCC of pencil beam navigator with a navigator signal derived from volume deformed using a 3D motion estimation provided by each of the three investigated methods over time.</ce:simple-para></ce:caption><ce:alt-text id="at0010" role="short">Fig. 10</ce:alt-text><ce:link id="celink0010" locator="gr10" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr10"/></ce:figure><ce:figure id="fig0011"><ce:label>Fig. 11</ce:label><ce:caption id="cap0011"><ce:simple-para id="spara0018" view="all">Example of the pencil beam navigator signal acquired for validation for volunteer III (top row) and navigator estimations produced by AAMM (no adapt.) (middle row) and AAMM (bottom row). The original pencil beam navigator is underlaid in grey for comparison. We show the entire time interval including the approximately 5 min of the calibration scan, and the approximately 15 min of model application. All signals have been normalised by subtracting the mean signal value such that the pencil beam navigator signal and the estimated signals can be visually compared.</ce:simple-para></ce:caption><ce:alt-text id="at0011" role="short">Fig. 11</ce:alt-text><ce:link id="celink0011" locator="gr11" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/gr11"/></ce:figure><ce:table xmlns="http://www.elsevier.com/xml/common/cals/dtd" id="tbl0001" rowsep="0" colsep="0" frame="topbot"><ce:label>Table 1</ce:label><ce:caption id="cap0012"><ce:simple-para id="spara0019" view="all">List of frequently used mathematical notations in this paper.</ce:simple-para></ce:caption><ce:alt-text id="at0012" role="short">Table 1</ce:alt-text><tgroup cols="3"><colspec colnum="1" colname="col1" align="left"/><colspec colnum="2" colname="col2" align="left"/><colspec colnum="3" colname="col3" align="left"/><thead><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead" align="left">Variable</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead" align="left">Size</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead" align="left">Description</entry></row></thead><tbody><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><mml:math altimg="si13.gif" overflow="scroll"><mml:mo>−</mml:mo></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">The <italic>i</italic>-th 2D MR image acquired at slice position <italic>p</italic>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><mml:math altimg="si13.gif" overflow="scroll"><mml:mo>−</mml:mo></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">2D motion field derived by registering <mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> to an exhale slice.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>D</italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">1</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">The dimensionality of the input data, i.e. the number of pixels in one slice (in <cross-ref id="crf0002" refid="sec0004">Section 2</cross-ref>), or the total number of motion components (in <cross-ref id="crf0003" refid="sec0008">Section 3</cross-ref>).</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>d</italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">1</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">The dimensionality to which the data gets reduced in the manifold alignment step.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>τ<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">1</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Total number of slices acquired from slice position <italic>p</italic> at a specific time of the application phase.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si2.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>D</italic> × 1</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Vectorised image <mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> (in <cross-ref id="crf0004" refid="sec0004">Section 2</cross-ref>), or vectorised motion field <mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> (in <cross-ref id="crf0005" refid="sec0008">Section 3</cross-ref>).</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>X<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>D</italic> × <italic>τ<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Matrix containing <italic>τ<inf loc="post">p</inf></italic> vectorised data points <mml:math altimg="si2.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si8.gif" overflow="scroll"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>d</italic> × 1</entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Low-dimensional point corresponding to <mml:math altimg="si2.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>Y<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>d</italic> × <italic>τ<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Matrix containing <italic>τ<inf loc="post">p</inf></italic> low-dimensional points.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>W<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>τ<inf loc="post">p</inf></italic> × <italic>τ<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Reconstruction weight matrix in LLE cost function (see <cross-ref id="crf0006" refid="eq0001">Eq. (1)</cross-ref>).</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>M<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>τ<inf loc="post">p</inf></italic> × <italic>τ<inf loc="post">p</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Centred version of weight matrix <italic>W<inf loc="post">p</inf></italic>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><italic>U<inf loc="post">pq</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><italic>τ<inf loc="post">p</inf></italic> × <italic>τ<inf loc="post">q</inf></italic></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Similarity kernel matrix connecting data from slice positions <italic>p</italic> and <italic>q</italic>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><mml:math altimg="si13.gif" overflow="scroll"><mml:mo>−</mml:mo></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Sagittal slice position <italic>p</italic>.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><mml:math altimg="si13.gif" overflow="scroll"><mml:mo>−</mml:mo></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Coronal slice position.</entry></row><row><entry xmlns="http://www.elsevier.com/xml/common/dtd" role="rowhead"><mml:math altimg="si17.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd"><mml:math altimg="si13.gif" overflow="scroll"><mml:mo>−</mml:mo></mml:math></entry><entry xmlns="http://www.elsevier.com/xml/common/dtd">Groupwise embedding of data from two different slice positions.</entry></row></tbody></tgroup></ce:table></ce:floats><head><ce:title id="ct0001">Autoadaptive motion modelling for MR-based respiratory motion estimation</ce:title><ce:author-group id="aut0001"><ce:author id="au0001" orcid="0000-0002-3629-4384"><ce:given-name>Christian F.</ce:given-name><ce:surname>Baumgartner</ce:surname><ce:cross-ref id="crf0007" refid="cor0001"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:cross-ref id="crf0008" refid="aff0001"><ce:sup loc="post">a</ce:sup></ce:cross-ref><ce:e-address type="email" id="ead0001">christian.baumgartner@kcl.ac.uk</ce:e-address></ce:author><ce:author id="au0002"><ce:given-name>Christoph</ce:given-name><ce:surname>Kolbitsch</ce:surname><ce:cross-ref id="crf0009" refid="aff0001"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="au0003"><ce:given-name>Jamie R.</ce:given-name><ce:surname>McClelland</ce:surname><ce:cross-ref id="crf0010" refid="aff0002"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="au0004"><ce:given-name>Daniel</ce:given-name><ce:surname>Rueckert</ce:surname><ce:cross-ref id="crf0011" refid="aff0003"><ce:sup loc="post">c</ce:sup></ce:cross-ref></ce:author><ce:author id="au0005"><ce:given-name>Andrew P.</ce:given-name><ce:surname>King</ce:surname><ce:cross-ref id="crf0012" refid="aff0001"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:affiliation id="aff0001"><ce:label>a</ce:label><ce:textfn id="cetextfn0001">Division of Imaging Sciences and Biomedical Engineering, King’s College London, London, UK</ce:textfn><sa:affiliation><sa:organization>Division of Imaging Sciences and Biomedical Engineering</sa:organization><sa:address-line>King’s College London, London</sa:address-line><sa:country>UK</sa:country></sa:affiliation></ce:affiliation><ce:affiliation id="aff0002"><ce:label>b</ce:label><ce:textfn id="cetextfn0002">Centre for Medical Image Computing, University College London, London, UK</ce:textfn><sa:affiliation><sa:organization>Centre for Medical Image Computing</sa:organization><sa:organization>University College London</sa:organization><sa:address-line>London</sa:address-line><sa:country>UK</sa:country></sa:affiliation></ce:affiliation><ce:affiliation id="aff0003"><ce:label>c</ce:label><ce:textfn id="cetextfn0003">Biomedical Image Analysis Group, Department of Computing, Imperial College London, London, UK</ce:textfn><sa:affiliation><sa:organization>Biomedical Image Analysis Group</sa:organization><sa:organization>Department of Computing</sa:organization><sa:address-line>Imperial College London, London</sa:address-line><sa:country>UK</sa:country></sa:affiliation></ce:affiliation><ce:correspondence id="cor0001"><ce:label>⁎</ce:label><ce:text id="cor1">Corresponding author.</ce:text></ce:correspondence></ce:author-group><ce:date-received day="1" month="6" year="2015"/><ce:date-revised day="22" month="4" year="2016"/><ce:date-accepted day="7" month="6" year="2016"/><ce:abstract class="author-highlights" id="absh001" view="all"><ce:section-title id="sectt0001">Highlights</ce:section-title><ce:abstract-sec id="abssec0001" view="all"><ce:simple-para id="spara0001" view="all"><ce:list id="celist0003"><ce:list-item id="celistitem0001"><ce:label>•</ce:label><ce:para id="para0001" view="all">We present an autoadaptive respiratory motion model for MR-guided interventions.</ce:para></ce:list-item><ce:list-item id="celistitem0002"><ce:label>•</ce:label><ce:para id="para0002" view="all">It follows a novel paradigm where calibration and surrogate data are of one type.</ce:para></ce:list-item><ce:list-item id="celistitem0003"><ce:label>•</ce:label><ce:para id="para0003" view="all">The resulting method continually and automatically adapts to new breathing patterns.</ce:para></ce:list-item><ce:list-item id="celistitem0004"><ce:label>•</ce:label><ce:para id="para0004" view="all">We implement such a model using manifold alignment techniques.</ce:para></ce:list-item><ce:list-item id="celistitem0005"><ce:label>•</ce:label><ce:para id="para0005" view="all">Our proposed method outperforms a non-adaptive technique on real and synthetic data.</ce:para></ce:list-item></ce:list></ce:simple-para></ce:abstract-sec></ce:abstract><ce:abstract class="graphical" id="absh0002" view="all"><ce:section-title id="sectt0002">Graphical abstract</ce:section-title><ce:abstract-sec id="abssec0002" view="all"><ce:simple-para id="spara0002" view="all"><ce:display><ce:figure id="fig0012"><ce:link id="celink0012" locator="fx1" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/fx1"/></ce:figure></ce:display></ce:simple-para></ce:abstract-sec></ce:abstract><ce:abstract id="abs0001" class="author" view="all"><ce:section-title id="sectt0003">Abstract</ce:section-title><ce:abstract-sec id="abssec0003" view="all"><ce:simple-para id="spara0003" view="all">Respiratory motion poses significant challenges in image-guided interventions. In emerging treatments such as MR-guided HIFU or MR-guided radiotherapy, it may cause significant misalignments between interventional road maps obtained pre-procedure and the anatomy during the treatment, and may affect intra-procedural imaging such as MR-thermometry. Patient specific respiratory motion models provide a solution to this problem. They establish a correspondence between the patient motion and simpler surrogate data which can be acquired easily during the treatment. Patient motion can then be estimated during the treatment by acquiring only the simpler surrogate data.</ce:simple-para><ce:simple-para id="spara0004" view="all">In the majority of classical motion modelling approaches once the correspondence between the surrogate data and the patient motion is established it cannot be changed unless the model is recalibrated. However, breathing patterns are known to significantly change in the time frame of MR-guided interventions. Thus, the classical motion modelling approach may yield inaccurate motion estimations when the relation between the motion and the surrogate data changes over the duration of the treatment and frequent recalibration may not be feasible.</ce:simple-para><ce:simple-para id="spara0005" view="all">We propose a novel methodology for motion modelling which has the ability to automatically adapt to new breathing patterns. This is achieved by choosing the surrogate data in such a way that it can be used to estimate the current motion in 3D as well as to update the motion model. In particular, in this work, we use 2D MR slices from different slice positions to build as well as to apply the motion model. We implemented such an autoadaptive motion model by extending our previous work on manifold alignment.</ce:simple-para><ce:simple-para id="spara0006" view="all">We demonstrate a proof-of-principle of the proposed technique on cardiac gated data of the thorax and evaluate its adaptive behaviour on realistic synthetic data containing two breathing types generated from 6 volunteers, and real data from 4 volunteers. On synthetic data the autoadaptive motion model yielded 21.45% more accurate motion estimations compared to a non-adaptive motion model 10 min after a change in breathing pattern. On real data we demonstrated the method’s ability to maintain motion estimation accuracy despite a drift in the respiratory baseline. Due to the cardiac gating of the imaging data, the method is currently limited to one update per heart beat and the calibration requires approximately 12 min of scanning. Furthermore, the method has a prediction latency of 800 ms. These limitations may be overcome in future work by altering the acquisition protocol.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="keys0001" class="keyword" view="all"><ce:section-title id="sectt0004">Keywords</ce:section-title><ce:keyword id="key0002"><ce:text id="cetext0001">MR-guided interventions</ce:text></ce:keyword><ce:keyword id="key0003"><ce:text id="cetext0002">Respiratory motion correction</ce:text></ce:keyword><ce:keyword id="key0004"><ce:text id="cetext0003">Motion modelling</ce:text></ce:keyword><ce:keyword id="key0005"><ce:text id="cetext0004">Manifold learning</ce:text></ce:keyword><ce:keyword id="key0006"><ce:text id="cetext0005">Manifold alignment</ce:text></ce:keyword></ce:keywords></head><body view="all"><ce:sections><ce:section id="sec0001" view="all" role="introduction"><ce:label>1</ce:label><ce:section-title id="sectt0005">Introduction</ce:section-title><ce:para id="para0006" view="all">Recent advances in magnetic resonance (MR) compatible materials and the development of fast parallel computational techniques now allow an increasing range of interventions to be guided by MR images in real-time. MR-guided high intensity focused ultrasound (MRg-HIFU) has been successfully applied to treat a range of conditions such as uterine fibroids, and prostate and liver cancers in patients where invasive therapy is not possible (<ce:cross-refs id="crfs0001" refid="bib0045 bib0014">Tempany et al., 2011; Foley et al., 2013</ce:cross-refs>). In MRg-HIFU, targets are identified in MR images and a computer controlled transducer is moved to sequentially ablate them. Furthermore, MR thermometry can be used to monitor temperature elevation of the tissue and MR imaging can be used after the ablation to evaluate the success of the treatment (<ce:cross-ref id="crf0013" refid="bib0017">Hynynen et al., 1996</ce:cross-ref>). Similarly, the recent development of integrated MR linear accelerators shows great potential for accurate guidance of radiotherapy (RT) treatments (<ce:cross-ref id="crf0014" refid="bib0030">Raaymakers et al., 2009</ce:cross-ref>) using MR imaging. In MRg-RT, magnetic resonance imaging is not only used to accurately identify and track the target but also to prevent the irradiation of healthy tissue in organs at risk (<ce:cross-ref id="crf0015" refid="bib0009">Crijns et al., 2012</ce:cross-ref>).</ce:para><ce:para id="para0007" view="all">For treatments targeting organs affected by breathing motion such as the lungs, the liver, the kidneys or the heart, accurate knowledge of the respiratory motion is essential. Apart from ensuring the irradiation or ablation of the intended target and sparing of the organs at risk, knowledge of respiratory motion is also crucial to correct for motion-induced image-artefacts and for adjusting accumulated dose calculations such as temperature maps in MRg-HIFU or dose simulations in MRg-RT (<ce:cross-ref id="crf0016" refid="bib0010">De Senneville et al., 2015</ce:cross-ref>). Respiratory motion correction is complicated by the fact that breathing, though approximately periodic, may exhibit large variations within a single breathing cycle (intra-cycle variation or hysteresis) or across breathing cycles (inter-cycle variation) (<ce:cross-refs id="crfs0002" refid="bib0006 bib0021 bib0025">Blackall et al., 2006; Kini et al., 2003; McClelland et al., 2011</ce:cross-refs>). For example, abdominal organs are known to undergo continuous drifts for long treatment durations (<ce:cross-refs id="crfs0003" refid="bib0046 bib0001">von Siebenthal et al., 2007; Arnold et al., 2011</ce:cross-refs>) and the motion observed in the lungs may significantly change over the duration of a treatment session due to changing breathing patterns (<ce:cross-refs id="crfs0004" refid="bib0006 bib0020 bib0021">Blackall et al., 2006; King et al., 2009; Kini et al., 2003</ce:cross-refs>).</ce:para><ce:para id="para0008" view="all">Respiratory motion correction can be roughly divided into two classes of techniques: Tracking methods, which attempt to track a single (or a few) targets, such as tumours or fibroids, and motion estimation techniques which aim to provide dense motion fields for an entire region of interest. Both can be achieved in real-time by either <ce:italic>directly</ce:italic> measuring the motion in the images, or <ce:italic>indirectly</ce:italic>, using respiratory motion modelling. In this paper, we provide the proof-of-principle for a novel autoadaptive motion modelling framework for MR-guided interventions which can provide dense three-dimensional motion estimates in the entire region of interest while automatically adapting to changes in respiratory patterns such as drift.</ce:para><ce:para id="para0009" view="all">The foremost objective in image guided treatments is to keep the radiation beam or transducer aligned with the moving target. Methods to track targets in real-time using MR imaging information have been proposed by a number of authors for MRg-HIFU (<ce:cross-refs id="crfs0005" refid="bib0032 bib0049">Ries et al., 2010; Zachiu et al., 2015</ce:cross-refs>) and MRg-RT (<ce:cross-refs id="crfs0006" refid="bib0009 bib0007">Crijns et al., 2012; Brix et al., 2014</ce:cross-refs>). Some tracking solutions not requiring any imaging data have been proposed as well (<ce:cross-ref id="crf0017" refid="bib0038">Sawant et al., 2009</ce:cross-ref>). While tracking has been used for estimating the motion of single targets, many interventions may benefit from richer motion information. In radiotherapy it is desirable to model the motion of the organs at risk as well as the target in order to avoid their irradiation (<ce:cross-ref id="crf0018" refid="bib0009">Crijns et al., 2012</ce:cross-ref>). In MRg-HIFU, MR thermometry is used to monitor the temperature of the sonicated tissue in order to detect when a lethal thermal dose has been delivered (<ce:cross-ref id="crf0019" refid="bib0049">Zachiu et al., 2015</ce:cross-ref>). Respiratory motion may distort the temperature measurements and ideally the entire organ’s motion should be densely estimated in three dimensions to correct for this motion (<ce:cross-refs id="crfs0007" refid="bib0049 bib0034 bib0032 bib0001">Zachiu et al., 2015; Rijkhorst et al., 2011; Ries et al., 2010; Arnold et al., 2011</ce:cross-refs>). MR is a good candidate to provide dense motion estimates during such treatments and has been used to this end. For example, (<ce:cross-ref id="crf0020" refid="bib0032">Ries et al., 2010</ce:cross-ref>) demonstrated a combination of 2D MR in-plane imaging and 1D through-plane tracking using an MR pencil beam navigator. <ce:cross-ref id="crf0021" refid="bib0049">Zachiu et al. (2015)</ce:cross-ref> proposed 2D MR imaging with intermittent adjustment using 3D MR imaging. <ce:cross-ref id="crf0022" refid="bib0010">De Senneville et al. (2015)</ce:cross-ref> proposed a general real-time 2D motion estimation technique for MRg-HIFU and MRg-RT. Current MR technology does not allow imaging in 3D directly with sufficient temporal and spatial resolution. It has been shown, however, that high-quality 3D motion estimations of the whole thorax can be obtained making use of sequentially acquired 2D MR data from different imaging planes (<ce:cross-refs id="crfs0008" refid="bib0048 bib0011 bib0046 bib0002">Würslin et al., 2013; Dikaios et al., 2012; von Siebenthal et al., 2007; Baumgartner et al., 2014a</ce:cross-refs>).</ce:para><ce:section id="sec0002" view="all"><ce:label>1.1</ce:label><ce:section-title id="sectt0006">Motion modelling</ce:section-title><ce:para id="para0010" view="all">Motion models offer a solution for indirect estimation of respiratory motion. A motion model is built by relating the patient-specific breathing motion to a simpler respiratory surrogate signal before the treatment. During the treatment, motion estimates can be obtained using only the surrogate signal. Patient-specific motion models have been proposed extensively for motion correction in radiotherapy (<ce:cross-refs id="crfs0009" refid="bib0042 bib0039 bib0040 bib0016 bib0008 bib0018">Seppenwoolde et al., 2002; Schweikard et al., 2000; 2005; Hoogeman et al., 2009; Cho et al., 2010; Isaksson et al., 2005</ce:cross-refs>) and to a lesser degree also in MR-guided HIFU (<ce:cross-refs id="crfs0010" refid="bib0033 bib0034">Rijkhorst et al., 2010; 2011</ce:cross-refs>). A comprehensive review of respiratory motion modelling can be found in <ce:cross-ref id="crf0023" refid="bib0024">McClelland et al. (2013)</ce:cross-ref>.</ce:para><ce:para id="para0011" view="all">Traditionally, motion models consist of three distinct stages as illustrated in <ce:cross-ref id="crf0024" refid="fig0001">Fig. 1</ce:cross-ref><ce:float-anchor refid="fig0001"/>a: before the treatment, in a <ce:italic>model calibration</ce:italic> step, typically imaging data are acquired along with some simpler surrogate data and image registration techniques are used to extract motion estimates from the imaging data. Surrogate data are often one-dimensional signals derived, for example, by tracking infra-red markers on the patient’s chest (<ce:cross-ref id="crf0025" refid="bib0039">Schweikard et al., 2000</ce:cross-ref>) or from a spirometer (<ce:cross-ref id="crf0026" refid="bib0023">Low et al., 2005</ce:cross-ref>). However, due to increasing requirements for precise motion estimation, recently there has been a trend in motion modelling towards the use of more complex surrogate signals, which offer the chance to capture more respiratory motion variabilities. Examples include chest surface data (<ce:cross-ref id="crf0027" refid="bib0012">Fassi et al., 2014</ce:cross-ref>), real-time ultrasound images (<ce:cross-refs id="crfs0011" refid="bib0028 bib0029">Peressutti et al., 2013; 2012</ce:cross-refs>), or real-time 2D MR slices (<ce:cross-ref id="crf0028" refid="bib0019">King et al., 2012</ce:cross-ref>). Next, in the <ce:italic>model formation</ce:italic> stage, the motion estimates are related to the surrogate data using an appropriate correspondence model. Then, during the treatment (i.e. in the <ce:italic>application phase</ce:italic>), only the surrogate data are continually acquired and motion estimates are derived by using them as input to the correspondence model.</ce:para><ce:para id="para0012" view="all">An underlying assumption of the majority of traditional motion models is that the nature of the relationship between the surrogate data and the motion (i.e. the correspondence model) remains constant. For long treatment durations it is possible for the breathing motion to undergo significant changes, for example due to varying degrees of relaxation of the patient during the procedure, because of pain or discomfort experienced (<ce:cross-refs id="crfs0012" refid="bib0019 bib0016">King et al., 2012; Hoogeman et al., 2009</ce:cross-refs>) or because of organ drift (<ce:cross-refs id="crfs0013" refid="bib0001 bib0046">Arnold et al., 2011; von Siebenthal et al., 2007</ce:cross-refs>). In the traditional motion model paradigm the model is formed before the treatment and has no ability to adapt to changing breathing patterns.</ce:para><ce:para id="para0013" view="all">In response to this problem, a number of papers have proposed <ce:italic>adaptive</ce:italic> motion modelling techniques. A common approach is to correct for changing breathing patterns through occasional intra-fractional imaging. For example, in stereotactic x-ray guided radiotherapy systems, the 3D target location can be intermittently obtained every 1–6 min using intra-fractional imaging along with a surrogate signal value (<ce:cross-refs id="crfs0014" refid="bib0041 bib0016">Seppenwoolde et al., 2007; Hoogeman et al., 2009</ce:cross-refs>). This data can then be used to recalibrate the model on a first-in-first-out basis (<ce:cross-refs id="crfs0015" refid="bib0039 bib0008">Schweikard et al., 2000; Cho et al., 2010</ce:cross-refs>). <ce:cross-ref id="crf0029" refid="bib0018">Isaksson et al. (2005)</ce:cross-ref> employed an adaptive motion model based on neural networks in which the model didn’t require recalibration. Instead, the weights of the neural network were adjusted based on frequent intra-fractional x-ray imaging. Some radiotherapy systems use the distance between the actual tumour position and the position predicted by the system as a quality measure. When this distance goes above a given threshold, the model application phase is interrupted and the current motion model is discarded, new calibration and surrogate data are acquired, and a new motion model is built (<ce:cross-ref id="crf0030" refid="bib0016">Hoogeman et al., 2009</ce:cross-ref>). A similar approach was used by <ce:cross-ref id="crf0031" refid="bib0019">King et al. (2012)</ce:cross-ref> for motion correction in a simultaneous PET/MR system. An adaptive motion modelling approach not requiring intra-fractional imaging was proposed by <ce:cross-ref id="crf0032" refid="bib0012">Fassi et al. (2014)</ce:cross-ref>, who accounted for respiratory baseline drift in x-ray guided radiotherapy by registering a chest surface mesh obtained during the treatment to the chest surface extracted from the 4D CT planning scan. To the best of our knowledge, no adaptive motion modelling techniques have been proposed for MR-guided treatments.</ce:para><ce:para id="para0014" view="all">In this paper, we propose a novel <ce:italic>autoadaptive</ce:italic> motion model for MR-guided interventions, which is automatically updated each time surrogate data is acquired. This is achieved by altering the traditional motion model paradigm as shown in <ce:cross-ref id="crf0033" refid="fig0001">Fig. 1</ce:cross-ref>b. In our proposed framework, both the calibration as well as the surrogate data are 2D MR slices acquired from variable imaging planes. Since the model calibration and surrogate data are of the same type, the surrogate data acquired in the application phase can be fed back into the model formation phase as the treatment goes on, allowing a continuous updating of the model. In <ce:cross-ref id="crf0034" refid="fig0001">Fig. 1</ce:cross-ref>b this update process is indicated by the red feedback arrow. This allows the model to maintain motion estimation accuracy despite gradual changes in the breathing motion and to adapt to previously unseen breathing patterns. Such a framework has potential application in all MR-guided interventions, in particular in MRg-RT and MRg-HIFU. Note that motion estimates derived from 2D MR data have the potential to more accurately reflect (in-plane) motion than 3D MR data due to their superior image quality (<ce:cross-refs id="crfs0016" refid="bib0048 bib0011 bib0002">Würslin et al., 2013; Dikaios et al., 2012; Baumgartner et al., 2014a</ce:cross-refs>). In the proposed framework, the function of the motion model is to relate 2D MR motion surrogates to dense 3D motion estimates.</ce:para><ce:para id="para0015" view="all">We demonstrate how such a motion model can be implemented based on the concepts of manifold learning (ML) and manifold alignment (MA).</ce:para></ce:section><ce:section id="sec0003" view="all"><ce:label>1.2</ce:label><ce:section-title id="sectt0007">Manifold learning and manifold alignment</ce:section-title><ce:para id="para0016" view="all">Time series of medical imaging data, such as the 2D motion fields which form the calibration and update data in the proposed motion model, are often inherently high-dimensional. In recent years manifold learning was shown to be useful in the analysis of motion in such data, either directly on image intensities (<ce:cross-refs id="crfs0017" refid="bib0047 bib0013">Wachinger et al., 2011; Fischer et al., 2014</ce:cross-refs>) or on motion fields (<ce:cross-ref id="crf0035" refid="bib0044">Souvenir et al., 2006</ce:cross-ref>), making use of the fact that similar points in the low-dimensional space correspond to similar motion states. Applications include the extraction of respiratory gating navigators from MR and ultrasound images (<ce:cross-ref id="crf0036" refid="bib0047">Wachinger et al., 2011</ce:cross-ref>) and the derivation of navigators from X-ray fluoroscopy images for motion modelling in image guided minimally invasive surgeries (<ce:cross-ref id="crf0037" refid="bib0013">Fischer et al., 2014</ce:cross-ref>).</ce:para><ce:para id="para0017" view="all">Manifold alignment techniques establish correspondences between multiple related datasets, which are not directly comparable in high/dimensional space, by aligning the low-dimensional manifold structure. Such approaches allow the identification of similar data points in distinct datasets. Recently a number of works in medical imaging have exploited the potential of such techniques. For example, (<ce:cross-ref id="crf0038" refid="bib0005">Bhatia et al., 2012</ce:cross-ref>) applied manifold alignment for the robust region-wise separation of cardiac and respiratory motion from cardiac MR images. <ce:cross-ref id="crf0039" refid="bib0015">Georg et al. (2008)</ce:cross-ref> used a basic manifold alignment approach for the gating of lung CT volumes.</ce:para><ce:para id="para0018" view="all">In our previous work (<ce:cross-refs id="crfs0018" refid="bib0003 bib0002">Baumgartner et al., 2013; 2014a</ce:cross-refs>) we developed the simultaneous groupwise manifold alignment (SGA) technique on which this work is based. The technique was proposed to relate partial image intensity information from coronal high-resolution 2D MR slices based on the groupwise alignment of manifolds derived from data acquired at the different slice positions. This allowed for accurate 4D MR reconstructions which could be used to correct simultaneously acquired PET data for respiratory motion.</ce:para><ce:para id="para0019" view="all">In this paper, we extend our previously proposed SGA technique to build an autoadaptive motion model from multiple 2D motion fields derived from sagittal 2D MR slices acquired at different anatomical positions. These 2D motion fields can then be combined to estimate 3D motion in the thorax. To allow this, significant changes to the original SGA methodology were necessary. (1) manifold alignment was performed on motion fields rather than images; (2) the method was extended to use a combination of coronal and sagittal slices; (3) in order to estimate motion at points where the respiratory pattern is not sufficiently sampled, a new interpolation scheme on the manifold was developed. The present work was presented with preliminary results in <ce:cross-ref id="crf0040" refid="bib0004">Baumgartner et al. (2014b)</ce:cross-ref>. In this work we extend the methodology by incorporating slices of different orientation into the model and include more extensive evaluations on real and synthetic data. The technique is evaluated for its feasibility in MR-guided interventions using real 20 min MR scans of healthy volunteers, and on synthetic MR data with two different breathing types.</ce:para></ce:section></ce:section><ce:section id="sec0004" view="all" role="background"><ce:label>2</ce:label><ce:section-title id="sectt0008">Background</ce:section-title><ce:para id="para0020" view="all">In the following we will briefly review the necessary theory to understand our previous work, as well as the extension of it which will be introduced in <ce:cross-ref id="crf0041" refid="sec0008">Section 3</ce:cross-ref>. Our goal in this work, as well as in our previous works (<ce:cross-refs id="crfs0019" refid="bib0003 bib0002">Baumgartner et al., 2013; 2014a</ce:cross-refs>), is to obtain correspondences between high-dimensional data obtained from slices at different anatomical positions by finding correspondences between their low-dimensional representations. In <ce:cross-ref id="crf0042" refid="bib0003">Baumgartner et al. (2013</ce:cross-ref>; <ce:cross-ref id="crf0043" refid="bib0002">2014a)</ce:cross-ref> the high-dimensional data were 2D MR slices. In this work, as well as in the preliminary version of this work (<ce:cross-ref id="crf0044" refid="bib0004">Baumgartner et al., 2014b</ce:cross-ref>), they are motion fields derived from such slices. In the next section, we will give an introduction to locally linear embeddings (LLE) (<ce:cross-ref id="crf0045" refid="bib0036">Roweis and Saul, 2000</ce:cross-ref>), which is the manifold learning technique used in this work, and how it can be applied to data obtained from one slice position. Next, we will discuss how correspondences in the low-dimensional embedded space can be established for data obtained from two slice positions (<ce:cross-ref id="crf0046" refid="sec0006">Section 2.2</ce:cross-ref>). In <ce:cross-ref id="crf0047" refid="sec0007">Section 2.3</ce:cross-ref> we will then show how the concept can be extended to many slice positions. For an overview of the mathematical notation used in the remainder of this paper refer to <ce:cross-ref id="crf0048" refid="tbl0001">Table 1</ce:cross-ref><ce:float-anchor refid="tbl0001"/>.</ce:para><ce:section id="sec0005" view="all"><ce:label>2.1</ce:label><ce:section-title id="sectt0009">Manifold learning on one dataset</ce:section-title><ce:para id="para0021" view="all">LLE can be used to reduce the dimensionality of a high-dimensional imaging dataset <mml:math altimg="si18.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math>. Such a dataset can be derived by vectorising all <ce:italic>τ<ce:inf loc="post">p</ce:inf></ce:italic> images <mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> acquired at a single slice position <ce:italic>p</ce:italic>, or alternatively, by additionally deriving a motion field <mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> for each image and vectorising those. Each of the columns <mml:math altimg="si19.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math> of <ce:italic>X<ce:inf loc="post">p</ce:inf></ce:italic>, can be thought of as a point in <ce:italic>D</ce:italic> dimensional space where <ce:italic>D</ce:italic> is the number of pixels in the original image <mml:math altimg="si20.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> or the number of motion components in <mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math>.</ce:para><ce:para id="para0022" view="all">In LLE, dimensionality reduction is accomplished by first forming a <ce:italic>k</ce:italic>-nearest neighbour graph of the data based on the <mml:math altimg="si21.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math>-distance between the data points. The key assumption is that the neighbourhood of each point and its nearest neighbours are on a locally linear patch of the manifold and that therefore each point can be reconstructed as a linear combination of its nearest neighbours. The optimal contributions of each point <ce:italic>j</ce:italic> to the reconstruction of <ce:italic>i</ce:italic> are given by a weight term <mml:math altimg="si22.gif" overflow="scroll"><mml:msubsup><mml:mi>w</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math>. The matrix <ce:italic>W<ce:inf loc="post">p</ce:inf></ce:italic> containing all the weights can be calculated in closed form as described in <ce:cross-ref id="crf0049" refid="bib0036">Roweis and Saul (2000)</ce:cross-ref>. A <ce:italic>d</ce:italic>-dimensional embedding, where <ce:italic>d</ce:italic> ≪ <ce:italic>D</ce:italic>, preserving this locally linear structure is given by the <mml:math altimg="si23.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math> minimising the following cost function:
<ce:display><ce:formula id="eq0001"><ce:label>(1)</ce:label><mml:math altimg="si24.gif" overflow="scroll"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>∥</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>η</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:msubsup><mml:mi>w</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>M</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>p</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>Here <ce:italic>η</ce:italic>(<ce:italic>i</ce:italic>) is the neighbourhood of the data point <ce:italic>i, Tr</ce:italic>( · ) is the trace operator, and <mml:math altimg="si25.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the centred weight matrix. This optimisation problem can be solved under the constraint that <mml:math altimg="si26.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>p</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math> by calculating the eigendecomposition of <ce:italic>M<ce:inf loc="post">p</ce:inf></ce:italic>. The embedding <ce:italic>Y<ce:inf loc="post">p</ce:inf></ce:italic> is given by the eigenvectors corresponding to the second smallest to <mml:math altimg="si27.gif" overflow="scroll"><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> smallest eigenvalues of <ce:italic>M</ce:italic> (<ce:cross-ref id="crf0050" refid="bib0036">Roweis and Saul, 2000</ce:cross-ref>).</ce:para></ce:section><ce:section id="sec0006" view="all"><ce:label>2.2</ce:label><ce:section-title id="sectt0010">Simultaneous embedding of two datasets</ce:section-title><ce:para id="para0023" view="all">Separate datasets generated by the same mechanics, e.g. respiration, will typically lie on similar manifolds, as is the case, for example, for two datasets <ce:italic>X<ce:inf loc="post">p</ce:inf></ce:italic> and <ce:italic>X<ce:inf loc="post">q</ce:inf></ce:italic> acquired from two different anatomical positions <ce:italic>p</ce:italic> and <ce:italic>q</ce:italic>. It has been shown by <ce:cross-ref id="crf0051" refid="bib0047">Wachinger et al. (2011)</ce:cross-ref> that this holds for 2D MR data from neighbouring, as well as distant slice positions and for slice positions of different orientations. This can be explained by the observation that the manifold of data from each slice position is defined by the principal modes of variation, which depend on the respiratory motion common to all slice positions rather than the absolute appearance of the slices. This knowledge can be used to identify corresponding data points from the two datasets. In our case this means finding corresponding data acquired from different anatomical positions but with similar respiratory phases. Unfortunately, generally embeddings obtained from different datasets are not aligned in the low-dimensional space as they may vary due to flipping or rotations of the eigenvectors, and slight variations in the manifold structure. One approach to find aligned manifold embeddings <ce:italic>Y<ce:inf loc="post">p</ce:inf>, Y<ce:inf loc="post">q</ce:inf></ce:italic> of two high-dimensional datasets is to embed them simultaneously. The cost function of LLE lends itself ideally to be extended to two datasets. The problem of finding a simultaneous embedding can be written as the following minimisation problem
<ce:display><ce:formula id="eq0002"><ce:label>(2)</ce:label><mml:math altimg="si28.gif" overflow="scroll"><mml:mrow><mml:munder><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mo>·</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>ϕ</ce:italic> is the embedding error within the respective datasets <ce:italic>p</ce:italic> and <ce:italic>q</ce:italic> (intra-dataset cost functions) as given by <ce:cross-ref id="crf0052" refid="eq0001">Eq. (1)</ce:cross-ref>, and <ce:italic>ψ</ce:italic> is the embedding error <ce:italic>between</ce:italic> the two datasets (inter-dataset cost function). This term ensures that corresponding points will be embedded close to each other. Note that typically no correspondences between the datasets are known <ce:italic>a priori</ce:italic>. Rather, corresponding data points must be identified at runtime. The parameter <ce:italic>μ</ce:italic> regulates the influence of the inter-dataset cost function <ce:italic>ψ</ce:italic> on the embedding.</ce:para><ce:para id="para0024" view="all">The cost function <ce:italic>ψ</ce:italic> can be defined as follows
<ce:display><ce:formula id="eq0003"><ce:label>(3)</ce:label><mml:math altimg="si29.gif" overflow="scroll"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where
<ce:display><ce:formula id="ueq0001"><mml:math altimg="si30.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>is a (non-symmetric) similarity kernel of the form
<ce:display><ce:formula id="eq0004"><ce:label>(4)</ce:label><mml:math altimg="si31.gif" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>ϵ</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>Above, ϵ( ·, ·) is a distance function which must be defined such that the kernel <ce:italic>K</ce:italic>( ·, ·) will take large values for similar data points and small values for dissimilar data points. The similarity kernel can be written as a matrix <ce:italic>U<ce:inf loc="post">pq</ce:inf></ce:italic> with high values connecting similar images from slice positions <ce:italic>p</ce:italic> and <ce:italic>q</ce:italic>. In <ce:cross-ref id="crf0053" refid="bib0003">Baumgartner et al. (2013)</ce:cross-ref> we used intensity-based distance of slices from neighbouring positions <ce:italic>p</ce:italic> and <ce:italic>q</ce:italic> to define the distance function ϵ. In <ce:cross-ref id="crf0054" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> we improved the method by correcting this distance measure for deformations that may occur between slice positions using non-rigid registration. As we will show in <ce:cross-ref id="crf0055" refid="sec0010">Section 3.2</ce:cross-ref>, in this work we used a similar kernel to the one described in <ce:cross-ref id="crf0056" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> for neighbouring slices of the same orientation, and a novel kernel based on motion similarities in the slice overlap for slices with different orientations (see <ce:cross-ref id="crf0057" refid="sec0012">Section 3.2.2</ce:cross-ref>).</ce:para><ce:para id="para0025" view="all">Next, the similarity kernel <ce:italic>U<ce:inf loc="post">pq</ce:inf></ce:italic> is sparsified to increase the robustness of the method. We use the Hungarian algorithm (<ce:cross-ref id="crf0058" refid="bib0022">Kuhn, 1955</ce:cross-ref>) to identify the optimal one-to-one mapping between the two datasets. That is, the mapping where each data point from dataset <ce:italic>X<ce:inf loc="post">p</ce:inf></ce:italic> is connected to exactly one data point from <ce:italic>X<ce:inf loc="post">q</ce:inf></ce:italic> and the sum of the remaining weights <mml:math altimg="si1.gif" overflow="scroll"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math> is maximised. This is illustrated in <ce:cross-ref id="crf0059" refid="fig0002">Fig. 2</ce:cross-ref><ce:float-anchor refid="fig0002"/>. We found in <ce:cross-ref id="crf0060" refid="bib0003">Baumgartner et al. (2013)</ce:cross-ref> that this kind of sparsification is more robust than a simple nearest neighbour sparsification.</ce:para><ce:para id="para0026" view="all">Using the sparsified kernel the problem in <ce:cross-ref id="crf0061" refid="eq0002">Eq. (2)</ce:cross-ref> can then easily be rewritten in matrix form and can be solved as an eigenvalue problem analogous to the original LLE algorithm as is described in <ce:cross-ref id="crf0062" refid="bib0003">Baumgartner et al. (2013</ce:cross-ref>; <ce:cross-ref id="crf0063" refid="bib0002">2014a)</ce:cross-ref>.</ce:para></ce:section><ce:section id="sec0007" view="all"><ce:label>2.3</ce:label><ce:section-title id="sectt0011">Embedding data from many slice positions</ce:section-title><ce:para id="para0027" view="all">In our previous work we were interested in simultaneously embedding not only two but up to 40 datasets, i.e. the number of slice positions from which our slice-by-slice data originated. It is possible to augment the minimisation problem in <ce:cross-ref id="crf0064" refid="eq0002">Eq. (2)</ce:cross-ref> to an arbitrary number of datasets, however, it is not trivial to define the similarity kernel for non-neighbouring slice positions and leaving these kernels undefined leads to an unstable optimisation problem (<ce:cross-ref id="crf0065" refid="bib0003">Baumgartner et al., 2013</ce:cross-ref>).</ce:para><ce:para id="para0028" view="all">In <ce:cross-ref id="crf0066" refid="bib0003">Baumgartner et al. (2013</ce:cross-ref>; <ce:cross-ref id="crf0067" refid="bib0002">2014a)</ce:cross-ref> we proposed to embed the data in overlapping groups of two consisting of data from neighbouring slice positions, which is a much more manageable problem. In order to relate the groups to each other they are chosen so that they share some data. In particular, data from each slice position appears in two different groups. For example, one group may contain data from slice positions 7 and 8, and another data from slice positions 8 and 9. The aligned embeddings of the data gathered from slice position 7 can then be related to the embeddings from slice position 9 by means of the shared data from slice position 8.</ce:para></ce:section></ce:section><ce:section id="sec0008" view="all"><ce:label>3</ce:label><ce:section-title id="sectt0012">Materials and methods</ce:section-title><ce:para id="para0029" view="all">Simultaneous groupwise manifold alignment was originally proposed for coronal input slices, since the anatomy changes less from slice position to slice position in this plane. In the motion modelling context, however, it is essential that the input data captures as much of the motion as possible. It is well known that respiratory motion is largest in the superior-inferior (S-I) and anterior-posterior (A-P) directions (<ce:cross-ref id="crf0068" refid="bib0042">Seppenwoolde et al., 2002</ce:cross-ref>). Therefore, we focused on sagittal input slices in this work. Unfortunately, SGA as described in the previous section is not robust to sagittal input slices because respiratory information often gets lost while propagating from group to group through the body centre, where anatomy changes rapidly from slice position to slice position. Therefore, here we extend the technique to additionally incorporate data acquired from a single coronal slice position to aid this transition through the body centre. Note that the preliminary version of this work (<ce:cross-ref id="crf0069" refid="bib0004">Baumgartner et al., 2014b</ce:cross-ref>) included only sagittal slices.</ce:para><ce:para id="para0030" view="all">In the following we will describe our proposed method for autoadaptive motion modelling following the three motion modelling stages outlined in the introduction. We first show how we acquire sagittal and coronal input slices and derive 2D motion estimates from them to train the model. Next, we show how SGA can be extended to use motion fields, rather than images, and how different slice orientations are incorporated into the model. Lastly, we show how the model can be updated during a treatment in the application phase, and how this leads to continuous adaptivity.</ce:para><ce:section id="sec0009" view="all"><ce:label>3.1</ce:label><ce:section-title id="sectt0013">Calibration scan</ce:section-title><ce:para id="para0031" view="all">The image acquisition scheme of the present work is an extension of the acquisition scheme used in <ce:cross-ref id="crf0070" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref>. We divide the entire region of interest into adjacent sagittal slice positions <mml:math altimg="si32.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:math> each spanning 8 mm. Here, the region of interest is the entire thorax including the liver and lungs. Additionally, we also choose one coronal slice position <mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math> to help with the propagation of respiratory information between distant sagittal slices. A schematic of the slice positions is shown in <ce:cross-ref id="crf0071" refid="fig0003">Fig. 3</ce:cross-ref><ce:float-anchor refid="fig0003"/>. The coronal slice is chosen such that it coincides with the dome of the left hemi-diaphragm in order to maximise the amount of captured respiratory motion.</ce:para><ce:para id="para0032" view="all">We acquire 2D images <mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> from these slice positions in a slice-by-slice fashion, iterating through the slice positions, first the sagittals then the coronal, until each slice position is covered <ce:italic>τ<ce:inf loc="post">p</ce:inf></ce:italic> times. In order to isolate the respiratory motion, in this study, we acquire only one slice per heart beat at systole. However, in principle, similar data could also be acquired without cardiac gating which would significantly reduce overall acquisition times. The acquisitions were carried out on a Philips Achieva 3T MR scanner using a T1-weighted gradient echo sequence with an acquired in-plane image resolution of 1.4 × 1.4 mm<ce:sup loc="post">2</ce:sup>, a slice thickness of 8 mm, repetition and echo times (TR and TE) of 3.1 and 1.9 ms, a flip angle (FA) of 30 degrees, and a SENSE-factor of 2. The field of view covering the entire thorax was 400  ×  370 mm<ce:sup loc="post">2</ce:sup>, and each slice took around 180 ms to acquire. To cover the entire thorax typically around 30 sagittal slice positions were needed. Additionally, we acquired exhale slices <mml:math altimg="si33.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> using the same slice-by-slice protocol in a scan consisting of two consecutive breath holds. The volunteers were instructed to try and reproduce the same exhale position as best as they could. Lastly, we acquired a 1D pencil beam navigator immediately before each dynamic image solely for the purpose of validating our method.</ce:para><ce:para id="para0033" view="all">In the next step we derive 2D motion fields <mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> for each slice position by registering each of the <ce:italic>τ<ce:inf loc="post">p</ce:inf></ce:italic> 2D images <mml:math altimg="si12.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> to the corresponding slice <mml:math altimg="si33.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> from the exhale breath hold image. We used the NiftyReg implementation of a non-rigid B-spline registration algorithm with 3 hierarchy levels, a final grid spacing of 15 mm in each direction and no bending energy penalty term (<ce:cross-ref id="crf0072" refid="bib0026">Modat et al., 2010</ce:cross-ref>). The vectorised motion fields <mml:math altimg="si14.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:math> derived from the slice positions <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si34.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> respectively, form the datasets <ce:italic>X</ce:italic><ce:inf loc="post">(<ce:italic>p, sag</ce:italic>)</ce:inf> and <ce:italic>X</ce:italic><ce:inf loc="post">(<ce:italic>cor</ce:italic>)</ce:inf>.</ce:para></ce:section><ce:section id="sec0010" view="all"><ce:label>3.2</ce:label><ce:section-title id="sectt0014">Motion model formation</ce:section-title><ce:para id="para0034" view="all">We propose that a groupwise embedding of all the motion data acquired during the calibration phase can be viewed as a motion model as it contains all respiratory information collected during the calibration and can be applied using new 2D motion information, as will be explained in <ce:cross-ref id="crf0073" refid="sec0014">Section 3.3</ce:cross-ref>. Thus, in order to form the motion model we perform an embedding of all the sagittal and coronal slices acquired during the calibration phase in groups of two as shown in <ce:cross-ref id="crf0074" refid="fig0003">Figs. 3</ce:cross-ref> and <ce:cross-ref id="crf0075" refid="fig0005">5</ce:cross-ref>. The embeddings can be performed as described in <ce:cross-ref id="crf0076" refid="sec0006">Sections 2.2</ce:cross-ref> and <ce:cross-ref id="crf0077" refid="sec0007">2.3</ce:cross-ref>. To embed the motion data derived from sagittal and coronal motion fields we need to introduce two significant methodological novelties. First, we need new similarity kernels of the form described in <ce:cross-ref id="crf0078" refid="eq0004">Eq. (4)</ce:cross-ref> with which motion fields of slices with the same as well as slices with different orientations can be compared. In particular, we need to define appropriate distance functions ϵ( ·, ·) for both these cases. Secondly, we need a new propagation scheme which allows respiratory information to propagate across the body centre.</ce:para><ce:section id="sec0011" view="all"><ce:label>3.2.1</ce:label><ce:section-title id="sectt0015">Distance functions for neighbouring slices of the same orientation</ce:section-title><ce:para id="para0035" view="all">We base our choice for neighbouring sagittal motion data on the robust distance measure we proposed in <ce:cross-ref id="crf0079" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> for coronal images and adapt it to the scenario of motion fields. For two neighbouring slice positions <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si35.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:math> the distance of data points <mml:math altimg="si36.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math> and <mml:math altimg="si37.gif" overflow="scroll"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:math> is assessed based on the <mml:math altimg="si21.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math>-distance of the corresponding motion fields <mml:math altimg="si38.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math> and <mml:math altimg="si39.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:math>. In order to account for the changes in anatomy between sagittal slices we transform one of the motion fields into the coordinate system of the other using transformations <ce:italic>T</ce:italic><ce:inf loc="post"><ce:italic>q</ce:italic>↦<ce:italic>p</ce:italic></ce:inf>, <ce:italic>T</ce:italic><ce:inf loc="post"><ce:italic>p</ce:italic>↦<ce:italic>q</ce:italic></ce:inf> which we obtain by registering the breath hold slices <mml:math altimg="si40.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> to <mml:math altimg="si41.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> and vice versa. As is discussed in more depth in <ce:cross-ref id="crf0080" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref>, transporting motion fields to the new coordinate system is achieved using the method proposed by <ce:cross-ref id="crf0081" refid="bib0031">Rao et al. (2002)</ce:cross-ref>. To increase robustness we average the results of the comparisons in the spaces of slice position <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si35.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:math>. The final distance measure is defined as
<ce:display><ce:formula id="eq0005"><ce:label>(5)</ce:label><mml:math altimg="si42.gif" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.33em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>↦</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:mspace width="0.16em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>↦</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>A possible source of errors are structures appearing and disappearing from the plane due to through-plane motion. In <ce:cross-ref id="crf0082" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> we showed that, despite such effects, including the transformations <ce:italic>T</ce:italic><ce:inf loc="post"><ce:italic>q</ce:italic>↦<ce:italic>p</ce:italic></ce:inf>, <ce:italic>T</ce:italic><ce:inf loc="post"><ce:italic>p</ce:italic>↦<ce:italic>q</ce:italic></ce:inf> significantly improves the matching accuracy compared to the simple <mml:math altimg="si21.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math>-distance between images. Since the changes from sagittal slice position to sagittal slice position can be even larger than for coronal slices, we expect this effect to be more pronounced for slices of this orientation. Note that we used normalised cross correlation in the preliminary version of this work (<ce:cross-ref id="crf0083" refid="bib0004">Baumgartner et al., 2014b</ce:cross-ref>). However, in this work we found the <mml:math altimg="si21.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math>-distance to be a more robust measure in this context.</ce:para></ce:section><ce:section id="sec0012" view="all"><ce:label>3.2.2</ce:label><ce:section-title id="sectt0016">Distance function for slices with different orientation</ce:section-title><ce:para id="para0036" view="all">To define a distance function for two slices acquired from a sagittal slice position <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and a coronal slice position <mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math> we use the fact that such slices have an overlap and thus visualise the same anatomy in the overlapping region as is illustrated in the example in <ce:cross-ref id="crf0024a" refid="fig0004">Fig. 4</ce:cross-ref><ce:float-anchor refid="fig0004"/><ce:float-anchor refid="fig0005"/>a. Motion estimates derived from two such slices share the S-I motion component along the slice overlap. If <mml:math altimg="si43.gif" overflow="scroll"><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math> is the S-I motion in the overlapping region originating from the <ce:italic>i</ce:italic>-th acquired sagittal slice at <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si44.gif" overflow="scroll"><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:math> the motion in the overlapping region from the <ce:italic>j</ce:italic>-th acquired coronal slice, we define the distance function as
<ce:display><ce:formula id="eq0006"><ce:label>(6)</ce:label><mml:math altimg="si45.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>To illustrate this we show examples of S-I line motions <mml:math altimg="si46.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math> originating from sagittal and coronal slices in <ce:cross-ref id="crf0024b" refid="fig0004">Fig. 4</ce:cross-ref>b. The left hand side shows S-I motion extracted along the intersection (highlighted in <ce:cross-ref id="crf0024c" refid="fig0004">Fig. 4</ce:cross-ref>a) from a coronal slice and the curves on the right hand side show two possible S-I motions extracted from the same region from the sagittal slice position. The blue curve shows a good match in respiratory position of the sagittal to the coronal slice and will lead to a low distance in <ce:cross-ref id="crf0084" refid="eq0006">Eq. (6)</ce:cross-ref>. Conversely, the motion in the sagittal slice from which the red curve was extracted has a higher distance to the coronal slice motion and thus corresponds to a different respiratory state.</ce:para></ce:section><ce:section id="sec0013" view="all"><ce:label>3.2.3</ce:label><ce:section-title id="sectt0017">Group connectivity and propagation of respiratory information</ce:section-title><ce:para id="para0037" view="all">By using the distance measures defined in <ce:cross-ref id="crf0085" refid="eq0005">Eqs. (5)</ce:cross-ref> and <ce:cross-ref id="crf0086" refid="eq0006">(6)</ce:cross-ref> we are able to simultaneously embed any two neighbouring sagittal slice positions <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si35.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:math> and any overlapping sagittal and coronal slice positions <mml:math altimg="si15.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math> and <mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math>. This is achieved by converting the distances into similarities using <ce:cross-ref id="crf0087" refid="eq0004">Eq. (4)</ce:cross-ref> and then solving the general optimisation in <ce:cross-ref id="crf0088" refid="eq0002">Eq. (2)</ce:cross-ref> to obtain an embedding.</ce:para><ce:para id="para0038" view="all">Similar to our previous work this allows us to embed data from all acquired slice positions in overlapping groups of two. In this work, we again connect all neighbouring sagittal slice positions by embedding them in overlapping groups. However, in addition, we align the data from each sagittal slice position together with the data from the coronal slice position. This is illustrated in <ce:cross-ref id="crf0089" refid="fig0003">Fig. 3</ce:cross-ref>. By embedding the data in this way, the 2D motion fields from all slice positions are embedded in three groups, with the exception of <mml:math altimg="si47.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math> and <mml:math altimg="si48.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math> which don’t have a left-hand or right-hand neighbour, respectively. For example, data from slice position <mml:math altimg="si49.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math> is embedded in the groups <mml:math altimg="si50.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg="si51.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> and <mml:math altimg="si52.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>.</ce:para><ce:para id="para0039" view="all">Note that the data within each group are aligned, as is illustrated by the close-up views of <mml:math altimg="si53.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> and <mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> in <ce:cross-ref id="crf0090" refid="fig0003">Fig. 3</ce:cross-ref>.</ce:para><ce:para id="para0040" view="all">As opposed to our earlier works (<ce:cross-refs id="crfs0020" refid="bib0002 bib0003">Baumgartner et al., 2014a; 2013</ce:cross-refs>) there now no longer is just one path from each slice position to each other slice position. Rather, the different slice positions are now connected by a network of groups as is illustrated in <ce:cross-ref id="crf0091" refid="fig0005">Fig. 5</ce:cross-ref>.</ce:para><ce:para id="para0041" view="all">This is a crucial element of our proposed technique which allows propagation of respiratory information in the form of low-dimensional embedded coordinates from slice position to slice position without having to go through difficult areas such as the body centre where there are larger anatomical differences between adjacent slices.</ce:para><ce:para id="para0042" view="all">In the following section we will outline how low-dimensional coordinates obtained from a 2D input motion field can be propagated from slice position to slice position.</ce:para></ce:section></ce:section><ce:section id="sec0014" view="all"><ce:label>3.3</ce:label><ce:section-title id="sectt0018">Model updating and adaptivity</ce:section-title><ce:para id="para0043" view="all">After the calibration scan and model formation phase the model is ready to be applied. During the application phase slices can be acquired in the same slice-by-slice fashion as described in <ce:cross-ref id="crf0092" refid="sec0009">Section 3.1</ce:cross-ref>. That means each input image is again acquired at a different slice position and can have sagittal or coronal orientation.</ce:para><ce:para id="para0044" view="all">From each of these slices we can derive a new 2D motion estimate, embed this motion estimate in the groups containing data from this slice position and reconstruct a pseudo 3D motion estimate by looking up corresponding 2D motions from all other slice positions. Note that the resulting 3D motion fields will lack the left-right (L-R) motion component. The new 2D motion, as well as being used as the surrogate input to the motion model, is retained in the manifold embeddings of the appropriate groups. This leads to the desired autoadaptivity. Each of these steps will be explained in detail below. We will illustrate the process using the example shown in <ce:cross-ref id="crf0093" refid="fig0005">Fig. 5</ce:cross-ref>.</ce:para><ce:section id="sec0015" view="all"><ce:label>3.3.1</ce:label><ce:section-title id="sectt0019">Obtaining a 2D update motion estimate</ce:section-title><ce:para id="para0045" view="all">In a first step, the most recently acquired image <mml:math altimg="si54.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> is registered in 2D to the corresponding breath hold slice <mml:math altimg="si33.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> in order to form the current update motion field <mml:math altimg="si55.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math>. That is, the motion field <mml:math altimg="si55.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> obtained in this way acts as the surrogate data for the motion model application. We used the same registration parameters as in the initial calibration (see <ce:cross-ref id="crf0094" refid="sec0009">Section 3.1</ce:cross-ref>). On a workstation with 8 cores clocked at 2.7 GHz this operation took around 500 ms. In the example in <ce:cross-ref id="crf0095" refid="fig0005">Fig. 5</ce:cross-ref>, we assumed that the newest slice was acquired at slice position <mml:math altimg="si10.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> which is highlighted in yellow. Note that only the registrations from <mml:math altimg="si54.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> to <mml:math altimg="si33.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> have to be performed during the application phase. The registrations across slice positions (i.e. <mml:math altimg="si33.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> to <mml:math altimg="si56.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math>), which are required for the registration based similarity kernel described in <ce:cross-ref id="crf0096" refid="sec0011">Section 3.2.1</ce:cross-ref>, only need to be performed once during the model formation.</ce:para></ce:section><ce:section id="sec0016" view="all"><ce:label>3.3.2</ce:label><ce:section-title id="sectt0020">Estimating current 3D motion</ce:section-title><ce:para id="para0046" view="all">In order to estimate 3D motion from partial motion information provided by the single input 2D motion field <mml:math altimg="si57.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> the motion from the newly acquired slice must be related to that from all other slice positions. First, all groups which contain data from the slice position at which the new slice was acquired must be recalculated. If, as in our example, the current update slice was acquired at slice position <mml:math altimg="si10.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> the groups <mml:math altimg="si58.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> and <mml:math altimg="si59.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> must be re-evaluated (see <ce:cross-ref id="crf0097" refid="fig0003">Figs. 3</ce:cross-ref> and <ce:cross-ref id="crf0098" refid="fig0005">5</ce:cross-ref>). To achieve this the dataset <ce:italic>X</ce:italic><ce:inf loc="post">2</ce:inf> is simply augmented by the new entry and the respective embeddings are recalculated. Updating just a few groups is relatively fast and on average took fewer than 100 ms in our single thread MATLAB implementation.</ce:para><ce:para id="para0047" view="all">As is shown in <ce:cross-ref id="crf0099" refid="fig0005">Fig. 5</ce:cross-ref>, the new motion field now has a corresponding low-dimensional point in each of the low-dimensional embeddings which include dataset <ce:italic>X</ce:italic><ce:inf loc="post">2</ce:inf>. These points are highlighted by squares with yellow backgrounds in <ce:cross-ref id="crf0100" refid="fig0005">Fig. 5</ce:cross-ref>. The coordinates of these low-dimensional embedded points are propagated from group to group following the shortest path, i.e. using the path requiring the fewest group transitions. This is done by making use of the fact that the groups share datasets, and that the datasets within a group are aligned. This effectively means that neighbouring slices are updated through the sagittal-to-sagittal groups and further away sagittal slice positions are connected through the coronal slice. Other methods for choosing the update paths taking into account the quality of the embedding were also investigated and may lead to small improvements. However, in this work for simplicity we confine our analysis to the shortest path method.</ce:para><ce:para id="para0048" view="all">Following our example, first the nearest neighbours of low-dimensional points corresponding to data from <mml:math altimg="si60.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg="si49.gif" overflow="scroll"><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math> and <mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math> are found in the respective groups. The nearest neighbour operation is indicated by the dotted arrows in <ce:cross-ref id="crf0101" refid="fig0005">Fig. 5</ce:cross-ref> and the nearest points are indicated by circles. The high-dimensional motion fields corresponding to the circled points in <mml:math altimg="si61.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> and <mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> are at the same respiratory position as the input slice. Note that in the example in <ce:cross-ref id="crf0102" refid="fig0005">Fig. 5</ce:cross-ref>, only one nearest neighbour is shown per slice position. In reality, <ce:italic>κ</ce:italic> nearest neighbours are identified at this stage and the corresponding 2D motion fields are interpolated.</ce:para><ce:para id="para0049" view="all">Next, motion fields from all other sagittal slice positions are chosen by using the coronal slice. The nearest low-dimensional neighbour of the input point in group <mml:math altimg="si59.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> is then transported to all other groups containing the coronal slice because that same point exists in all other groups. Note that only the closest neighbour is transported across groups. From there the corresponding points from the sagittal motion datasets are again found by looking up the <ce:italic>κ</ce:italic> nearest neighbours.</ce:para><ce:para id="para0050" view="all">At the end of this process, <ce:italic>κ</ce:italic> 2D motion fields have been identified for each slice position. In the following section, it will be described how these 2D motion fields can be combined to arrive at an interpolated motion estimate for each slice position, and how these partial 2D motion estimates can then be stacked into a full pseudo 3D motion field.</ce:para></ce:section><ce:section id="sec0017" view="all"><ce:label>3.3.3</ce:label><ce:section-title id="sectt0021">Interpolating motion fields on the manifold and 3D reconstruction</ce:section-title><ce:para id="para0051" view="all">If the motion model has not yet fully sampled all the possible motion states of the new breathing pattern, it is important that it has the ability to interpolate between the motion states which are already there.</ce:para><ce:para id="para0052" view="all">In order to estimate the 2D motion field for a slice position, <ce:italic>κ</ce:italic> nearest neighbours are identified for each slice position as described in the previous section. The estimated motion field is then given as a weighted average of the <ce:italic>κ</ce:italic> motion fields corresponding to those nearest neighbours. That is, the estimated motion field for a slice position <ce:italic>q</ce:italic> is given by
<ce:display><ce:formula id="eq0007"><ce:label>(7)</ce:label><mml:math altimg="si62.gif" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>η</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>c</mml:mi><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>η</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <mml:math altimg="si63.gif" overflow="scroll"><mml:mrow><mml:mi>η</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:math> are the <ce:italic>κ</ce:italic> nearest neighbours on the manifold of slice position <ce:italic>q</ce:italic> to the low-dimensional point <mml:math altimg="si64.gif" overflow="scroll"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math> from a slice position <ce:italic>p</ce:italic> which is sharing a group with <ce:italic>q</ce:italic>. Furthermore, <mml:math altimg="si65.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>ω</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:italic>ω<ce:inf loc="post">i</ce:inf></ce:italic> is distance of each neighbour to <mml:math altimg="si64.gif" overflow="scroll"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math> in the manifold embedding. This process is illustrated in the close-up of <mml:math altimg="si5.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">G</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> which is shown in <ce:cross-ref id="crf0103" refid="fig0006">Fig. 6</ce:cross-ref><ce:float-anchor refid="fig0006"/>. Note that the distances <ce:italic>ω<ce:inf loc="post">i</ce:inf></ce:italic> could also be used to estimate how well the manifold is sampled around a given motion state which could be used to derive a confidence measure for motion estimation. However, this is not investigated further in this paper.</ce:para><ce:para id="para0053" view="all">The <mml:math altimg="si66.gif" overflow="scroll"><mml:msubsup><mml:mi>c</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> for all sagittal slice positions <mml:math altimg="si67.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:math> are then stacked into a pseudo 3D motion field, i.e. a dense 3D motion field lacking the L-R component. This 3D motion estimate is the output of the motion model given the 2D surrogate image <mml:math altimg="si54.gif" overflow="scroll"><mml:msubsup><mml:mi>b</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math> as input. Note that the coronal motion field from slice position <mml:math altimg="si16.gif" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math> is currently only used for the propagation of manifold coordinates but not for the reconstruction. This means the motion field from the coronal slice position will not be part of the volume.</ce:para></ce:section><ce:section id="sec0018" view="all"><ce:label>3.3.4</ce:label><ce:section-title id="sectt0022">Updating the model and adaptivity</ce:section-title><ce:para id="para0054" view="all">The mechanism of embedding the new slice motion field into the corresponding groups automatically updates the model. The new motion fields, after being used to stack a 3D motion field, stay in the model and may be used themselves in the future for new motion estimations.</ce:para><ce:para id="para0055" view="all">In this manner, as the application phase goes on, more and more data is added to the model making it adaptive. In the case of respiratory drift or changes in the breathing pattern the model does not lose its validity but rather incorporates these new motion patterns.</ce:para></ce:section></ce:section></ce:section><ce:section id="sec0019" view="all"><ce:label>4</ce:label><ce:section-title id="sectt0023">Experiments and results</ce:section-title><ce:para id="para0056" view="all">In order to validate our proposed autoadaptive motion model (AAMM) technique we compared it to two versions of the method, each with one of our major novelties removed: AAMM without the autoadaptivity, and AAMM without the incorporation of slices of different orientations in the groupwise manifold alignment step. That is, we compared the following techniques:
<ce:list id="celist0004"><ce:list-item id="celistitem0006"><ce:label>•</ce:label><ce:para id="para0057" view="all">AAMM: The proposed autoadaptive motion modelling method as described in <ce:cross-ref id="crf0104" refid="sec0008">Section 3</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id="celistitem0007"><ce:label>•</ce:label><ce:para id="para0058" view="all">AAMM (no adapt.): The proposed method without the adaptivity. This means that after each update step we discarded the most recently added 2D motion field again.</ce:para></ce:list-item><ce:list-item id="celistitem0008"><ce:label>•</ce:label><ce:para id="para0059" view="all">SGA: The proposed AAMM method but without using the coronal input slices. Essentially, this is our simultaneous groupwise manifold alignment technique (<ce:cross-ref id="crf0105" refid="bib0002">Baumgartner et al., 2014a</ce:cross-ref>) extended to use sagittal motion fields instead of coronal images. The adaptivity was implemented in exactly the same way as for AAMM with the sole exception that there were no coronal input slices.</ce:para></ce:list-item></ce:list></ce:para><ce:para id="para0060" view="all">The experiments in this section aim to answer the following main research questions:
<ce:list id="celist0001"><ce:list-item id="celistitem0009"><ce:label>1.</ce:label><ce:para id="para0061" view="all">How does autoadaptivity affect the motion estimates after a short calibration phase with a constant breathing pattern?</ce:para></ce:list-item><ce:list-item id="celistitem0010"><ce:label>2.</ce:label><ce:para id="para0062" view="all">Can the autoadaptive motion model adapt to a previously unseen breathing pattern?</ce:para></ce:list-item><ce:list-item id="celistitem0011"><ce:label>3.</ce:label><ce:para id="para0063" view="all">Can the method be applied using real MR data?</ce:para></ce:list-item></ce:list></ce:para><ce:para id="para0064" view="all">In order to pursue these questions, we evaluate the three methods described above on synthetic data derived from 6 volunteer scans and on real data acquired from 4 volunteers. In Experiment 1 (<ce:cross-ref id="crf0106" refid="sec0023">Section 4.2.2</ce:cross-ref>), synthetic data representing normal free breathing is generated to answer the first research question. In Experiment 2 (<ce:cross-ref id="crf0107" refid="sec0024">Section 4.2.3</ce:cross-ref>), additionally, synthetic data which corresponds to a deep breathing pattern is generated in order to investigate the second of the above questions. Lastly, in Experiment 3, the algorithms are evaluated on real volunteer scans acquired over 20 min. Using this data we seek to answer the third research question and investigate the method’s feasibility in a real MR-guided scenario. Furthermore, it is investigated how the methods respond to natural, gradual changes in the breathing pattern which may not have been observed during model calibration and whether the proposed technique can maintain motion estimation accuracy in such circumstances.</ce:para><ce:para id="para0065" view="all">Note that no comparison of AAMM to any other state-of-the-art motion modelling techniques was performed. All motion models from the literature follow the traditional motion modelling paradigm (see <ce:cross-ref id="crf0108" refid="fig0001">Fig. 1</ce:cross-ref>) and could not be built using the 2D slice-by-slice data used in this work. Thus an evaluation on equal terms was not feasible.</ce:para><ce:section id="sec0020" view="all"><ce:label>4.1</ce:label><ce:section-title id="sectt0024">Parameter choices</ce:section-title><ce:para id="para0066" view="all">We chose the free parameters of the investigated techniques based on our previous experience with SGA. In <ce:cross-ref id="crf0109" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> we investigated the optimal values for the reduced dimensionality <ce:italic>d</ce:italic>, and the weighting parameter <ce:italic>μ</ce:italic> (see <ce:cross-ref id="crf0110" refid="eq0002">Eq. (2)</ce:cross-ref>). Furthermore, we found that the method is not significantly affected by the choices of the kernel shape parameter <ce:italic>σ</ce:italic> (see <ce:cross-ref id="crf0111" refid="eq0004">Eq. (4)</ce:cross-ref>) and the number of nearest neighbours <ce:italic>k</ce:italic> used in the LLE cost function (see <ce:cross-ref id="crf0112" refid="eq0001">Eq. (1)</ce:cross-ref>). Based those findings, here we chose the following parameters for all of the methods: <mml:math altimg="si68.gif" overflow="scroll"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math>.</ce:para><ce:para id="para0067" view="all">In <ce:cross-ref id="crf0113" refid="bib0002">Baumgartner et al. (2014a)</ce:cross-ref> we set the parameter <ce:italic>k</ce:italic> to half the number of acquired slices per slice position. In this work, the number of 2D motion fields increased steadily as the model was applied. Consequently, we continually adapted the parameter <ce:italic>k</ce:italic> to the current data size. That is, we set
<ce:display><ce:formula id="ueq0002"><mml:math altimg="si69.gif" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>τ<ce:inf loc="post">p</ce:inf></ce:italic> is the number of 2D motion fields per slice position currently part of the respective groups.<ce:float-anchor refid="fig0007"/></ce:para></ce:section><ce:section id="sec0021" view="all"><ce:label>4.2</ce:label><ce:section-title id="sectt0025">Experiments on synthetic data</ce:section-title><ce:para id="para0068" view="all">To quantitatively assess our method we generated very realistic synthetic 2D motion fields containing two breathing types by mimicking an actual slice-by-slice acquisition process as will be described in <ce:cross-ref id="crf0114" refid="sec0022">Section 4.2.1</ce:cross-ref>. We separately generated two synthetic datasets with two different breathing types: normal breathing, and deep breathing. The normal breathing data was used in Experiment 1 (<ce:cross-ref id="crf0115" refid="sec0023">Section 4.2.2</ce:cross-ref>), and a combination of both breathing types was used for Experiment 2 (<ce:cross-ref id="crf0116" refid="sec0024">Section 4.2.3</ce:cross-ref>).</ce:para><ce:section id="sec0022" view="all"><ce:label>4.2.1</ce:label><ce:section-title id="sectt0026">Generation of realistic synthetic data</ce:section-title><ce:para id="para0069" view="all">The method to generate synthetic data in this work differs from the approach we took in our previous works (<ce:cross-refs id="crfs0021" refid="bib0004 bib0003 bib0002">Baumgartner et al., 2014b; 2013; 2014a</ce:cross-refs>). Previously, we directly transformed a breath hold volume using motion fields derived from low-resolution volumes. However, using this method resulted in a dataset where all slice positions have an identical distribution of respiratory states, which is unrealistic and oversimplifies the problem of finding matching motion states from different slice positions. Here, we aimed to generate 50 synthetic slices per slice position, such that no respiratory state was exactly repeated in the whole dataset.</ce:para><ce:para id="para0070" view="all">The underlying idea of our data generation framework was to first build a simple linear subject specific motion model based on two 1D navigators and 3D motion fields derived from short dynamic low-resolution 3D MR scans under different breathing modes. Note that the motion model used to generate the synthetic data is distinct from the autoadaptive motion model we are proposing in this work. By generating random samples of synthetic navigator values and using them as input to the motion model we obtained synthetic, but realistic, respiratory motion deformations. Note that the number of random samples that can be generated is not limited and can be freely chosen. The respiratory motion deformations, on one hand, served as a ground truth for our experiments, and on the other hand, were used to generate synthetic slice-by-slice data by transforming a slice-by-slice breath hold scan. This approach had two main advantages: 1) more realistic sampling of respiratory positions, 2) even though only a 50 s scan was used as input, an arbitrary number of 2D slices could be generated using this generating framework.</ce:para><ce:para id="para0071" view="all">In the following we explain each step in detail. The generation of the synthetic data is summarised in <ce:cross-ref id="crf0117" refid="fig0007">Fig. 7</ce:cross-ref>. We split the description of the generation into two parts:
<ce:list id="celist0002"><ce:list-item id="celistitem0012"><ce:label>1.</ce:label><ce:para id="para0072" view="all">The generation of realistic ground truth motion (see <ce:cross-ref id="crf0118" refid="fig0007">Fig. 7</ce:cross-ref>a).</ce:para></ce:list-item><ce:list-item id="celistitem0013"><ce:label>2.</ce:label><ce:para id="para0073" view="all">The generation of synthetic slice-by-slice images and the derivation of slice-by-slice motion fields from them (see <ce:cross-ref id="crf0119" refid="fig0007">Fig. 7</ce:cross-ref>b).</ce:para></ce:list-item></ce:list></ce:para><ce:para id="para0074" view="all">For the generation of the ground truth data, in a first step we acquired two sets of 50 3D low-resolution MR volumes on a Philips Achieva 3T MR system using a cardiac-triggered T1-weighted gradient echo sequence with an acquired image resolution of 1.5 × 5 × 4.1 mm<ce:sup loc="post">3</ce:sup> (S-I, A-P, L-R), an acquisition time of approximately 600 ms per volume, a SENSE-factor of 2 in A-P and a SENSE-factor of 4 in L-R, TR/TE = 3.3 ms/0.9 ms, a FA of 10°, and a field of view of 500 × 450 × 245 mm<ce:sup loc="post">3</ce:sup> covering the entire thorax. The highest resolution was chosen in the S-I direction, where most respiratory motion occurs (<ce:cross-ref id="crf0120" refid="bib0042">Seppenwoolde et al., 2002</ce:cross-ref>). For the first set of images the volunteers were instructed to breathe freely (i.e. normal breathing). For the second set of images we instructed the volunteers to take slow, deep breaths (i.e. deep breathing).</ce:para><ce:para id="para0075" view="all">From these two sets of volumes we generated two separate synthetic datasets; a normal breathing and a deep breathing one. To this end we derived 50 B-spline grid displacements for each breathing type by registering the volumes to an exhale volume chosen manually from the set of normal breathing images. The registration was performed using NiftyReg (<ce:cross-ref id="crf0121" refid="bib0026">Modat et al., 2010</ce:cross-ref>) using the same parameters as for the real data, that is, 3 hierarchy levels, a final grid spacing of 15 mm in each direction and no bending energy penalty term. Furthermore, we extracted two series of 50 navigator signals <ce:italic>s</ce:italic><ce:inf loc="post">1</ce:inf>, <ce:italic>s</ce:italic><ce:inf loc="post">2</ce:inf> from the images by measuring the displacements of small rectangular regions on the dome of the left hemidiaphragm and the anterior chest wall (<ce:cross-ref id="crf0122" refid="bib0037">Savill et al., 2011</ce:cross-ref>). We chose two signals to increase the amount of respiratory variabilities captured in the resulting model. Next, we formed a motion model for each breathing type by fitting a linear function of the time series of navigator signal values to the displacements of each B-spline grid point (<ce:cross-ref id="crf0123" refid="bib0024">McClelland et al., 2013</ce:cross-ref>), i.e.
<ce:display><ce:formula id="eq0008"><ce:label>(8)</ce:label><mml:math altimg="si70.gif" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">α</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">α</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:bold><ce:italic>α</ce:italic></ce:bold><ce:inf loc="post">1</ce:inf>, <ce:bold><ce:italic>α</ce:italic></ce:bold><ce:inf loc="post">2</ce:inf>, <ce:bold><ce:italic>α</ce:italic></ce:bold><ce:inf loc="post">3</ce:inf> are the parameters of the motion model and <ce:bold>v</ce:bold>(<ce:bold>t</ce:bold>) are the grid displacements at grid location <ce:bold>t</ce:bold>.</ce:para><ce:para id="para0076" view="all">In the next step, we fitted a 2D distribution to the navigator signal values for each breathing mode using kernel density estimation (<ce:cross-ref id="crf0124" refid="bib0035">Rosenblatt et al., 1956</ce:cross-ref>). We then sampled <ce:italic>S</ce:italic> random navigator value pairs <mml:math altimg="si71.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math> from this distribution. In the final synthetic datasets each 2D slice was associated with a ground truth 3D motion field. Hence, we needed to draw as many synthetic navigator values as the total number of synthetic 2D slices in each dataset. Since we aimed to generate 50 slices per slice position, we needed to sample <mml:math altimg="si72.gif" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo>·</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math> navigator values, where <ce:italic>L</ce:italic> is the total number of slice positions in the synthetic sequence. Next, by substituting the sampled values <mml:math altimg="si71.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math> into <ce:cross-ref id="crf0125" refid="eq0008">Eq. (8)</ce:cross-ref> we obtained <ce:italic>S</ce:italic> synthetic B-spline transformations per breathing mode, which were then used for the generation of the ground truth 3D motion fields as well as for the generation of the synthetic slice-by-slice data. The ground truth motion fields were derived simply by interpolating a dense motion field using the voxel sizes of the slice-by-slice breath hold volumes described below.</ce:para><ce:para id="para0077" view="all">In the following, we will describe how the synthetic slice-by-slice data was generated (see <ce:cross-ref id="crf0126" refid="fig0007">Fig. 7</ce:cross-ref>b). In addition to the low-resolution volumes, we also acquired all sagittal slice positions and one coronal slice position in two exhale breath hold acquisitions using the same protocol as for the real data, which was described in <ce:cross-ref id="crf0127" refid="sec0009">Section 3.1</ce:cross-ref>. The breath hold data was then transformed using the synthetic B-spline grid displacements. This led to a sequence of <ce:italic>S</ce:italic> synthetic slice-by-slice volumes for each of the breathing types. In the real acquisitions at each time point we can observe only one slice position, and hence, we sampled only one slice from each of these volumes, and discarded the rest. However, note that each slice was still associated with a 3D ground truth motion field (see <ce:cross-ref id="crf0128" refid="fig0007">Fig. 7</ce:cross-ref>a). The sampled slices were chosen according to the acquisition order of the real data described in <ce:cross-ref id="crf0129" refid="sec0009">Section 3.1</ce:cross-ref>. This sampled data constituted the synthetic slice-by-slice dataset and was the synthetic equivalent to the data obtained from a real slice-by-slice scan. As part of the model calibration phase, the slice-by-slice image data was then registered in 2D to the corresponding breath hold slices in order to obtain slice-by-slice 2D motion fields which are the input to the proposed AAMM. The parameters used for the registration were the same as in <ce:cross-ref id="crf0130" refid="sec0009">Section 3.1</ce:cross-ref>.</ce:para><ce:para id="para0078" view="all">Note that in order to make the acquisition of 3D dynamic volumes feasible, compromises had to be made in the image quality. The relatively low-resolutions in A-P and L-R directions, and the high SENSE factors led to artefacts and blurring of certain structures. Furthermore, the residual motion during the volume acquisition may cause slight blurring, especially during deep breathing, which may in turn lead to underestimation of the motion close to end-inhale. Nevertheless, we found that the simulated 2D images and motion fields reasonably approximated a real 2D MR acquisition.</ce:para></ce:section><ce:section id="sec0023" view="all"><ce:label>4.2.2</ce:label><ce:section-title id="sectt0027">Experiment 1: synthetic training adaptivity</ce:section-title><ce:para id="para0079" view="all">In this section, we investigate the autoadaptive behaviour of our proposed method in the presence of an approximately constant breathing pattern. We quantitatively assessed the motion estimation accuracy using the three compared models on the synthetic, normal-breathing slice-by-slice data which was generated using the technique described in the previous section. Note that the resulting data mimics an acquisition of around 20–25 min. However, it can only reflect breathing patterns observed in the 50 s normal breathing dynamic 3D MR scan. On average L-R motion accounted for 15.85% of the total motion, and the A-P and S-I accounted for 20.44% and 63.71%, respectively.</ce:para><ce:para id="para0080" view="all">The motion estimation accuracy was quantitatively assessed using the three compared models on the synthetic slice-by-slice data. Each of the three stages of motion modelling shown in <ce:cross-ref id="crf0131" refid="fig0001">Fig. 1</ce:cross-ref> was performed, i.e. model calibration, model formation and model application. The synthetic data generation can be seen as a synthetic model calibration stage yielding slice-by-slice motion fields. In the next step, we formed the model by embedding a subset of the synthetic data using the three compared methods. We used 10 slices from each slice position for the initial formation of the model. Obtaining this amount of data in a real (cardiac-gated) scan would take approximately 5 min. We then applied the motion model by continually adding all remaining slices one after the other, and at each time step evaluated the accuracy of the estimated motion against the 3D ground truth motion field corresponding to the newest update slice.</ce:para><ce:para id="para0081" view="all">In <ce:cross-ref id="crf0132" refid="fig0008">Fig. 8</ce:cross-ref><ce:float-anchor refid="fig0008"/> we show the resulting motion estimation error curves for all of the volunteers during a synthetic application phase. The evolution of the errors is shown over the duration of the application phase, which is the time it would take to acquire and add the remaining slices in a real scenario. Here we assumed an acquisition frequency of one slice per second which corresponds to a heart rate of 60 beats per minute. Each point in <ce:cross-ref id="crf0133" refid="fig0008">Fig. 8</ce:cross-ref> represents the mean error obtained over a time interval of 2<ce:italic>L</ce:italic> update slices, i.e. the time taken to acquire each slice position twice.</ce:para><ce:para id="para0082" view="all">In order to quantitatively evaluate the 3D motion estimation errors and the adaptivity of the compared techniques, we split the application phase into 5 time periods <mml:math altimg="si73.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> of equal length. Those are highlighted in <ce:cross-ref id="crf0134" refid="fig0008">Fig. 8</ce:cross-ref>. The mean 3D motion estimation errors in the corresponding time intervals using the three methods for all 6 volunteers can be found in <ce:cross-ref id="crf0135" refid="tbl0001">Table 1</ce:cross-ref> in the supplementary materials.</ce:para><ce:para id="para0083" view="all">For all volunteers the AAMM technique significantly (<ce:italic>p</ce:italic> &lt; 0.01) outperformed the other two methods in all of the intervals as can be seen by comparing to the error curves shown in <ce:cross-ref id="crf0136" refid="fig0008">Fig. 8</ce:cross-ref> and the figures in <ce:cross-ref id="crf0137" refid="tbl0001">Table 1</ce:cross-ref> in the supplementary materials. Significance was assessed using a 1-tailed Wilcoxon signed rank test since the error distributions were generally not symmetric. The estimation errors for AAMM and its non-adaptive counterpart, AAMM (no adapt.), were similar in the beginning of the application phase, but as anticipated, as the application phase went on, the AAMM technique continually improved its accuracy by incorporating more and more data into the model. On average the motion estimation of AAMM improved by 22.94% in <ce:italic>T</ce:italic><ce:inf loc="post">5</ce:inf> with respect to its non-adaptive counterpart. However, the method has already significantly adapted to the breathing pattern in <ce:italic>T</ce:italic><ce:inf loc="post">2</ce:inf>, i.e. after between 3 and 7 min of imaging, where motion estimations where on average 16.87% more accurate than at the beginning of the adaptation phase. By visually inspecting the curves for AAMM in <ce:cross-ref id="crf0138" refid="fig0008">Fig. 8</ce:cross-ref> it can be seen that for many volunteers (in particular volunteers A, D, E, and F) the error curves start to flatten approximately around the 7 min mark. From this it can be concluded that a longer calibration scan of around 12 min would be optimal, that is the 5 min that were used for calibration in this experiment plus 7 min worth of data added during the application phase. Note that this time could be significantly reduced if a non-cardiac-gated sequence was used.</ce:para><ce:para id="para0084" view="all">The AAMM technique also consistently performed better than SGA, i.e. the version without coronal slices. This shows that the addition of data from a coronal slice position in the manifold alignment step improves the 3D motion estimation accuracy.</ce:para><ce:para id="para0085" view="all">A fraction of the remaining errors was due to the fact that the technique currently cannot estimate L-R motion. In this experiment on synthetic data the L-R motion was responsible for on average 46.53% of the remaining motion estimation error of the AAMM technique, or on average 0.63 mm. The motion estimation error did not vary depending on the position of the surrogate slice.</ce:para><ce:para id="para0086" view="all">Note that the error curves did not necessarily steadily decrease over the entire period of time, but exhibited some variations usually affecting all methods equally. See for example <ce:italic>T</ce:italic><ce:inf loc="post">3</ce:inf> and <ce:italic>T</ce:italic><ce:inf loc="post">4</ce:inf> of volunteer C (<ce:cross-ref id="crf0139" refid="fig0008">Fig. 8</ce:cross-ref>c). The motion estimation error tends to be smaller for exhale motion states than for inhale motion states, since the motions involved are smaller. The variations in the error can be explained by differences in the frequency of occurrence of exhale or inhale states. For example, there were a large amount of inhale motion states around the 11 min mark of volunteer C, and a large amount of exhale states around the 9 min mark. The variations in the error between volunteers can be explained by the fact that the synthetic data was derived from real volunteers scans and some volunteers naturally had larger or more complicated motion patterns.</ce:para></ce:section><ce:section id="sec0024" view="all"><ce:label>4.2.3</ce:label><ce:section-title id="sectt0028">Experiment 2: synthetic adaptivity to a new breathing pattern</ce:section-title><ce:para id="para0087" view="all">In Experiment 1, we investigated how the autoadaptive technique behaves if more data of the same breathing pattern is added. However, the data used in that experiment does not reflect any of the long term changes which may occur in real data, such as drift or changes in breathing mode. In order to investigate if the model can adapt to previously unseen breathing patterns, for this experiment, a second synthetic dataset was generated using a 50 s dynamic 3D MR scan performed under deep breathing as input as was described in <ce:cross-ref id="crf0140" refid="sec0022">Section 4.2.1</ce:cross-ref>. That scan was performed immediately after the 50 s free breathing scan, but the volunteers were instructed to take deep quiet breaths. For all volunteers this resulted in synthetic data with significantly longer respiratory cycles and significantly larger displacements of the anatomy. The average magnitude of the motion varied significantly between volunteers. On average, L-R motion accounted for 17.59% of the total motion, and the A-P and S-I accounted for 23.76% and 58.65%, respectively.</ce:para><ce:para id="para0088" view="all">In order to investigate how the examined methods would react to this new deep breathing pattern, in a first step the models were calibrated and formed by using all time points of the normal breathing data. This means that the models had largely adapted to the normal breathing pattern. Note that the state of the models was the same as for the last time point of the AAMM technique in <ce:cross-ref id="crf0141" refid="fig0008">Fig. 8</ce:cross-ref>. In a next step, the motion models were applied using the synthetic deep breathing data. That is, the 2D deep breathing motion fields were added to the model one-by-one, and the motion estimation error was evaluated exactly as in Experiment 1. The resulting error curves are shown in <ce:cross-ref id="crf0142" refid="fig0009">Fig. 9</ce:cross-ref><ce:float-anchor refid="fig0009"/>, where each point corresponds to an average over 2<ce:italic>L</ce:italic> motion estimates. In order to assess the performance of the models quantitatively, the errors for each subject were averaged within 5 time intervals of equal length. The quantitative error figures for all volunteers are given in Table 2 in the supplementary materials.</ce:para><ce:para id="para0089" view="all">As before the AAMM method significantly outperformed the two other techniques for all volunteers and for all time intervals. As expected, the estimation errors for AAMM and its non-adaptive counterpart AAMM (no adapt.) started at similar values in <ce:italic>T</ce:italic><ce:inf loc="post">1</ce:inf>, but AAMM led to improved motion estimates the more data of the new breathing type was added to the model. Already in time-interval <ce:italic>T</ce:italic><ce:inf loc="post">2</ce:inf>, AAMM led to significant average improvements of 21.45% over AAMM (no adapt.) In <ce:italic>T</ce:italic><ce:inf loc="post">5</ce:inf>, the average improvements amounted to 27.10%. As before AAMM also performed significantly better than the SGA technique, which is due to the additional robustness added by the coronal slice employed in the AAMM technique.</ce:para><ce:para id="para0090" view="all">For all examined methods the motion estimation errors were significantly larger for the deep breathing pattern than for the normal breathing pattern in Experiment 1. This is due to the fact that the deep breathing data contained much larger motion amplitudes. The variations between the subjects are due to the fact that the extent of the deep breathing motion varied from volunteer to volunteer. The average error over all subjects due to the missing motion estimates in the L-R direction amounted to 42.15% of the motion estimation error of AAMM, or 2.28 mm. As before, the motion estimation error did not vary depending on the position of the surrogate slice.</ce:para></ce:section></ce:section><ce:section id="sec0025" view="all"><ce:label>4.3</ce:label><ce:section-title id="sectt0029">Experiment 3: adaptivity on real data</ce:section-title><ce:para id="para0091" view="all">For the experiments on real data we acquired real dynamic slice-by-slice data and a slice-by-slice breath hold volume as described in <ce:cross-ref id="crf0143" refid="sec0009">Section 3.1</ce:cross-ref>. In order to validate the model we acquired the data for the calibration and model formation, and for the model application in one long scan. Overall, we acquired each slice position 40 times which typically resulted in an approximately 20 min scan. Additionally, we acquired a 1D pencil beam navigator signal from the left hemi-diaphragm immediately before the acquisition of each 2D slice, which we used to validate the accuracy of the motion estimations, but not for any part of the motion modelling framework.</ce:para><ce:para id="para0092" view="all">As in Experiment 1, we formed the three models on the motion fields derived from the first 10 slices acquired from each slice position. During the model application phase we then added the remainder of the slices one by one and estimated a 3D motion field for each of the input slices. Note that according to our findings in Experiment 1, ideally the model should be trained with 12 min of slice-by-slice data, or 24 slices per slice position in order to guarantee that the models have been trained to convergence. However, since this would not leave enough data to adequately study the adaptivity, we chose to use only the first 10 slices of each slice position and leave 30 slices per slice position to investigate the methods’ behaviour during the model application phase. However, as a consequence we are underestimating the accuracy of the non-adaptive model AAMM (no adapt.).</ce:para><ce:para id="para0093" view="all">Because, for the real data, no ground truth motion was available, we instead transformed the slice-by-slice breath hold volume using each estimated 3D motion field and extracted a 1D navigator value from a rectangular region of interest on the dome of the left hemi-diaphragm, i.e. approximately the same location from which the real pencil beam navigator was acquired. Note that for both the pencil beam navigator and the signal estimated from the reconstructed volumes, the displacements in millimetres are known, however, the two signals are offset by an unknown value from each other. For visualisation of the navigator curves in <ce:cross-ref id="crf0144" refid="fig0011">Fig. 11</ce:cross-ref>, we corrected the curves estimated by AAMM and pencil beam navigator curves for this shift by subtracting the mean of each from itself. For the quantitative evaluation, we chose to report the normalised cross correlation (NCC) between the signals because this measure is invariant to such offsets. For perfect motion estimation the extracted navigator signal should be strongly correlated with the pencil beam navigator. In reality, however, this correlation depends on the accuracy of the estimated 3D motion.</ce:para><ce:para id="para0094" view="all">In order to quantitatively assess the adaptivity of the compared methods we measured the NCC of the estimated navigator signal with the pencil beam navigator over fixed intervals. In <ce:cross-ref id="crf0145" refid="fig0010">Fig. 10</ce:cross-ref><ce:float-anchor refid="fig0010"/><ce:float-anchor refid="fig0011"/> we show the progression of this correlation for all four volunteers. For a robust estimation of the NCC we chose intervals of twice the number of slice positions, i.e. 2<ce:italic>L</ce:italic>, to calculate each error point.</ce:para><ce:para id="para0095" view="all">As for the synthetic data we divided the entire application phase into 5 larger time intervals <mml:math altimg="si74.gif" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math>. Table 3 in the supplemental materials contains the NCC between the pencil beam navigator and the retrospectively derived navigator signal for all volunteers over the entire duration of these periods.</ce:para><ce:para id="para0096" view="all">AAMM outperformed the other two methods for most time intervals. Furthermore, as for the synthetic data, it could again be observed that the motion estimation accuracy, as measured by NCC, improved over the duration of the application phase. Note that the data in this experiment was derived from a relatively long scan, where natural changes in respiration patterns are very likely to happen due to relaxation or, occasionally, due to the volunteer falling asleep in the scanner. We observed that motion estimation accuracy sometimes dropped due to such changes. For example, volunteer II (see <ce:cross-ref id="crf0146" refid="fig0010">Fig. 10</ce:cross-ref>b) started taking deep breaths around <ce:italic>T</ce:italic><ce:inf loc="post">3</ce:inf>, but then returned to his previous breathing pattern. Had he continued breathing deeply, presumably our model would have adapted to that pattern. Note that for volunteer III the NCC quickly approaches its maximum for AAMM, but continually decreases for its non-adaptive counterpart. AAMM manages to maintain the motion estimation accuracy for the remainder of the session. By examining the original pencil beam navigator signal shown in the top row of <ce:cross-ref id="crf0147" refid="fig0011">Fig. 11</ce:cross-ref>, it can be seen that the subject exhibited a significant drift of close to 10 mm in the respiration base level throughout the imaging session. By comparing this signal to the estimated signals by AAMM and AAMM (no adapt.) it can be observed that AAMM manages to follow this drift whilst AAMM (no adapt.) cannot adapt its range of motion predictions.</ce:para><ce:para id="para0097" view="all">In contrast to the synthetic experiments, in the experiments on real data, SGA consistently performed worse than the other examined methods. We found that on real data SGA was fundamentally not robust to the sagittal input slices. We observed that respiratory information often failed to propagate through the body middle, that is for example, an input slice from the left body half would often fail to properly estimate motion in the right body half and vice versa. Incorporating data from coronal slice positions in the manifold alignment step of AAMM effectively solved this problem.</ce:para></ce:section></ce:section><ce:section id="sec0026" view="all" role="discussion"><ce:label>5</ce:label><ce:section-title id="sectt0030">Discussion</ce:section-title><ce:para id="para0098" view="all">We have proposed a novel motion modelling framework which enables accurate 3D motion estimations over extended periods of time in the scenario of MR-guided interventions. This is achieved by using partial motion information, i.e. 2D motion fields estimated from MR slices, to form as well as to apply the motion model. In contrast to 3D MR imaging, 2D MR slices can be acquired close to real-time and offer better in-plane image quality. By acquiring 2D MR data from variable imaging planes we are able to combine the image quality of 2D MR with the coverage of 3D MR. The fact that the calibration and surrogate data are of the same type inherently enables the proposed motion model to automatically adapt to changing breathing patterns without the need to rebuild the model during the application phase.</ce:para><ce:para id="para0099" view="all">The vast majority of motion models in the literature cannot adapt to changing breathing patterns and need to be rebuilt entirely if the correlation between the surrogate and the motion data loses validity (<ce:cross-ref id="crf0148" refid="bib0024">McClelland et al., 2013</ce:cross-ref>). A small number of papers such as <ce:cross-ref id="crf0149" refid="bib0040">Schweikard et al. (2005)</ce:cross-ref> and <ce:cross-ref id="crf0150" refid="bib0008">Cho et al. (2010)</ce:cross-ref> proposed adaptive techniques, which have the ability to update the model using intra-fractional imaging. These models can only update the model intermittently whereas the proposed AAMM framework can make use of all the surrogate data acquired to update the model continuously. Adaptive approaches not requiring intra-fractional imaging such as <ce:cross-ref id="crf0151" refid="bib0012">Fassi et al. (2014)</ce:cross-ref> can also continually adapt, but, nevertheless, may lose validity if the change in respiratory pattern is more complicated than a simple drift, such as, for example, a change to a new breathing pattern.</ce:para><ce:para id="para0100" view="all">We implemented the autoadaptive motion model by extending our previously proposed simultaneous groupwise manifold alignment (SGA) technique to use 2D motion fields as input. This approach has two important limitations: Through-plane motion may distort the motion estimations and motion in the direction orthogonal to the slices cannot be estimated. <ce:cross-ref id="crf0152" refid="bib0027">Park et al. (2012)</ce:cross-ref> found that liver tumour motion is smallest in the L-R direction with a magnitude of 3.0 mm on average. In comparison, the average motions in the S-I and A-P directions amount to 17.9 mm and 5.1 mm, respectively. Similarly, <ce:cross-ref id="crf0153" refid="bib0042">Seppenwoolde et al. (2002)</ce:cross-ref> found that the S-I motion of lung tumours was 12 mm on average in the lower lobes, while A-P and L-R motion was 2.2 mm and 1.2 mm on average. Hence, in order to minimise the effects of through-plane motion we derive the motion from sagittal input slices. The large differences in the appearance of sagittal slices acquired from different locations necessitated the incorporation of coronal images from a single slice position. In order to combine sagittal and coronal data we substantially expanded the methodology of SGA to arrive at the proposed AAMM technique.</ce:para><ce:para id="para0101" view="all">We demonstrated a proof-of-principle of our proposed motion modelling framework and validated it on realistic synthetic and real data. Our experiments show that the autoadaptive motion model is able to adapt to novel breathing patterns and can thus produce significantly better 3D motion estimations over the duration of an MR-guided treatment compared to its non-adaptive counterpart. Furthermore, the experiments show that the incorporation of data from a single coronal slice position leads to significant improvements in motion estimation. Note that we did not compare the performance of AAMM to traditional motion models from the literature. Our proposed method follows a new paradigm using 2D MR data in all stages of the model, which is conceptually different from the classical motion model paradigm. Hence, it was not possible to compare against existing techniques using the same data. In the synthetic experiments we could have trained a classical motion model on the 3D ground truth motion fields. However, a comparison to such a model would not have been on equal terms because the synthetic 2D motion fields were derived through an additional registration step.</ce:para><ce:para id="para0102" view="all">The proposed technique offers a novel way of performing adaptive motion modelling, however, the method has only been evaluated on healthy volunteers and there are a number of challenges which need to be addressed before the technique will be ready for use in a clinical system. In the following we will discuss a number of limitations and possible extensions of the technique.</ce:para><ce:para id="para0103" view="all">The current implementation of the proposed autoadaptive framework suffers from significant latency. In the current system, for each update, the following steps need to be performed: 2D MR image acquisitions and reconstruction ( ∼ 200 ms), 2D registration ( ∼ 500 ms) and the groupwise embedding and lookup ( ∼ 100 ms). Consequently, the motion modelling system in its present form has a latency of around 800 ms, which would be unacceptable in a clinical scenario and would increase the motion prediction errors. However, we would like to stress that the focus of this paper is not an efficient implementation but rather a proof-of-principle of autoadaptive motion modelling. The large latency is <ce:italic>not</ce:italic> an inherent drawback of our proposed method. Rather, it is a result of the acquisition sequence and computational techniques used in this work. In the context of MR-guided interventions, <ce:cross-ref id="crf0154" refid="bib0032">Ries et al. (2010)</ce:cross-ref> have demonstrated that motion estimations can be obtained from 2D MR images with latencies less than 114 ms, and <ce:cross-ref id="crf0155" refid="bib0010">De Senneville et al. (2015)</ce:cross-ref> has proposed a framework which can provide motion estimations from 2D MR data with a latency of only 80 ms. Significant speed improvements could also be achieved for the groupwise manifold alignment with a more efficient parallel implementation, as the groups containing the aligned manifold embeddings can be processed independently of each other. In this manner it would be possible to reduce the computational times of the manifold alignment to just a few milliseconds by using a parallel implementation and a modern GPU (graphics processing unit) or multi-core work-station. It is therefore believed that an optimised version of the proposed autoadaptive motion modelling system may be able to run with update latencies close to 100 ms. The remaining latency could be addressed by combining the method with a motion prediction technique such as Kalman filtering (<ce:cross-refs id="crfs0022" refid="bib0043 bib0032">Sharp et al., 2004; Ries et al., 2010</ce:cross-refs>).</ce:para><ce:para id="para0104" view="all">In the present work the update frequency is limited by the cardiac gating of the images to around 1 Hz, based on a typical heart rate of 60 beats per minute. The reason cardiac gated images were employed was to isolate the respiratory motion for this study. The cardiac gating, however, is not an essential part of the technique and could be easily dropped if the region of interest excluded the heart as in the scenario of a MR-guided HIFU of the liver. For example, <ce:cross-ref id="crf0156" refid="bib0010">De Senneville et al. (2015)</ce:cross-ref> acquired 2D MR slices of the liver with a imaging frame-rate of 10 Hz. In the experiments in this paper it was found that the proposed system can significantly improve the motion estimation accuracy by close to 20% in less than 10 min. Potentially, however, much faster adaptivity could be achieved. Based on a hypothetical update frame-rate of 10 Hz, the same improvements in the motion estimation in the whole thorax could be achieved in as little as 1 min.</ce:para><ce:para id="para0105" view="all">Currently the motion is estimated only from sagittal 2D MR slices. This orientation was chosen to minimise the effects of through-plane motion. However, the remaining L-R motion may cause artefacts in the registration step of the calibration phase. Furthermore, the 3D motion estimations are obtained by simply stacking the 2D motion fields, which leads to motion fields lacking the L-R component. In the evaluation on synthetic data the missing L-R component accounted for over 40% of the remaining motion estimation error. This is a significant drawback of the presented method and extending it to account also for through-plane motion will be a priority in future work. Note that currently the coronal motion fields are used only in the groupwise manifold alignment step but are not part of the final 3D motion estimations. It may be possible to mitigate the through-plane motion effects by also using motion information derived from one or potentially several coronal slice positions in the 3D motion estimation step.</ce:para><ce:para id="para0106" view="all">Lastly, in the autoadaptive motion model in its present form all the data added is retained. The rationale behind this is that, in this manner, the model can go back to breathing patterns which were observed before a change occurred. A patient may, for example, go back and forth between a calm and a nervous breathing pattern as a result of certain actions of the surgeon or the progress of the treatment. However, the larger the model grows the more memory is used to store the 2D motion fields and the more computationally expensive it becomes to evaluate the updated group embeddings. It may therefore make sense to implement a “ring buffer” approach, where older data is discarded as new data is added to the model. An interesting future direction would be to automatically determine which data is essential to model certain breathing types and selectively delete data which is unlikely to be used again.</ce:para></ce:section><ce:section id="sec0027" view="all" role="conclusion"><ce:label>6</ce:label><ce:section-title id="sectt0031">Conclusion</ce:section-title><ce:para id="para0107" view="all">Modelling respiratory motion from MR data may provide a solution for correcting MR-guided treatments for respiratory motion. In particular it can provide intra-procedure 3D motion estimations in MR-guided interventions such as MRg-HIFU or MRg-RT. However, such treatments are typically performed in a time frame in which respiratory motion patterns are known to change, causing conventional motion models to lose their validity. This work demonstrates a proof-of-principle for a novel autoadaptive motion modelling framework which is calibrated and applied using the same type of data, i.e. 2D MR slices acquired from variable imaging planes. This allows the proposed motion model to continually adapt every time a new 2D slice is acquired and used to estimate 3D motion. A number of challenges must be addressed before the method can be applied in a clinical setting, in particular the long calibration time and large latency of 800 ms. Nevertheless, our novel motion modelling paradigm provides an important stepping stone which may allow lengthy MR-guided treatments to go on uninterrupted whilst the model continually maintains its ability to provide accurate, up-to-date 3D motion estimations, despite changing breathing patterns.</ce:para></ce:section><ce:section id="sec0029" view="all"><ce:section-title id="sectt0032">Data download</ce:section-title><ce:para id="para0108" view="all">The real 2D MR data acquired for the evaluation of our proposed framework in <ce:cross-ref id="crf0157" refid="sec0025">Section 4.3</ce:cross-ref> are freely available and can be downloaded from <ce:inter-ref id="interref1002" xlink:href="https://zenodo.org/record/55345" xlink:type="simple">https://zenodo.org/record/55345</ce:inter-ref> under the Creative Commons Attribution license.</ce:para></ce:section></ce:sections><ce:acknowledgment id="ack0001" view="all"><ce:section-title id="sectt0033">Acknowledgements</ce:section-title><ce:para id="para0109" view="all">This work was funded by EPSRC programme grant EP/H046410/1. This research was supported by the National Institute for Health Research (NIHR) Biomedical Research Centre at Guy’s and St Thomas’ NHS Foundation Trust and King’s College London. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health.</ce:para></ce:acknowledgment><ce:appendices view="all"><ce:section id="sec0030" view="compact-standard"><ce:section-title id="sectt0034">Supplementary material</ce:section-title><ce:para id="para0110" view="all">Supplementary material associated with this article can be found, in the online version, at <ce:inter-ref id="interref0001" xlink:href="http://dx.doi.org/10.1016/j.media.2016.06.005" xlink:type="simple">10.1016/j.media.2016.06.005</ce:inter-ref></ce:para></ce:section><ce:section id="sec0028" view="extended"><ce:label>Appendix A</ce:label><ce:section-title id="sectt0035">Supplementary materials</ce:section-title><ce:para id="para0111" view="all"><ce:display><ce:e-component id="ecom0001" role="raw-data"><ce:label>Supplementary Data S1</ce:label><ce:caption id="cap0013"><ce:simple-para id="spara0007" view="all">Supplementary Raw Research Data. This is open data under the CC BY license <ce:inter-ref id="interref0002" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:role="http://www.elsevier.com/xml/linking-roles/text/html" xlink:type="simple">http://creativecommons.org/licenses/by/4.0/</ce:inter-ref></ce:simple-para></ce:caption><ce:alt-text id="at0013" role="short">Supplementary Data S1</ce:alt-text><ce:link id="celink0013" locator="mmc1" xlink:type="simple" xlink:href="pii:S1361-8415(16)30082-2/mmc1"/></ce:e-component></ce:display></ce:para></ce:section></ce:appendices></body><tail view="all"><ce:bibliography id="bib001" view="all"><ce:section-title id="sectt0036">References</ce:section-title><ce:bibliography-sec id="bibsec002" view="all"><ce:bib-reference id="bib0001"><ce:label>Arnold, Preiswerk, Fasel, Salomir, Scheffler, Cattin, 2011</ce:label><sb:reference id="sbref0001"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Arnold</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Preiswerk</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Fasel</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Salomir</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Scheffler</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Cattin</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>3D organ motion prediction for MR-guided high intensity focused ultrasound</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. MICCAI</sb:maintitle></sb:title><sb:date>2011</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>623</sb:first-page><sb:last-page>630</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0002"><ce:label>Baumgartner, Kolbitsch, Balfour, Marsden, McClelland, Rueckert, King, 2014a</ce:label><sb:reference id="sbref0002"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Baumgartner</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Kolbitsch</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Balfour</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Marsden</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Rueckert</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>High-resolution dynamic MR imaging of the thorax for respiratory motion correction of PET using groupwise manifold alignment</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Image Anal.</sb:maintitle></sb:title><sb:volume-nr>18</sb:volume-nr></sb:series><sb:issue-nr>7</sb:issue-nr><sb:date>2014</sb:date></sb:issue><sb:pages><sb:first-page>939</sb:first-page><sb:last-page>952</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0003"><ce:label>Baumgartner, Kolbitsch, McClelland, Rueckert, King, 2013</ce:label><sb:reference id="sbref0003"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Baumgartner</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Kolbitsch</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Rueckert</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Groupwise simultaneous manifold alignment for high-resolution dynamic MR imaging of respiratory motion</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IPMI</sb:maintitle></sb:title><sb:date>2013</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>232</sb:first-page><sb:last-page>243</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0004"><ce:label>Baumgartner, Kolbitsch, McClelland, Rueckert, King, 2014b</ce:label><sb:reference id="sbref0004"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Baumgartner</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Kolbitsch</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Rueckert</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Autoadaptive motion modelling</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IEEE ISBI</sb:maintitle></sb:title><sb:date>2014</sb:date></sb:book><sb:pages><sb:first-page>457</sb:first-page><sb:last-page>460</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0005"><ce:label>Bhatia, Rao, Price, Wolz, Hajnal, Rueckert, 2012</ce:label><sb:reference id="sbref0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Bhatia</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Rao</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Price</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Wolz</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Hajnal</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Rueckert</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Hierarchical manifold learning</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. MICCAI</sb:maintitle></sb:title><sb:date>2012</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>512</sb:first-page><sb:last-page>519</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0006"><ce:label>Blackall, Ahmad, Miquel, McClelland, Landau, Hawkes, 2006</ce:label><sb:reference id="sbref0006"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Blackall</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Ahmad</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Miquel</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Landau</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>MRI-based measurements of respiratory motion variability and assessment of imaging strategies for radiotherapy planning</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>51</sb:volume-nr></sb:series><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>4147</sb:first-page><sb:last-page>4169</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0007"><ce:label>Brix, Ringgaard, Sørensen, Poulsen, 2014</ce:label><sb:reference id="sbref0007"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Brix</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Ringgaard</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Sørensen</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Poulsen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Three-dimensional liver motion tracking using real-time two-dimensional MRI</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Phys.</sb:maintitle></sb:title><sb:volume-nr>41</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2014</sb:date></sb:issue><sb:pages><sb:first-page>042302</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0008"><ce:label>Cho, Poulsen, Keall, 2010</ce:label><sb:reference id="sbref0008"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Cho</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Poulsen</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Keall</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Real-time tumor tracking using sequential kv imaging combined with respiratory monitoring: a general framework applicable to commonly used IGRT systems</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. MedBiol.</sb:maintitle></sb:title><sb:volume-nr>55</sb:volume-nr></sb:series><sb:issue-nr>12</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>3299</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0009"><ce:label>Crijns, Raaymakers, Lagendijk, 2012</ce:label><sb:reference id="sbref0009"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Crijns</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Raaymakers</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Lagendijk</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Proof of concept of MRI-guided tracked radiation delivery: tracking one-dimensional motion</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>57</sb:volume-nr></sb:series><sb:issue-nr>23</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>7863</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>De Senneville, El Hamidi, Moonen, 2015</ce:label><sb:reference id="sbref0010"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.</ce:given-name><ce:surname>De Senneville</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>El Hamidi</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Moonen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A direct PCA-based approach for real-time description of physiological organ deformations</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Med. Imaging.</sb:maintitle></sb:title><sb:volume-nr>34</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2015</sb:date></sb:issue><sb:pages><sb:first-page>974</sb:first-page><sb:last-page>982</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0011"><ce:label>Dikaios, Izquierdo-Garcia, Graves, Mani, Fayad, Fryer, 2012</ce:label><sb:reference id="sbref0011"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Dikaios</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Izquierdo-Garcia</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Graves</ce:surname></sb:author><sb:author><ce:given-name>V.</ce:given-name><ce:surname>Mani</ce:surname></sb:author><sb:author><ce:given-name>Z.</ce:given-name><ce:surname>Fayad</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Fryer</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>MRI-based motion correction of thoracic PET: initial comparison of acquisition protocols and correction strategies suitable for simultaneous PET/MRI systems</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Eur. radiol.</sb:maintitle></sb:title><sb:volume-nr>22</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>439</sb:first-page><sb:last-page>446</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0012"><ce:label>Fassi, Schaerer, Fernandes, Riboldi, Sarrut, Baroni, 2014</ce:label><sb:reference id="sbref0012"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Fassi</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Schaerer</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Fernandes</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Riboldi</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Sarrut</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Baroni</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Tumor tracking method based on a deformable 4D CT breathing motion model driven by an external surface surrogate</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int J Radiat Oncol</sb:maintitle></sb:title><sb:volume-nr>88</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2014</sb:date></sb:issue><sb:pages><sb:first-page>182</sb:first-page><sb:last-page>188</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0013"><ce:label>Fischer, Pohl, Hornegger, 2014</ce:label><sb:reference id="sbref0013"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Fischer</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Pohl</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Hornegger</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Real-time respiratory signal extractino from X-ray sequences using incremental manifold learning</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IEEE ISBI</sb:maintitle></sb:title><sb:date>2014</sb:date></sb:book><sb:pages><sb:first-page>915</sb:first-page><sb:last-page>918</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0014"><ce:label>Foley, Eames, Snell, Hananel, Kassell, Aubry, 2013</ce:label><sb:reference id="sbref0014"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Foley</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Eames</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Snell</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Hananel</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Kassell</ce:surname></sb:author><sb:author><ce:given-name>J.-F.</ce:given-name><ce:surname>Aubry</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Image-guided focused ultrasound: state of the technology and the challenges that lie ahead</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Imaging Med.</sb:maintitle></sb:title><sb:volume-nr>5</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>357</sb:first-page><sb:last-page>370</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>Georg, Souvenir, Hope, Pless, 2008</ce:label><sb:reference id="sbref0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Georg</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Souvenir</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Hope</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Pless</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Manifold learning for 4D CT reconstruction of the lung</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IEEE CVPRW</sb:maintitle></sb:title><sb:date>2008</sb:date></sb:book><sb:pages><sb:first-page>1</sb:first-page><sb:last-page>8</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0016"><ce:label>Hoogeman, Prévost, Nuyttens, Pöll, Levendag, Heijmen, 2009</ce:label><sb:reference id="sbref0016"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Hoogeman</ce:surname></sb:author><sb:author><ce:given-name>J.-B.</ce:given-name><ce:surname>Prévost</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Nuyttens</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Pöll</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Levendag</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Heijmen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Clinical accuracy of the respiratory tumor tracking system of the cyberknife: assessment by analysis of log files</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Radiat. Oncol.</sb:maintitle></sb:title><sb:volume-nr>74</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>297</sb:first-page><sb:last-page>303</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0017"><ce:label>Hynynen, Freund, Cline, Chung, Watkins, Vetro, Jolesz, 1996</ce:label><sb:reference id="sbref0017"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Hynynen</ce:surname></sb:author><sb:author><ce:given-name>W.</ce:given-name><ce:surname>Freund</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Cline</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Chung</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Watkins</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Vetro</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Jolesz</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A clinical, noninvasive, MR imaging-monitored ultrasound surgery method</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Radiographics</sb:maintitle></sb:title><sb:volume-nr>16</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>1996</sb:date></sb:issue><sb:pages><sb:first-page>185</sb:first-page><sb:last-page>195</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0018"><ce:label>Isaksson, Jalden, Murphy, 2005</ce:label><sb:reference id="sbref0018"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Isaksson</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Jalden</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Murphy</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>On using an adaptive neural network to predict lung tumor motion during respiration for radiotherapy applications</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Phys.</sb:maintitle></sb:title><sb:volume-nr>32</sb:volume-nr></sb:series><sb:issue-nr>12</sb:issue-nr><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>3801</sb:first-page><sb:last-page>3809</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0019"><ce:label>King, Buerger, Tsoumpas, Marsden, Schaeffter, 2012</ce:label><sb:reference id="sbref0019"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Buerger</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Tsoumpas</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Marsden</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Schaeffter</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Thoracic respiratory motion estimation from MRI using a statistical model and a 2-D image navigator</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Image Anal.</sb:maintitle></sb:title><sb:volume-nr>16</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>252</sb:first-page><sb:last-page>264</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0020"><ce:label>King, Rhode, Razavi, Schaeffter, 2009</ce:label><sb:reference id="sbref0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Rhode</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Razavi</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Schaeffter</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>An adaptive and predictive respiratory motion model for image-guided interventions: theory and first clinical application</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>IEEE Trans. Med. Imaging</sb:maintitle></sb:title><sb:volume-nr>28</sb:volume-nr></sb:series><sb:issue-nr>12</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>2020</sb:first-page><sb:last-page>2032</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0021"><ce:label>Kini, Vedam, Keall, Patil, Chen, Mohan, 2003</ce:label><sb:reference id="sbref0021"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>V.</ce:given-name><ce:surname>Kini</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Vedam</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Keall</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Patil</ce:surname></sb:author><sb:author><ce:surname>Chen</ce:surname><ce:given-name>C.</ce:given-name></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Mohan</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Patient training in respiratory-gated radiotherapy</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Dosim.</sb:maintitle></sb:title><sb:volume-nr>28</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2003</sb:date></sb:issue><sb:pages><sb:first-page>7</sb:first-page><sb:last-page>11</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0022"><ce:label>Kuhn, 1955</ce:label><sb:reference id="sbref0022"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Kuhn</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The Hungarian method for the assignment problem</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Nav. Res. Logist. Q.</sb:maintitle></sb:title><sb:volume-nr>2</sb:volume-nr></sb:series><sb:issue-nr>1-2</sb:issue-nr><sb:date>1955</sb:date></sb:issue><sb:pages><sb:first-page>83</sb:first-page><sb:last-page>97</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0023"><ce:label>Low, Parikh, Lu, Dempsey, Wahab, Hubenschmidt, Nystrom, Handoko, Bradley, 2005</ce:label><sb:reference id="sbref0023"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Low</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Parikh</ce:surname></sb:author><sb:author><ce:given-name>W.</ce:given-name><ce:surname>Lu</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Dempsey</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Wahab</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Hubenschmidt</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Nystrom</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Handoko</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Bradley</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Novel breathing motion model for radiotherapy</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Radiat. Oncol.</sb:maintitle></sb:title><sb:volume-nr>63</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>921</sb:first-page><sb:last-page>929</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0024"><ce:label>McClelland, Hawkes, Schaeffter, King, 2013</ce:label><sb:reference id="sbref0024"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Schaeffter</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Respiratory motion models: a review</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Image Anal.</sb:maintitle></sb:title><sb:volume-nr>17</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>19</sb:first-page><sb:last-page>42</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0025"><ce:label>McClelland, Hughes, Modat, Qureshi, Ahmad, Landau, Ourselin, Hawkes, 2011</ce:label><sb:reference id="sbref0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>McClelland</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Hughes</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Modat</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Qureshi</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Ahmad</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Landau</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Ourselin</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Inter-fraction variations in respiratory motion models</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>56</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>251</sb:first-page><sb:last-page>272</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0026"><ce:label>Modat, Ridgway, Taylor, Lehmann, Barnes, Hawkes, Fox, Ourselin, 2010</ce:label><sb:reference id="sbref0026"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Modat</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Ridgway</ce:surname></sb:author><sb:author><ce:given-name>Z.</ce:given-name><ce:surname>Taylor</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Lehmann</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Barnes</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Fox</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Ourselin</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Fast free-form deformation using graphics processing units</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Comput. Meth. Prog. Bio.</sb:maintitle></sb:title><sb:volume-nr>98</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>278</sb:first-page><sb:last-page>284</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0027"><ce:label>Park, Park, Kim, Yoon, Song, Liu, Song, Kauweloa, Webster, Sandhu, et al., 2012</ce:label><sb:reference id="sbref0027"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Park</ce:surname><ce:given-name>J.</ce:given-name></sb:author><sb:author><ce:surname>Park</ce:surname><ce:given-name>S.</ce:given-name></sb:author><sb:author><ce:surname>Kim</ce:surname><ce:given-name>J.</ce:given-name></sb:author><sb:author><ce:surname>Yoon</ce:surname><ce:given-name>S.</ce:given-name></sb:author><sb:author><ce:surname>Song</ce:surname><ce:given-name>S.</ce:given-name></sb:author><sb:author><ce:surname>Liu</ce:surname><ce:given-name>Z.</ce:given-name></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Song</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Kauweloa</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Webster</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Sandhu</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Liver motion during cone beam computed tomography guided stereotactic body radiation therapy</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Phys</sb:maintitle></sb:title><sb:volume-nr>39</sb:volume-nr></sb:series><sb:issue-nr>10</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>6431</sb:first-page><sb:last-page>6442</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0028"><ce:label>Peressutti, Penney, Housden, Kolbitsch, Gomez, Rijkhorst, Barratt, Rhode, King, 2013</ce:label><sb:reference id="sbref0028"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Peressutti</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Penney</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Housden</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Kolbitsch</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Gomez</ce:surname></sb:author><sb:author><ce:given-name>E.-J.</ce:given-name><ce:surname>Rijkhorst</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Barratt</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Rhode</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A novel bayesian respiratory motion model to estimate and resolve uncertainty in image-guided cardiac interventions</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Image Anal.</sb:maintitle></sb:title><sb:volume-nr>17</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>488</sb:first-page><sb:last-page>502</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0029"><ce:label>Peressutti, Rijkhorst, Barratt, Penney, King, 2012</ce:label><sb:reference id="sbref0029"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Peressutti</ce:surname></sb:author><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Rijkhorst</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Barratt</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Penney</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Estimating and resolving uncertainty in cardiac respiratory motion modelling</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IEEE ISBI</sb:maintitle></sb:title><sb:date>2012</sb:date></sb:book><sb:pages><sb:first-page>262</sb:first-page><sb:last-page>265</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0030"><ce:label>Raaymakers, Lagendijk, Overweg, Kok, Raaijmakers, Kerkhof, van der Put, Meijsing, Crijns, Benedosso, et al., 2009</ce:label><sb:reference id="sbref0030"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Raaymakers</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Lagendijk</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Overweg</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Kok</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Raaijmakers</ce:surname></sb:author><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Kerkhof</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>van der Put</ce:surname></sb:author><sb:author><ce:given-name>I.</ce:given-name><ce:surname>Meijsing</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Crijns</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Benedosso</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Integrating a 1.5 T MRI scanner with a 6 MV accelerator: proof of concept</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>54</sb:volume-nr></sb:series><sb:issue-nr>12</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>N229</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0031"><ce:label>Rao, Sanchez-Ortiz, Chandrashekara, Lorenzo-Valdés, Mohiaddin, Rueckert, 2002</ce:label><sb:reference id="sbref0031"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Rao</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Sanchez-Ortiz</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Chandrashekara</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Lorenzo-Valdés</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Mohiaddin</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Rueckert</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Comparison of cardiac motion across subjects using non-rigid registration</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. MICCAI</sb:maintitle></sb:title><sb:date>2002</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>722</sb:first-page><sb:last-page>729</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0032"><ce:label>Ries, De Senneville, Roujol, Berber, Quesson, Moonen, 2010</ce:label><sb:reference id="sbref0032"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Ries</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>De Senneville</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Roujol</ce:surname></sb:author><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Berber</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Quesson</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Moonen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Real-time 3D target tracking in MRI guided focused ultrasound ablations in moving tissues</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Magn. Reson. Med.</sb:maintitle></sb:title><sb:volume-nr>64</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>1704</sb:first-page><sb:last-page>1712</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0033"><ce:label>Rijkhorst, Heanes, Odille, Hawkes, Barratt, 2010</ce:label><sb:reference id="sbref0033"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>E.-J.</ce:given-name><ce:surname>Rijkhorst</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Heanes</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Odille</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Barratt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Simulating dynamic ultrasound using MR-derived motion models to assess respiratory synchronisation for image-guided liver interventions</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IPCAI</sb:maintitle></sb:title><sb:date>2010</sb:date><sb:publisher><sb:name>Springer</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>113</sb:first-page><sb:last-page>123</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0034"><ce:label>Rijkhorst, Rivens, Haar, Hawkes, Barratt, 2011</ce:label><sb:reference id="sbref0034"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>E.-J.</ce:given-name><ce:surname>Rijkhorst</ce:surname></sb:author><sb:author><ce:given-name>I.</ce:given-name><ce:surname>Rivens</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Haar</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Hawkes</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Barratt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Effects of respiratory liver motion on heating for gated and model-based motion-compensated high-intensity focused ultrasound ablation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. MICCAI</sb:maintitle></sb:title><sb:date>2011</sb:date><sb:publisher><sb:name>Springer-Verlag</sb:name></sb:publisher></sb:book><sb:pages><sb:first-page>605</sb:first-page><sb:last-page>612</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0035"><ce:label>Rosenblatt, 1956</ce:label><sb:reference id="sbref0035"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Rosenblatt</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Remarks on some nonparametric estimates of a density function</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Ann. Math. Stat.</sb:maintitle></sb:title><sb:volume-nr>27</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>1956</sb:date></sb:issue><sb:pages><sb:first-page>832</sb:first-page><sb:last-page>837</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0036"><ce:label>Roweis, Saul, 2000</ce:label><sb:reference id="sbref0036"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Roweis</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Saul</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Nonlinear dimensionality reduction by locally linear embedding</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Science</sb:maintitle></sb:title><sb:volume-nr>290</sb:volume-nr></sb:series><sb:issue-nr>5500</sb:issue-nr><sb:date>2000</sb:date></sb:issue><sb:pages><sb:first-page>2323</sb:first-page><sb:last-page>2326</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0037"><ce:label>Savill, Schaeffter, King, 2011</ce:label><sb:reference id="sbref0037"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Savill</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Schaeffter</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>King</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Assessment of input signal positioning for cardiac respiratory motion models during different breathing patterns</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. ISBI</sb:maintitle></sb:title><sb:date>2011</sb:date></sb:book><sb:pages><sb:first-page>1698</sb:first-page><sb:last-page>1701</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0038"><ce:label>Sawant, Smith, Venkat, Santanam, Cho, Poulsen, Cattell, Newell, Parikh, Keall, 2009</ce:label><sb:reference id="sbref0038"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Sawant</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Smith</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Venkat</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Santanam</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Cho</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Poulsen</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Cattell</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Newell</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Parikh</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Keall</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Toward submillimeter accuracy in the management of intrafraction motion: the integration of real-time internal position monitoring and multileaf collimator target tracking</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Radiat. Oncol.</sb:maintitle></sb:title><sb:volume-nr>74</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>575</sb:first-page><sb:last-page>582</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0039"><ce:label>Schweikard, Glosser, Bodduluri, Murphy, Adler, 2000</ce:label><sb:reference id="sbref0039"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Schweikard</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Glosser</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Bodduluri</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Murphy</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Adler</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Robotic motion compensation for respiratory movement during radiosurgery</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Comput. Aided Surg.</sb:maintitle></sb:title><sb:volume-nr>5</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2000</sb:date></sb:issue><sb:pages><sb:first-page>263</sb:first-page><sb:last-page>277</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0040"><ce:label>Schweikard, Shiomi, Adler, 2005</ce:label><sb:reference id="sbref0040"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Schweikard</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Shiomi</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Adler</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Respiration tracking in radiosurgery without fiducials</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Med. Rob. Comp.</sb:maintitle></sb:title><sb:volume-nr>1</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>19</sb:first-page><sb:last-page>27</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0041"><ce:label>Seppenwoolde, Berbeco, Nishioka, Shirato, Heijmen, 2007</ce:label><sb:reference id="sbref0041"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Seppenwoolde</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Berbeco</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Nishioka</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Shirato</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>Heijmen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Accuracy of tumor motion compensation algorithm from a robotic respiratory tracking system: a simulation study</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Phys.</sb:maintitle></sb:title><sb:volume-nr>34</sb:volume-nr></sb:series><sb:issue-nr>7</sb:issue-nr><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>2774</sb:first-page><sb:last-page>2784</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0042"><ce:label>Seppenwoolde, Shirato, Kitamura, Shimizu, van Herk, Lebesque, Miyasaka, 2002</ce:label><sb:reference id="sbref0042"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Seppenwoolde</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Shirato</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Kitamura</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Shimizu</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>van Herk</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Lebesque</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Miyasaka</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Precise and real-time measurement of 3D tumor motion in lung due to breathing and heartbeat, measured during radiotherapy</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Int. J. Radiat. Oncol.</sb:maintitle></sb:title><sb:volume-nr>53</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2002</sb:date></sb:issue><sb:pages><sb:first-page>822</sb:first-page><sb:last-page>834</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0043"><ce:label>Sharp, Jiang, Shimizu, Shirato, 2004</ce:label><sb:reference id="sbref0043"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>G.C.</ce:given-name><ce:surname>Sharp</ce:surname></sb:author><sb:author><ce:given-name>S.B.</ce:given-name><ce:surname>Jiang</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Shimizu</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Shirato</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Prediction of respiratory tumour motion for real-time image-guided radiotherapy</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>49</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2004</sb:date></sb:issue><sb:pages><sb:first-page>425</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0044"><ce:label>Souvenir, Zhang, Pless, 2006</ce:label><sb:reference id="sbref0044"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Souvenir</ce:surname></sb:author><sb:author><ce:surname>Zhang</ce:surname><ce:given-name>Q.</ce:given-name></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Pless</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Image manifold interpolation using free-form deformations</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Proc. IEEE Image Proc</sb:maintitle></sb:title><sb:date>2006</sb:date></sb:book><sb:pages><sb:first-page>1437</sb:first-page><sb:last-page>1440</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0045"><ce:label>Tempany, McDannold, Hynynen, Jolesz, 2011</ce:label><sb:reference id="sbref0045"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Tempany</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>McDannold</ce:surname></sb:author><sb:author><ce:given-name>K.</ce:given-name><ce:surname>Hynynen</ce:surname></sb:author><sb:author><ce:given-name>F.</ce:given-name><ce:surname>Jolesz</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Focused ultrasound surgery in oncology: overview and principles</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Radiology</sb:maintitle></sb:title><sb:volume-nr>259</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>39</sb:first-page><sb:last-page>56</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0046"><ce:label>von Siebenthal, Székely, Gamper, Boesiger, Lomax, Cattin, 2007</ce:label><sb:reference id="sbref0046"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>von Siebenthal</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>Székely</ce:surname></sb:author><sb:author><ce:given-name>U.</ce:given-name><ce:surname>Gamper</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Boesiger</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Lomax</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Cattin</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>4D MR imaging of respiratory organ motion and its variability</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Phys. Med. Biol.</sb:maintitle></sb:title><sb:volume-nr>52</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>1547</sb:first-page><sb:last-page>1564</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0047"><ce:label>Wachinger, Yigitsoy, Rijkhorst, Navab, 2011</ce:label><sb:reference id="sbref0047"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Wachinger</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Yigitsoy</ce:surname></sb:author><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Rijkhorst</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Navab</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Manifold learning for image-based breathing gating in ultrasound and MRI</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Image Anal.</sb:maintitle></sb:title><sb:volume-nr>16</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2011</sb:date></sb:issue><sb:pages><sb:first-page>806</sb:first-page><sb:last-page>818</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0048"><ce:label>Würslin, Schmidt, Martirosian, Brendle, Boss, Schwenzer, Stegger, 2013</ce:label><sb:reference id="sbref0048"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Würslin</ce:surname></sb:author><sb:author><ce:given-name>H.</ce:given-name><ce:surname>Schmidt</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Martirosian</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Brendle</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Boss</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Schwenzer</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Stegger</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Respiratory motion correction in oncologic PET using T1-weighted MR imaging on a simultaneous whole-body PET/MR system</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>J. Nucl. Med.</sb:maintitle></sb:title><sb:volume-nr>54</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>464</sb:first-page><sb:last-page>471</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0049"><ce:label>Zachiu, de Senneville, Moonen, Ries, 2015</ce:label><sb:reference id="sbref0049"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Zachiu</ce:surname></sb:author><sb:author><ce:given-name>B.</ce:given-name><ce:surname>de Senneville</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Moonen</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Ries</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A framework for the correction of slow physiological drifts during MR-guided HIFU therapies: proof of concept</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Med. Phys.</sb:maintitle></sb:title><sb:volume-nr>42</sb:volume-nr></sb:series><sb:issue-nr>7</sb:issue-nr><sb:date>2015</sb:date></sb:issue><sb:pages><sb:first-page>4137</sb:first-page><sb:last-page>4148</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
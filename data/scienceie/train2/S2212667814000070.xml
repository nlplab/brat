<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S2212667814000070</prism:url><dc:identifier>doi:10.1016/j.ieri.2014.03.006</dc:identifier><eid>1-s2.0-S2212667814000070</eid><prism:doi>10.1016/j.ieri.2014.03.006</prism:doi><pii>S2212-6678(14)00007-0</pii><dc:title>Rotation Invariant Multiple Face-detection Architecture for Smart TV </dc:title><prism:publicationName>IERI Procedia</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>22126678</prism:issn><prism:volume>6</prism:volume><prism:startingPage>33</prism:startingPage><prism:endingPage>38</prism:endingPage><prism:pageRange>33-38</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2014-12-31</prism:coverDate><prism:coverDisplayDate>2014</prism:coverDisplayDate><prism:copyright>Copyright © 2014 The Authors. Published by Elsevier B.V.</prism:copyright><prism:publisher>The Authors. Published by Elsevier B.V.</prism:publisher><prism:issueName>2013 International Conference on Future Software Engineering and Multimedia Engineering (ICFM 2013)</prism:issueName><dc:creator>Choi, Jeahoon</dc:creator><dc:creator>Yoo, Seong Joon</dc:creator><dc:creator>Baik, Sung Wook</dc:creator><dc:creator>Shin, Ho Chul</dc:creator><dc:creator>Han, Dongil</dc:creator><dc:description>AbstractThis paper suggests a design of high quality real-time rotation face detection architecture for gesture recognition of smart TV. For high performance rotated face detection, the multiple-MCT(Modified Census Transform) architecture, which is robust against lighting change, was used. The Adaboost learning algorithm was used for creating optimized learning data. The proposed hardware structure was composed of Color Space Converter, Image Resizer, Noise Filter, Memory Controller Interface, Image Rotator, Image Scaler, MCT Generator, Candidate Detector, Confidence Switch, Confidence Mapper, Position Resizer, Data Grouper, Overlay Processor and Color Overlay Processer. As a result, suggested face detection device can conduct real-time processing at speed of at least 30 frames per second.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType/><openaccessUserLicense>http://creativecommons.org/licenses/by-nc-nd/3.0/</openaccessUserLicense><dcterms:subject>MCT</dcterms:subject><dcterms:subject>Adaboost</dcterms:subject><dcterms:subject>FPGA</dcterms:subject><dcterms:subject>Face detection</dcterms:subject><dcterms:subject>Rotation Inariance ;</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S2212667814000070"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S2212667814000070"/></coredata><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>282178</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291773</xocs:ssid><xocs:ssid type="subj">291800</xocs:ssid><xocs:ssid type="subj">291880</xocs:ssid><xocs:ssid type="subj">291882</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>IERI Procedia</xocs:srctitle><xocs:normalized-srctitle>IERIPROCEDIA</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20140607">2014-06-07</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20140607">2014-06-07</xocs:available-online-date><xocs:ew-transaction-id>2014-10-23T04:52:13</xocs:ew-transaction-id><xocs:eid>1-s2.0-S2212667814000070</xocs:eid><xocs:pii-formatted>S2212-6678(14)00007-0</xocs:pii-formatted><xocs:pii-unformatted>S2212667814000070</xocs:pii-unformatted><xocs:doi>10.1016/j.ieri.2014.03.006</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.2</xocs:item-version-number><xocs:item-weight>HEAD-AND-TAIL</xocs:item-weight><xocs:hub-eid>1-s2.0-S2212667814X0002X</xocs:hub-eid><xocs:timestamp yyyymmdd="20150515">2015-05-15T07:34:50.756359-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20140101</xocs:date-search-begin><xocs:date-search-end>20141231</xocs:date-search-end><xocs:year-nav>2014</xocs:year-nav><xocs:indexeddate epoch="1402099200">2014-06-07T00:00:00Z</xocs:indexeddate><xocs:articleinfo>rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>2212-6678</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>22126678</xocs:issn-primary-unformatted></xocs:issns><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>6</xocs:vol-first><xocs:volume-list><xocs:volume>6</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 6</xocs:vol-iss-suppl-text><xocs:sort-order>6</xocs:sort-order><xocs:first-fp>33</xocs:first-fp><xocs:last-lp>38</xocs:last-lp><xocs:pages><xocs:first-page>33</xocs:first-page><xocs:last-page>38</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>2014</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>2014</xocs:cover-date-text><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:cover-date-year>2014</xocs:cover-date-year><xocs:title-editors-groups><xocs:title-editors-group><ce:title>2013 International Conference on Future Software Engineering and Multimedia Engineering (ICFM 2013)</ce:title><ce:editors><ce:author-group><ce:author><ce:given-name>Garry</ce:given-name><ce:surname>Lee</ce:surname></ce:author></ce:author-group></ce:editors></xocs:title-editors-group></xocs:title-editors-groups><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>Copyright © 2014 The Authors. Published by Elsevier B.V.</xocs:copyright-line><xocs:normalized-article-title>ROTATIONINVARIANTMULTIPLEFACEDETECTIONARCHITECTUREFORSMARTTV</xocs:normalized-article-title><xocs:normalized-first-auth-surname>CHOI</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>J</xocs:normalized-first-auth-initial><xocs:references><xocs:ref-info refid="sbref0005"><xocs:ref-normalized-surname>HAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>1222</xocs:ref-first-fp><xocs:ref-last-lp>1239</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="oref0010"/><xocs:ref-info refid="sbref0015"><xocs:ref-normalized-surname>VIOLA</xocs:ref-normalized-surname><xocs:ref-pub-year>2004</xocs:ref-pub-year><xocs:ref-first-fp>137</xocs:ref-first-fp><xocs:ref-last-lp>154</xocs:ref-last-lp><xocs:ref-normalized-initial>P</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:refkeys><xocs:refkey3>CHOIX2014X33</xocs:refkey3><xocs:refkey4lp>CHOIX2014X33X38</xocs:refkey4lp><xocs:refkey4ai>CHOIX2014X33XJ</xocs:refkey4ai><xocs:refkey5>CHOIX2014X33X38XJ</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2014-06-07T06:31:24Z</xocs:oa-access-effective-date><xocs:oa-user-license>http://creativecommons.org/licenses/by-nc-nd/3.0/</xocs:oa-user-license><xocs:oa-access-inherited-from winid="http://vtw.elsevier.com/content/oaw/PROC_UNBOUNDED_ESWaived">OA-Window</xocs:oa-access-inherited-from></xocs:open-access><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S2212-6678(14)00007-0</xocs:pii-formatted><xocs:pii-unformatted>S2212667814000070</xocs:pii-unformatted><xocs:eid>1-s2.0-S2212667814000070</xocs:eid><xocs:doi>10.1016/j.ieri.2014.03.006</xocs:doi><xocs:cid>282178</xocs:cid><xocs:timestamp>2014-10-23T01:29:23.346571-04:00</xocs:timestamp><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S2212667814000070-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814000070/MAIN/application/pdf/5d40ee5840fd969e91ccc7d97e3f04b2/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814000070/MAIN/application/pdf/5d40ee5840fd969e91ccc7d97e3f04b2/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>1091366</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>6</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S2212667814000070-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814000070/PREVIEW/image/png/7341a7c7973c8a2d3a36093c8de7ac5d/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814000070/PREVIEW/image/png/7341a7c7973c8a2d3a36093c8de7ac5d/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>41950</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:rawtext> I E R I  P r o c e d i a    6   (  2 0 1 4  )   3 3  â€“  3 8   Available online at www.sciencedirect.com 2212-6678  2014. The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.  Peer review under responsibility of Scientific Committee of of Information Engineering Research Institute doi: 10.1016/j.ieri.2014.03.006  ScienceDirect 2013 International Conference on Future Software Engineering and Multimedia  Engineering  Rotation Invariant Multiple Face-Detection Architecture for  Smart TV  Jeahoon Choi a ,  Seong Joon Yoo a , Sung Wook Baik b , Ho Chul Shin c , Dongil Han a,* a Depertment of    Computer Engineering, Sejong University,  Seoul, Korea  b Digital Contents Research Institute, Sejong University, Seoul, Korea  c  Robot,Cognitive System Research Department,  Electronics and Telecommunications Research Institute (ETRI),  Daejeon, Korea  Abstract  This paper suggests a design of high quality real-time rotation face detection architecture for gesture recognition of smart  TV.  For high performance rotated face detection, the multiple-MCT(Modified Census Transform) architecture, which is  robust against lighting change, was used. The Adaboost learning algorithm was used for creating optimized learning data.  The proposed hardware structure was composed of Color Space Converter, Image Resizer, Noise Filter, Memory  Controller Interface, Image Rotator, Image Scaler, MCT Generator, Candidate Detector, Confidence Switch, Confidence  Mapper, Position Resizer, Data Grouper, Overlay Processor and Color Overlay Processer. As a result, suggested face detection device can conduct real-time processing at speed of at least 30 frames per second.  Â© 2013. Published by Elsevier B.V.  Selection and peer review under responsibility of Information Engineering Research Institute  Keywords : MCT, Adaboost, FPGA, Face detection, Rotation Inariance;   * Corresponding author. Tel.: +82-2-3408-3751; fax: +82-2-3408-4321.  E-mail address: dihan@sejong.ac.kr.   2014. The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.  Peer review under responsibility of Scientific Committee of of Information Engineering Research Institute 34   Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  1. Introduction  Previous TV users were manually accessing media, which on the other hand, the way of users access media  is being modified automatically through improvements in Smart TV. Furthermore, demands on gesture  recognition based interface to handily control TV and search contents, as a new user interface technology of  Smart TV, is increasing.  When designing this gesture recognition based interface, adding face detection technology brings many  advantages. Speed and accuracy of gesture recognition can be granted through reading distance of the user by  having face detection.  Because accuracy is a very important aspect of face detection technology, many variables such as  environmental lighting change, facial expression change and face's rotation change are making it troublesome  for present technology to get accurate readings make face detection technology look limited.   We confirmed that it is possible to design a face detection which is strong against lighting change and have  real-time processing with hardware by using MCT and Adaboost Learning Algorithm in the past researches  [1]. Also, suggested a face detection design [2] which can detect rotated faces within the range of  Â±36Â° using  image memory's rotation alternation technique,  This paper suggests a face detection which is able to detect rotated face within the usual TV viewed  distance, 1.5m~3.5m, and rotation range of Â±102Â° by using parallel processing technique and improving  memory interface's efficiency.  2. Face Detection Algorithm  2.1. Former face detection structure  Former face detection structure [2] detected face by continuously scaling down an imaged processed  through MCT and calculating the value for 20x20 window. At this process, face detection is successful as  long as the face rotates within the range of Â±12Â°, it rotated image three times at angles of 0Â°, +24Â°, -24Â° to  detect faces. However, to be able to use this method for a usual Smart TV environment, which needs face  detection for angles up to Â±90Â°, 9 steps are needed, making it difficult to become real-time process. To solve  this problem, parallel processing technique was used to reduce the detection steps down to 5 steps, and  increasing memory interface's efficiency is suggested.  2.2. Parallel processing technique  Two confidence Mappers storing probability values are used for parallel processing. One is for detecting  from images rotated at angle 0Â° and the other at angle -90Â°. And then it rotates input images by 22.5Â° each  step before detection. Detection allowable angles for each steps using two confidence mappers are tabled in  Table 1 showing that is possible to detect faces rotated at all angles within Â±102Â°.  35 Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  Fig. 1. A block diagram of Memory Interface  Table 1. Face detection range for each rotation steps  Step Image rotation degree Confidence Mapper 0 Confidence Mapper 1  1 0Â° -12Â° ~ +12Â° -102Â° ~ -78Â°  2 22.5Â° +10.5Â° ~ +34.5Â° -79.5Â° ~ -55.5Â°  3 45Â° +33Â° ~ +57Â° -57Â° ~ -33.5Â°  4 67.5Â° +55.5Â° ~ +79.5Â° -34.5Â° ~ -10.5Â°  5 90Â° 78+Â° ~ +102Â° -12Â° ~ +12Â°    Because for rotating angles of 67.5Â° and  90Â°, images gets scaled down too much for accurate detection at  distant faces, likewise in Figure 2, stored the images to memory after rotating them to angles of  -22.5Â°and  0Â°,  and Confidence Mapper was reflected the  left to right to minimize the scaling down of the images, which is  maximizing the performance.    (a) Step 1, 5    (b) Step 2    (c) Step 3    (d) Step 4  Fig. 2. Steps of storing images in memory  36   Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  2.3. Memory Timing Optimization  For real-time processing, optimization of the memory size is necessary. We adopted the following  methods:   Î¾ Face detection results are outputted to the gesture recognition stage. Gesture recognition uses a stereo  matching. If the face is located in the boundary region of image, that face is not useful for stereo matching.  Thus, 5% of the image can be removed on each side.  Fig. 3. Garbage area in stereo matching   Î¾ If the face in the corner of image, it has less information for gesture recognition. 20% of the image can be  removed for 22.5È‹ rotated image, and 25% of the image can be removed for 45È‹ rotated image,  Fig. 4. Removed area in rotated images.  2.4. Memory Interface optimization  For the parallel processing, as shown in Table 2, step 2, 3 and 4, two sides where no images are printed  were deleted in the Image Scaler before Scaling down to increase execution speed. Table 2 shows the overall  scaling down time information.         37 Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  Table 2. Scale down time  Step 1,5 Step 2,4 step 5  Step Width Height  Time  requirement  Accumulated  time  Width Height  Time  requirement  Accumulated  time  Width Height  Time  requirement  Accumulated time  0 608 360 1.9099ms 1.9099ms 366 360 1.1547ms 1.1547ms 304 360 0.9612ms 0.9612ms  1 540 320 1.5101ms 3.4199ms 325 320 0.9133ms 2.0679ms 270 320 0.7606ms 1.7218ms  2 480 284 1.1933ms 4.6132ms 288 284 0.7199ms 2.7878ms 240 284 0.6016ms 2.3233ms  3 426 252 0.9416ms 5.5548ms 256 252 0.5693ms 3.3572ms 213 252 0.4752ms 2.7985ms  4 378 224 0.7442ms 6.299ms 227 224 0.4501ms 3.8072ms 189 224 0.376ms 3.1745ms  5 336 199 0.5891ms 6.8882ms 201 199 0.3552ms 4.1624ms 168 199 0.298ms 3.4726ms  6 298 176 0.4634ms 7.3516ms 178 176 0.2793ms 4.4417ms 149 176 0.2348ms 3.7073ms  7 264 156 0.365ms 7.7166ms 158 156 0.2207ms 4.6624ms 132 156 0.1852ms 3.8926ms  8 234 138 0.2872ms 8.0039ms 140 138 0.1738ms 4.8361ms 117 138 0.146ms 4.0386ms  9 208 122 0.2266ms 8.2305ms 124 122 0.1368ms 4.973ms 104 122 0.1154ms 4.1541ms  10 184 108 0.1783ms 8.4088ms 110 108 0.1081ms 5.0811ms 92 108 0.091ms 4.2451ms  11 163 96 0.1411ms 8.5498ms 97 96 0.0853ms 5.1664ms 81 96 0.0718ms 4.3169ms  12 144 85 0.111ms 8.6608ms 86 85 0.0675ms 5.2339ms 72 85 0.057ms 4.3739ms  13 128 75 0.0876ms 8.7485ms 76 75 0.0531ms 5.287ms 64 75 0.0451ms 4.419ms  14 113 66 0.0686ms 8.8171ms 67 66 0.0416ms 5.3286ms 56 66 0.0352ms 4.4542ms  15 100 58 0.0538ms 8.8708ms 59 58 0.0326ms 5.3612ms 49 58 0.0274ms 4.4816ms  Total Accumulated Time : 32.9457 ms,  30.3529 frame/sec    3. Experimental Results  Fig. 5. Face detection result.  As shown in Figure 5, face is successfully detected at a distance of 1.2m~5m from image rotated at angle  of 0Â°, 0.9~3.8m from image rotated at angle of 22.5Â°, 67.5Â° and 0.8~3.6m from image rotated at angle of 45Â°  4. Conclusion  Former face detection algorithms had limits to angles which faces were rotated and was difficult to detect  users watching TV leaning on sofa or lying down. The new design, which this paper suggests, could detect  faces rotated at angle range of Â±102Â° at normal TV viewing distance by using parallel processing technique  and memory interface optimization. The accurate face detection through high performance rotation face  detecting engine could also detect faces with high reliability in real-time. We therefore expect this face  detection engine can be easily used in gesture detecting applications.  38   Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  Acknowledgements  This work was supported by the ETRI R&amp;D Program of MSIP(Ministry of Science, ICT &amp; Future  Planning), Korea [11921-03001, "Development of Beyond Smart TV Technology"], also supported by a  National Research Foundation of Korea Grant funded by the Korean Government (No. 2012-007498), and  also supported by the Technology Innovation Program(Development of SR Image Scaler for 4K UHD) under  Grant K10041900.  References  [1] Han D, et al. Design and VLSI implementation of a high-performance face detection engine. Computers &amp;  Electrical Engineering 2012;38.5:1222-1239  [2] Choi J, Han D, Yoo SJ. Real-Time Face-Detection Engine for Robustness to Variable Illumination and  Rotated Faces. In: Computers, Networks, Systems and Industrial Engineering (CNSI), 2011 First ACIS/JNU  International Conference on. 2011;53-58.  [3] Viola P, Jones MJ. Robust real-time face detection. International journal of computer vision. 2004;57.2:  137-154.  arbage area in stereo matching   Î¾ If the face in the corner of image, it has less information for gesture recognition. 20% of the image can be  removed for 22.5È‹ rotated image, and 25% of the image can be removed for 45È‹ rotated image,  Fig. 4. Removed area in rotated images.  2.4. Memory Interface optimization  For the parallel processing, as shown in Table 2, step 2, 3 and 4, two sides where no images are printed  were deleted in the Image Scaler before Scaling down to increase execution speed. Table 2 shows the overall  scaling down time information.         37 Jeahoon Choi et al. /  IERI Procedia  6 ( 2014 )  33 â€“ 38  Table 2. Scale down time  Step 1,5 Step 2,4 step 5  Step Width Height  Time  requirement  Accumulated  time  Width Height  Time  requirement  Accumulated  time  Width Height  Time  requirement  Accumulated time  0 608 360 1.9099ms 1.9099ms 366 360 1.1547ms 1.1547ms 304 360 0.9612ms 0.9612ms  1 540 320 1.5101ms 3.4199ms 325 320 0.9133ms 2.0679ms 270 320 0.7606ms 1.7218ms  2 480 284 1.1933ms 4.6132ms 288 284 0.7199ms 2.7878ms 240 284 0.6016ms 2.3233ms  3 426 252 0.9416ms 5.5548ms 256 252 0.5693ms 3.3572ms 213 252 0.4752ms 2.7985ms  4 378 224 0.7442ms 6.299ms 227 224 0.4501ms 3.8072ms 189 224 0.376ms 3.1745ms  5 336 199 0.5891ms 6.8882ms 201 199 0.3552ms 4.1624ms 168 199 0.298ms 3.4726ms  6 298 176 0.4634ms 7.3516ms 178 176 0.2793ms 4.4417ms 149 176 0.2348ms 3.7073ms  7 264 156 0.365ms 7.7166ms 158 156 0.2207ms 4.6624ms 132 156 0.1852ms 3.8926ms  8 234 138 0.2872ms 8.0039ms 140 138 0.1738ms 4.8361ms 117 138 0.146ms 4.0386ms  9 208 122 0.2266ms 8.2305ms 124 122 0.1368ms 4.973ms 104 122 0.1154ms 4.1541ms  10 184 108 0.1783ms 8.4088ms 110 108 0.1081ms 5.0811ms 92 108 0.091ms 4.2451ms  11 163 96 0.1411ms 8.5498ms 97 96 0.0853ms 5.1664ms 81 96 0.0718ms 4.3169ms </xocs:rawtext><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" version="5.2" xml:lang="en" docsubtype="fla"><item-info><jid>IERI</jid><aid>361</aid><ce:pii>S2212-6678(14)00007-0</ce:pii><ce:doi>10.1016/j.ieri.2014.03.006</ce:doi><ce:copyright type="other" year="2014">The Authors</ce:copyright></item-info><head><ce:article-footnote><ce:label>☆</ce:label><ce:note-para id="npar0005" view="all">Peer review under responsibility of Scientific Committee of of Information Engineering Research Institute.</ce:note-para></ce:article-footnote><ce:title id="tit0005">Rotation Invariant Multiple Face-detection Architecture for Smart TV</ce:title><ce:author-group id="aug0005"><ce:author id="aut0005"><ce:given-name>Jeahoon</ce:given-name><ce:surname>Choi</ce:surname><ce:cross-ref id="crf0005" refid="aff0005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0010"><ce:given-name>Seong Joon</ce:given-name><ce:surname>Yoo</ce:surname><ce:cross-ref id="crf0010" refid="aff0005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0015"><ce:given-name>Sung Wook</ce:given-name><ce:surname>Baik</ce:surname><ce:cross-ref id="crf0015" refid="aff0010"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0020"><ce:given-name>Ho Chul</ce:given-name><ce:surname>Shin</ce:surname><ce:cross-ref id="crf0020" refid="aff0015"><ce:sup loc="post">c</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0025"><ce:given-name>Dongil</ce:given-name><ce:surname>Han</ce:surname><ce:cross-ref id="crf0025" refid="aff0005"><ce:sup loc="post">a</ce:sup></ce:cross-ref><ce:cross-ref id="crf0030" refid="cor0005"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:e-address id="eadd0005" type="email">dihan@sejong.ac.kr</ce:e-address></ce:author><ce:affiliation id="aff0005"><ce:label>a</ce:label><ce:textfn>Depertment of Computer Engineering, Sejong University, Seoul, Korea</ce:textfn></ce:affiliation><ce:affiliation id="aff0010"><ce:label>b</ce:label><ce:textfn>Digital Contents Research Institute, Sejong University, Seoul, Korea</ce:textfn></ce:affiliation><ce:affiliation id="aff0015"><ce:label>c</ce:label><ce:textfn>Robot,Cognitive System Research Department, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Korea</ce:textfn></ce:affiliation><ce:correspondence id="cor0005"><ce:label>⁎</ce:label><ce:text>Corresponding author. Tel.: +82-2-3408-3751; fax: +82-2-3408-4321.</ce:text></ce:correspondence></ce:author-group><ce:abstract id="abs0005" view="all" class="author"><ce:section-title id="sect0005">Abstract</ce:section-title><ce:abstract-sec id="abst0005" view="all"><ce:simple-para id="spar0005" view="all">This paper suggests a design of high quality real-time rotation face detection architecture for gesture recognition of smart TV. For high performance rotated face detection, the multiple-MCT(Modified Census Transform) architecture, which is robust against lighting change, was used. The Adaboost learning algorithm was used for creating optimized learning data. The proposed hardware structure was composed of Color Space Converter, Image Resizer, Noise Filter, Memory Controller Interface, Image Rotator, Image Scaler, MCT Generator, Candidate Detector, Confidence Switch, Confidence Mapper, Position Resizer, Data Grouper, Overlay Processor and Color Overlay Processer. As a result, suggested face detection device can conduct real-time processing at speed of at least 30 frames per second.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="kwd0005" class="keyword" view="all"><ce:section-title id="sect0010">Keywords</ce:section-title><ce:keyword id="kw0005"><ce:text>MCT</ce:text></ce:keyword><ce:keyword id="kw0010"><ce:text>Adaboost</ce:text></ce:keyword><ce:keyword id="kw0015"><ce:text>FPGA</ce:text></ce:keyword><ce:keyword id="kw0020"><ce:text>Face detection</ce:text></ce:keyword><ce:keyword id="kw0025"><ce:text>Rotation Inariance ;</ce:text></ce:keyword></ce:keywords></head><tail view="all"><ce:bibliography id="bibl0005" view="all"><ce:section-title id="sect0020">References</ce:section-title><ce:bibliography-sec id="bibs0005" view="all"><ce:bib-reference id="bib0005"><ce:label>[1]</ce:label><sb:reference id="sbref0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Han</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Design and VLSI implementation of a high-performance face detection engine</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computers &amp; Electrical Engineering</sb:maintitle></sb:title><sb:volume-nr>38</sb:volume-nr></sb:series><sb:issue-nr>5</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>1222</sb:first-page><sb:last-page>1239</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>[2]</ce:label><ce:other-ref id="oref0010"><ce:textref>Choi J, Han D, Yoo SJ. Real-Time Face-Detection Engine for Robustness to Variable Illumination and Rotated Faces. In: Computers, Networks, Systems and Industrial Engineering (CNSI), 2011 First ACIS/JNU International Conference on. 2011;53-58.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>[3]</ce:label><sb:reference id="sbref0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Viola</ce:surname></sb:author><sb:author><ce:given-name>M.J.</ce:given-name><ce:surname>Jones</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Robust real-time face detection</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>International journal of computer vision</sb:maintitle></sb:title><sb:volume-nr>57</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2004</sb:date></sb:issue><sb:pages><sb:first-page>137</sb:first-page><sb:last-page>154</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
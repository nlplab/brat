<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S2212667814001208</prism:url><dc:identifier>doi:10.1016/j.ieri.2014.09.072</dc:identifier><eid>1-s2.0-S2212667814001208</eid><prism:doi>10.1016/j.ieri.2014.09.072</prism:doi><pii>S2212-6678(14)00120-8</pii><dc:title>Improving HPC Application Performance in Public Cloud </dc:title><prism:publicationName>IERI Procedia</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>22126678</prism:issn><prism:volume>10</prism:volume><prism:startingPage>169</prism:startingPage><prism:endingPage>176</prism:endingPage><prism:pageRange>169-176</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2014-12-31</prism:coverDate><prism:coverDisplayDate>2014</prism:coverDisplayDate><prism:copyright>Copyright © 2014 The Authors. Published by Elsevier B.V.</prism:copyright><prism:publisher>The Authors. Published by Elsevier B.V.</prism:publisher><prism:issueName>International Conference on Future Information Engineering (FIE 2014)</prism:issueName><dc:creator>Hassani, Rashid</dc:creator><dc:creator>Aiatullah, Md</dc:creator><dc:creator>Luksch, Peter</dc:creator><dc:description>AbstractImproving as well as evaluating the performance of High Performance Computing (HPC) applications by migrating them to Cloud environments are widely considered as critical issues in the field of high performance and Cloud computing. However, poor network performance, heterogeneous and dynamic environments are some series of pitfalls for execution of HPC applications in Cloud. This paper proposes a new approach to improve the performance and scalability of HPC applications on Amazon's HPC Cloud. The evidence from our approach points a significant improvement in speed up and scale up with the response rate of more than 20 percent parallel efﬁciency on the Cloud in comparison to dedicated HPC cluster. We state that the EC2 Cloud system is a feasible platform for deploying on-demand, small sized HPC applications.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType>ElsevierWaived</openaccessSponsorType><openaccessUserLicense>http://creativecommons.org/licenses/by-nc-nd/3.0/</openaccessUserLicense><dcterms:subject>Cloud computing</dcterms:subject><dcterms:subject>HPC applications</dcterms:subject><dcterms:subject>parallel sorting algorithm</dcterms:subject><dcterms:subject>MPI</dcterms:subject><dcterms:subject>Amazon EC2</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S2212667814001208"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S2212667814001208"/></coredata><scopus-id>84969718725</scopus-id><scopus-eid>2-s2.0-84969718725</scopus-eid><link rel="abstract" href="http://api.elsevier.com/content/abstract/scopus_id/84969718725"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>282178</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291773</xocs:ssid><xocs:ssid type="subj">291800</xocs:ssid><xocs:ssid type="subj">291880</xocs:ssid><xocs:ssid type="subj">291882</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>IERI Procedia</xocs:srctitle><xocs:normalized-srctitle>IERIPROCEDIA</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20141001">2014-10-01</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20141001">2014-10-01</xocs:available-online-date><xocs:ew-transaction-id>2014-10-10T04:56:58</xocs:ew-transaction-id><xocs:eid>1-s2.0-S2212667814001208</xocs:eid><xocs:pii-formatted>S2212-6678(14)00120-8</xocs:pii-formatted><xocs:pii-unformatted>S2212667814001208</xocs:pii-unformatted><xocs:doi>10.1016/j.ieri.2014.09.072</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.2</xocs:item-version-number><xocs:item-weight>HEAD-AND-TAIL</xocs:item-weight><xocs:hub-eid>1-s2.0-S2212667814X00067</xocs:hub-eid><xocs:timestamp yyyymmdd="20150515">2015-05-15T07:34:50.756359-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20140101</xocs:date-search-begin><xocs:date-search-end>20141231</xocs:date-search-end><xocs:year-nav>2014</xocs:year-nav><xocs:indexeddate epoch="1412186304">2014-10-01T17:58:24.892674Z</xocs:indexeddate><xocs:articleinfo>rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>2212-6678</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>22126678</xocs:issn-primary-unformatted></xocs:issns><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>10</xocs:vol-first><xocs:volume-list><xocs:volume>10</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 10</xocs:vol-iss-suppl-text><xocs:sort-order>25</xocs:sort-order><xocs:first-fp>169</xocs:first-fp><xocs:last-lp>176</xocs:last-lp><xocs:pages><xocs:first-page>169</xocs:first-page><xocs:last-page>176</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>2014</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>2014</xocs:cover-date-text><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:cover-date-year>2014</xocs:cover-date-year><xocs:title-editors-groups><xocs:title-editors-group><ce:title>International Conference on Future Information Engineering (FIE 2014)</ce:title><ce:editors><ce:author-group><ce:author><ce:given-name>Garry</ce:given-name><ce:surname>Lee</ce:surname></ce:author></ce:author-group></ce:editors></xocs:title-editors-group></xocs:title-editors-groups><xocs:hub-sec><xocs:hub-sec-title>Computer Engineering</xocs:hub-sec-title></xocs:hub-sec><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>Copyright © 2014 The Authors. Published by Elsevier B.V.</xocs:copyright-line><xocs:normalized-article-title>IMPROVINGHPCAPPLICATIONPERFORMANCEINPUBLICCLOUD</xocs:normalized-article-title><xocs:normalized-first-auth-surname>HASSANI</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>R</xocs:normalized-first-auth-initial><xocs:references><xocs:ref-info refid="oref0005"/><xocs:ref-info refid="oref0010"/><xocs:ref-info refid="oref0015"/><xocs:ref-info refid="oref0020"/><xocs:ref-info refid="oref0025"/><xocs:ref-info refid="oref0030"/><xocs:ref-info refid="oref0035"/><xocs:ref-info refid="oref0040"/><xocs:ref-info refid="oref0045"/><xocs:ref-info refid="oref0050"/><xocs:ref-info refid="oref0055"/><xocs:ref-info refid="oref0060"/><xocs:ref-info refid="oref0065"/><xocs:ref-info refid="oref0070"/><xocs:ref-info refid="oref0075"/><xocs:ref-info refid="oref0080"/><xocs:ref-info refid="oref0085"/><xocs:ref-info refid="oref0090"/><xocs:ref-info refid="oref0095"/><xocs:ref-info refid="oref0100"/><xocs:ref-info refid="oref0105"/><xocs:ref-info refid="oref0110"/><xocs:ref-info refid="oref0115"/></xocs:references><xocs:refkeys><xocs:refkey3>HASSANIX2014X169</xocs:refkey3><xocs:refkey4lp>HASSANIX2014X169X176</xocs:refkey4lp><xocs:refkey4ai>HASSANIX2014X169XR</xocs:refkey4ai><xocs:refkey5>HASSANIX2014X169X176XR</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2014-10-01T11:57:40Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>ElsevierWaived</xocs:oa-sponsor-type></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by-nc-nd/3.0/</xocs:oa-user-license><xocs:oa-access-inherited-from winid="http://vtw.elsevier.com/content/oaw/PROC_UNBOUNDED_ESWaived">OA-Window</xocs:oa-access-inherited-from></xocs:open-access><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S2212-6678(14)00120-8</xocs:pii-formatted><xocs:pii-unformatted>S2212667814001208</xocs:pii-unformatted><xocs:eid>1-s2.0-S2212667814001208</xocs:eid><xocs:doi>10.1016/j.ieri.2014.09.072</xocs:doi><xocs:cid>282178</xocs:cid><xocs:timestamp>2014-10-10T10:10:04.754882-04:00</xocs:timestamp><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S2212667814001208-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814001208/MAIN/application/pdf/47027bddefaf59c58dbd07e5db2b6308/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814001208/MAIN/application/pdf/47027bddefaf59c58dbd07e5db2b6308/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>758014</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>8</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S2212667814001208-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814001208/PREVIEW/image/png/e14746da567ed6e42c19a9597eb7d7e7/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814001208/PREVIEW/image/png/e14746da567ed6e42c19a9597eb7d7e7/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>46153</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:rawtext> IERI Procedia   10  ( 2014 )  169 â€“ 176  Available online at www.sciencedirect.com 2212-6678  2014 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). Selection and peer review under responsibility of Information Engineering Research Institute doi: 10.1016/j.ieri.2014.09.072  ScienceDirect 2014 International Conference on Future Information Engineering  Improving HPC Application Performance in Public Cloud  Rashid Hassani*, Md Aiatullah, Peter Luksch  University of Rostock, Rostock, 18059, Germany    Abstract  Improving as well as evaluating the performance of High Performance Computing (HPC) applications by migrating them  to Cloud environments are widely considered as critical issues in the field of high performance and Cloud computing.  However, poor network performance, heterogeneous and dynamic environments are some series of pitfalls for execution  of HPC applications in Cloud. This paper proposes a new approach to improve the performance and scalability of HPC  applications on Amazonâ€™s HPC Cloud. The evidence from our approach points a significant improvement in speed up and  scale up with the response rate of more than 20 percent parallel efficiency on the Cloud in comparison to dedicated HPC  cluster. We state that the EC2 Cloud system is a feasible platform for deploying on-demand, small sized HPC  applications.    Â© 2014 The Authors. Published by Elsevier B.V.  Selection and peer review under responsibility of Information Engineering Research Institute    Keywords: Cloud computing; HPC applications; parallel sorting algorithm; MPI; Amazon EC2  1. Introduction  Supercomputing, often called as High Performance Computing (HPC), is referred to as an attribute that  employs parallel processing to perform huge computations in short time. HPC platforms are typically tightly- coupled and perform frequent inter-processor communication and synchronization. They require a cluster  setup with massive number of computers which are expensive to install, maintain, and operate. They are  mostly being used for scientific research in academia and industries. Therefore, supercomputers cannot be a      * Rashid Hassani. Tel.: +49-3814987565; fax: +49-3814987522.  E-mail address: rashid.hassani@uni-rostock.de.   2014 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). Selection and peer review under responsibility of Information Engineering Research Institute 170   Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  feasible solution for the normal users and small businesses who intend to have on-demand access or to run  their applications for a short period.  Cloud computing is emerging as a commodious resource of computational power in recent years which  provides several possibilities to build HPC platform [1]. Traditional HPC platforms offer limited hardware  access and fail to scale.  The ability to scale up and down the computing platform according to the application  requirements and usersâ€™ budget, makes the Cloud a cost-effective, timely solution and emerging trend to the  needs of HPC users. Some of the key features characterizing Cloud computing are virtualization, elasticity of  resources and rapid growing with ability of delivering both infrastructure and software as a services. These  features allow better flexibility and customization to specific application of HPC users. Therefore, HPC  community has discovered Cloud computing facilities as a potential target system. This is one of the main  reason motivating many users and organizations to port HPC applications to Cloud.  Elastic Compute Cloud (EC2) [2], introduced by Amazon Web Services (AWS), provides powerful  compute and storage resources on demand through hardware level virtualization and also aims to be global. It  provides the possibility of computing on virtual parallel clusters. Some studies investigated the benefits of  performing HPC applications on the Amazon Cloud infrastructure. Despite the benefits offered by Cloud  computing, it has not yet been established whether Cloud can offer a suitable alternative to supercomputers for  HPC applications. Therefore, this motivated us to carry out a detail studies on HPC in the Cloud.  The results from past research of HPC applications on Cloud by focusing on performance as the metric  have been pessimistic. They outlined major limitations which have been resulted from insufficient network  performance, resource heterogeneity and multi-tenancy for HPC applications on Cloud [3,4,5,10,11].  However, Cloud advanced in recent years and now is going to solve some of these problems by leading to  heterogeneous configurations in processors, memory, and network. They have already been adopted in  different scenarios such as intensive and business applications in which, the user can scale up and down  resources when required and finally drop them out when the task is done.   Sorting algorithms are considered as a core part used in HPC applications. There  are  many  types  of   distributed sorting algorithms and many  improvements  have  been  done  on them. Speed up is the  performance attribute to analyze the parallel algorithms. Some of these sorting algorithms have been  implemented on various computing infrastructures to analyze the performance of the system. It would be  interesting to see on how the Cloud scales and what is the performance in Cloud vs. high-end machines when  the parallel sorting algorithm is implemented. Despite the wide benefits the Cloud offers, the research question  currently is â€œwhether the Cloud is a feasible platform for parallel sorting HPC applicationsâ€�.   In this paper, we have implemented the MPI version of parallel Radix sort and analyzed its performance on  Cloud infrastructure and finally compared it with dedicated high-end HPC platform.   The contributions of this work are the following:    Î¾ Investigating most recent works on HPC applications which have been ported to the Cloud environment  in various fields and also identifying the challenges faced by these applications in Cloud environment.    Î¾ Implementing an efficient MPI version of parallel Radix sort algorithm to obtain scalability and good  speed up in Cloud.   Î¾ Evaluating the performance and scalability of our proposed technique by deploying it both on a real  dedicated HPC testbed (Sirius) [6] and on Amazon EC2 Cloud [2].   The rest of the paper is organized as follows:  Section II gives a brief overview of Cloud computing and also Amazon EC2 infrastructure by defining the  reference model of this paradigm and discusses the potential opportunities and investigates the current state of  the art of high performance computing in public Cloud specially Amazon EC2. Section III describes the  implementation of our proposed parallel version of Radix sort and outlines the results of the scaling analysis  171 Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  under the MPI middleware that have been achieved on EC2 as well as dedicated HPC cluster. Finally,  conclusion and future work are drawn in the final section.    Nomenclature  HPC High Performance Computing  AWS  Amazon Web Services  EC2 Elastic Compute Cloud  MPI Message Passing Interface  2. HPC on Cloud  2.1. Cloud architecture  As shown in Fig. 1, there are three main layers in Cloud architecture namely Infrastructure as a Service  (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS).      Fig. 1. Cloud architecture  SaaS is at the top end of the Cloud computing stack. It is a most visible layer of Cloud computing which  gives access to a specific application hosted in the Cloud to end users. It includes software applications such  as Google Apps, Yahoo Mail etc. PaaS is an abstraction layer between a SaaS layer and a virtualized IaaS  layer. It provides users with an application framework and a set of APIs that can be used by developers to  build their applications for the Cloud. PaaS offerings include Google App Engine, Salesforceâ€™s Force.com.  IaaS offers  the  users  and  organizations  both  storage  and  computing  resources  which  are obtained  as  a   service.  Amazon is one of the major players in providing IaaS solutions.  172   Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  2.2. Amazon Web Services  In 2006, Amazon Web Services (AWS) introduced Elastic Compute Cloud (EC2) which provides powerful  compute and storage resources on demand through hardware level virtualization. It provides pay-per-use  model of large computing infrastructure and a service based on hardware virtualization in which the user can  scale up resources when required. The applications launch on hardware through Amazon Machine Image  (AMI). The running system acts as an instance once AMI is launched. There are different types of instances  based on the computing demands namely standard, high-memory, micro, high-CPU, cluster GPU and cluster  compute.  There have been several studies to evaluate Amazon EC2 for HPC applications. Gunarathne et al. [12]  concluded that latency-sensitive applications are less performed compared to bandwidth-sensitive applications  on Cloud. Zhou et al. [13] compared the result from dedicated HPC system with three public Cloud platforms  using classical benchmark and real application. Ramakrishnan et al. [14] extended previous research to EC2  Cloud platform. They concluded higher performance degradation on Amazon EC2 comparing with  conventional HPC platform due to interconnects on the EC2 Cloud. In [15], the comparison is based on  performance measurement for HPC application running on EC2. Deploying new phenomena is suggested by  this author to evaluate the performance. The work in [16] is most relevant to our study in which the Amazon  EC2 is compared with local cluster for running MPI applications. The author has evaluated a cluster compute  instance on EC2 and has stated several problems such as interconnects which limit the performance on EC2.   Now, Amazon EC2 has started to solve the previous problems by providing specifically modern HPC  targeted compute instances enabled by multi-tenancy and virtualization with fast network connections.  However, recent efforts towards HPC-optimized Clouds [17][18] are promising positive signs and leading to  tremendous growth for the research community.  2.3. Sorting algorithm on Cloud  Sorting  is considered  as  a  supercomputing  benchmark  for  testing  the  performance  of   HPC  application on computing architectures. There is an increasing demand to improve data sorting. Parallel  sorting algorithms are abundant. They have been tested on various computing infrastructures and many  improvements have been done on them. There are many types of distributed sorting algorithms such as Radix  sort, Quick sort, Heap sort and Merge sort, etc.  Several  research  works  had  been  carried  out  to  investigate  the  performance  of  sorting algorithms  deployed on Cloud. Bitonic sort [19] and Bucket sort [20]. Merge sort based algorithm with variation of  comparison and also generalization of Quick sort [21]. According to the achieved results so far, these  algorithms seem either to be with a relative slow start such as Quick sort or slow ending like Merge and  Bitonic sort in which fewer sequences are merged with parallelism but unlike these algorithms, when Radix  sort is parallelized, it performs faster  for  larger  datasets  when  compared  to  other  algorithms  like  Quick  sort and Merge sort [22][7].   Radix sort is currently a well-known fast algorithm method for sorting 32 and 64-bit keys on both CPU and  GPU processors which makes certain positional and symbolic assumptions regarding the bitwise  representations of keys [22].This idea motivated us to develop a parallel version of Radix sort algorithm and  deploy it on the Cloud to test the performance using â€˜speed upâ€™ measurement.  So far, we have discussed the potential opportunities and the current state of the art of high performance  computing on public Cloud specially Amazon EC2. The  â€˜speed upâ€™  measurement  signifies  the  performance   of  both  the  parallel algorithm  and  the  parallel  system. The objective of this research is to implement and  deploy the parallel Radix sort and analysis the speed up measurements on Cloud.  173 Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  3. Implementation and evaluation  To implement and measure the speed up of Radix sort in Cloud, there is a need to study many methods to  implement the parallel version of this algorithm. Most parallel HPC applications today employ Message  Passing Interface (MPI) [8][9][23]. As a case study, in the first step we implemented parallel Radix sort  programming using MPI, Pthreads and OpenMP and analyzed their performance using benchmarking test.  Our experimental results have led us to conclude that MPI performs better than others at the time of parallel  sorting. Therefore, MPI was chosen as a suitable method to develop and implement the parallel Radix sort on  Cloud. To the best of our knowledge, we are the first to carryout MPI version of Radix sort on the Amazon  Cloud.   Prior  to  the  implementation  of  Radix sort  in  the  Cloud,  a  cluster  has  to  be built. Amazon  recommends CentOS â€“based images for HPC applications. Cluster  compute  instances  are  well  suited  for   HPC  applications  and  are  demanding  when CPU  resources  are  coupled  with  networking performance.  As a middleware, we have reconfigured and installed the most recent version of OpenMPI (v 1.8) specially  for HPC applications [8][9] and also GNU C++ compiler is installed both on our Sirius test bed [6] and on  Amazon public Cloud. We used â€œextra large instanceâ€� type of Amazon EC2 for our experiment with  specification of: 12 EC2 compute units (2x Intel Xeon X5570); 15GB memory and 10 Gigabit Ethernet.   The hardware specification of our dedicated HPC platform is as follows:   Î¾ 8 nodes each with: 4 CPU Opteron 8350, 160GB SATA, 16GB DDR2-RAM.   Î¾ 3 nodes each with: 4 CPUs Opteron 842, 160GB SATA, 16GB DDR2-RAM.  Table. 1 shows the software specification of our Sirius test bed cluster.  Table 1. Software specification of Sirius cluster  Library/Compiler/OS Version  Linux Enterprise(Suse-Novell) 10.3  GNU compiler 4.1.2  Open MPI V 1.8  3.1. Implementation  We have used an optimized parallel version of Radix sort algorithm which guarantees near-perfect load- balancing amongst CPU cores in compare to all other sorting algorithms [22]. We have developed parallel  MPI version of Radix sort using â€˜Câ€™. It starts with left Radix sorting in its first phase and continues with a  one-bit Right Radix. Through Amazon Web Service, first we created AMI and saved it as template with extra  large instance type as we mentioned above. Through this template, we ran multiple HPC instances. For HPC  instances, Amazon guarantees a 10 Gigabit Ethernet interconnect with full bisection bandwidth. For our  experiment, we have been considered four different workloads i.e., 25MB, 50MB, 75MB and 100MB of  integer data. The integer values are generated using a â€˜randâ€™ function.  Master-Slave  model have been chosen  as  an  efficient  method  to  develop  and  implement  parallel  Radix sort. In this method, the jobs are  allocated to the slaves by master using â€œMPI_Sendâ€� command which results to store chunk of data in slaveâ€™s  buffers. At this time the sorting operations are performed in parallel by all slaves. Next step is a collection of  sorted chunks by the master using â€œMPI_Recvâ€� command and finally merging them in to a single array. The  experiment has been repeated ten times under different workloads conditions and then the average has been  calculated. Speed up has been defined according to Amdahlâ€™s Law. To measure the execution time of these  instances we used â€œcpu timeâ€� instead of â€œwall clockâ€� to prevent any contention of daemons or other processes.  174   Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  3.2. Analysis  After compiling and execution of parallel Radix sort on both platforms, to measure scalability (speed up  for different workloads) of our methodology with respect to the data size, the execution times and then speed  up have been calculated for four different workloads 25, 50, 75 and 100MB by scaling up the nodes from 2, 4,  6 to 8 nodes. The results of 25MB data and 100MB data have been shown in Fig. 2 and Fig. 3 respectively. To  identify the computation performance with respect to the scalability, all workloads have been tested  individually from 2 to 8 nodes on each platform. We have shown the experimental results of computing  clusters with 2 and 8 nodes in Fig. 4 and Fig. 5 respectively. By analyzing each input data individually, we  observed that there is a better execution time when the data is distributed evenly to the nodes but in case of  uneven distribution, execution times increased. The huge variation in execution time has been recorded for  75MB and 100MB for both platforms. On the other hand, load unbalancing has significant impact on  performance and it results in more execution time and less speed up. This is also considered between the  nodes for all the cases.                    Fig. 2. Average execution times (sec) for 25MB data                        Fig. 3. Average execution times (sec) for 100MB data  We assumed that the communication time taken by master to allocate and retrieve back the tasks, increases  as cluster grows. During the experiments on EC2 compute cluster, starting with 2 and 4 nodes, we observed  maximum speed up obtained for all the input sizes. This occurred because of the differences between the ratio  of computation and communication time. We have observed that the computing power and communication  time for 6 and further 8 nodes have slightly increased, resulted in the performance degradation and poor speed  up. This is due to more communication overhead but still performs better than dedicated HPC cluster. Overall,  it is observed that the Cloud has shown better an acceptable performance with the maximum speed up  compare to the dedicated HPC.    175 Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176                       Fig. 4. Computation performance with 2 nodes                                   Fig. 5. Computation performance with 8 nodes  4. Conclusion and future work  Tuning the parallel applications for efficient execution in Cloud is significant. We have devised a  methodology to improve the speed up and scale up of HPC applications on a range of platforms from  Amazonâ€™s HPC Cloud to HPC-optimized cluster. Our results emphasize the validity of our method. They  have been compared with the previous works done in the Cloud to verify the performance when HPC  applications have been deployed. We observed significant improvement in speed up and scale up for up to 8  nodes with the response rate of more than 20 percent parallel efficiency on the Cloud in comparison to  dedicated HPC cluster. Beyond that limit, considerable attention must be paid because we may run into  network interconnect bandwidth problems if we do not pre-reserve more instances.   We are of the opinion that Cloud provides a viable alternative solution for some HPC applications and not  all because application characteristics such as size and scale are important factors for the purpose of  determining the optimal platform. However, still there are chances of improving the performance by solving  the problems stated in section II. However, we expect there is a possibility of better parallel efficiency even  more than 40 percent scaling if we apply an explicit request for more CPU cores / instances.   In summary, we believe that Amazonâ€™s HPC Cloud is a viable platform for specifically parallel  computation intensive applications scaling up to high processor count and also for moderately sized parallel  communication intensive applications.   Analysis the performance of MPI version of other parallel sorting algorithms such as Quick sort, Merge  sort etc. on public Clouds like Amazon and Microsoft Azure will be useful in future.  References  [1] R.  Buyya,  C. S. Yeo, S.  Venugopal, J. Broberg, and I. Brandic, â€œCloud Computing and Emerging IT  Platforms: Vision, Hype, and Reality  for  Delivering  Computing  as  the  5th  Utilityâ€�  Future Generation  Computer Systems, vol. 25, no. 6, June 2009, pp 599-616, Elsevier Science, Amsterdam, Netherlands.  [2] â€œAmazon Elastic Compute Cloudâ€�, available at â€œhttp://aws.amazon.com/ec2â€�, accessed on 15/05/2014.  [3] A. Iosup, S. Ostermann, N. Yigitbasi, R. Prodan, T. Fahringer, and D. Epema, â€œPerformance Analysis of  Cloud Computing Services for Many-Tasks Scientific Computingâ€�, IEEE Trans. Parallel Distrib. Syst., vol.  22, pp. 931-945, June 2011.  [4] A. Iosup et al., â€œPerformance Analysis of Cloud Computing Services for Many-Tasks Scientific  Computingâ€�, Parallel and Distributed Systems, IEEE Transactions on, vol. 22, no. 6, pp. 931 -945, June 2011.  176   Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  [5] A. Gupta and D. Milojicic, â€œEvaluation of HPC Applications on Cloudâ€�, in Open Cirrus Summit, Atlanta,  GA, pp. 22 -26, Oct 2011.  [6] â€œSirius clusterâ€�, available at â€œhttp://wwwvhr.informatik.uni-rostock.de/vhr_cluster.htmlâ€�, accessed on  15/05/2014.  [7] Rashid Hassani, Riaz Choudhury, and Peter Luksch, â€œAnalysis of Sparse Matrix-Vector Multiplication  Using Iterative Method in CUDAâ€�, IEEE NAS 2013, ISBN: 978-0-7695-5034-3/13, pp. 262-266, DOI:  10.1109/NAS.2013.41, July 2013.  [8] Rashid Hassani, and Peter Luksch, â€œHigh Performance Concurrent Multi-Path Communication for MPIâ€�,  EuroPVM/MPI 2012, Springer LNCS 7490, pp. 285-286, DOI: 10.1007/978-3-642-33518-1_34, Sep 2012.  [9] Rashid Hassani and Peter Luksch, â€œScalable High Performance Computing in Wide Area Networkâ€�,  HPCS 2012, ISBN: 978-1-4673-2362-8/12, pp. 684-686, DOI: 10.1109/HPCSim.2012.6266993, July 2012.  [10] Rashid Hassani, and Peter Luksch, â€œOptimizing Bandwidth by Employing MPLS AToM with QoS  Supportâ€�, IEEE NAS 2012, ISBN: 978-0-7695-4722-0/12, pp. 104-108, DOI:  10.1109/NAS.2012.18, June  2012.  [11] Rashid Hassani, and Peter Luksch, â€œDMT: A new Approach of DiffServ QoS Methodologyâ€�, AICT  2012, ISBN: 978-1-61208-199-1, pp. 179-183, May 2012.  [12] J. Ekanayake, X. Qiu, T. Gunarathne, S. Beason, and G. C. Fox, â€œHigh Performance Parallel Computing  with Clouds and Cloud Technologiesâ€�, CRC Press (Taylor and Francis), July 2010.  [13] Q. He, S. Zhou, B. Kobler, D. Duffy, and T. McGlynn, â€œCase study for running HPC applications in  public cloudsâ€�, ACM International Symposium on High Performance Distributed Computing, ser. HPDC â€™10.  New York, NY, USA: ACM, pp. 395-401, 2010.  [14] K. R. Jackson, L. Ramakrishnan, K. Muriki, S. Canon, S. Cholia, J. Shalf, H. J. Wasserman, and N. J.  Wright, â€œPerformance analysis of high performance computing applications on the amazon web services  cloudâ€�, in CloudComâ€™10, 2010.  [15] Yan Zhai, Mingliang Liu, Jidong Zhai, Xiaosong Ma, and Wenguang Chen, â€œCloud versus in-house  cluster: Evaluating Amazon cluster compute instances for running MPI applicationsâ€�, International  Conference in High Performance Computing, Networking, Storage and Analysis (SC2011) , pp. 1-10, 2011.  [16] L. Rashid, W. Hassanein, and M. Hammad, â€œAnalyzing and enhancing the parallel sort operation on  multithreaded architecturesâ€�, Journal of Supercomputing, vol. 53, no. 2, pp. 293â€“312, 2010.  [17] â€œMagellan - Argonneâ€™s DoE Cloud Computingâ€�, available at â€œhttp:// magellan.alcf.anl.govâ€�, accessed on  15/05/2014.  [18] â€œNebula Cloud Computing Platformâ€�, available at â€œhttp://nebula.nasa.govâ€�, accessed on 15/05/2014.  [19] Kun Zhou, Minmin Gong, Xin Huang, and Baining Guo, "Data-Parallel Octrees for Surface  Reconstruction", IEEE Transactions on Visualization &amp; Computer Graphics, 2010.  [20] Nadathur Satish et al., "Fast sort on CPUs and GPUs: a case for bandwidth oblivious SIMD sort", pp.  351-362, 2010.  [21] Guojing  Cong,  George  Almasi,  and  Vijay  Saraswat,  "Fast  PGAS  Implementation  of Distributed   Graph  Algorithms", ACM/IEEE  International Conference  for  High  Performance  Computing,  Networking,   Storage  and  Analysis  (SC'10), pp. 1-11, 2010.  [22] Duane. M, Andrew. G, â€œHigh Performance and Scalable Radix Sortingâ€�, Department of Computer  Science, University of Virginia Charlottesville, Virginia, USA, Jan 2011.  [23] Rashid Hassani, Ganesh Chavan and Peter Luksch, â€œOptimization of Communication in MPI-Based  Clustersâ€�, IEEE computer society, CyberC 2014, Oct 2014.        , R. Prodan, T. Fahringer, and D. Epema, â€œPerformance Analysis of  Cloud Computing Services for Many-Tasks Scientific Computingâ€�, IEEE Trans. Parallel Distrib. Syst., vol.  22, pp. 931-945, June 2011.  [4] A. Iosup et al., â€œPerformance Analysis of Cloud Computing Services for Many-Tasks Scientific  Computingâ€�, Parallel and Distributed Systems, IEEE Transactions on, vol. 22, no. 6, pp. 931 -945, June 2011.  176   Rashid Hassani et al. /  IERI Procedia  10 ( 2014 )  169 â€“ 176  [5] A. Gupta and D. Milojicic, â€œEvaluation of HPC Applications on Cloudâ€�, in Open Cirrus Summit, Atlanta,  GA, pp. 22 -26, Oct 2011.  [6] â€œSirius clusterâ€�, available at â€œhttp://wwwvhr.informatik.uni-rostock.de/vhr_cluster.htmlâ€�, accessed on  15/05/2014.  [7] Rashid Hassani, Riaz Choudhury, and Peter Luksch, â€œAnalysis of Sparse Matrix-Vector Multiplication  Using Iterative Method in CUDAâ€�, IEEE NAS 2013, ISBN: 978-0-7695-5034-3/13, pp. 262-266, DOI:  10.1109/NAS.2013.41, July 2013.  [8] Rashid Hassani, and Peter Luksch, â€œHigh Performance Concurrent Multi-Path Communication for MPIâ€�,  EuroPVM/MPI 2012, Springer LNCS 7490, pp. 285-286, DOI: 10.1007/978-3-642-33518-1_34, Sep 2012.  [9] Rashid Hassani and Peter Luksch, â€œScalable High Performance Computing in Wide Area Networkâ€�,  HPCS 2012, ISBN: 978-1-4673-2362-8/12, pp. 684-686, DOI: 10.1109/HPCSim.2012.6266993, July 2012.  [10] Rashid Hassani, and Peter Luksch, â€œOptimizing Bandwidth by Employing MPLS AToM with QoS  Supportâ€�, IEEE NAS 2012, ISBN: 978-0-7695-4722-0/12, pp. 104-108, DOI:  10.1109/NAS.2012.18, June  2012.  [11] Rashid Hassani, and Peter Luksch, â€œDMT: A new Approach of DiffServ QoS Methodologyâ€�, AICT  2012, ISBN: 978-1-61208-199-1, pp. 179-183, May 2012.  [12] J. Ekanayake, X. Qiu, T. Gunarathne, S. Beason, and G. C. Fox, â€œHigh Performance Parallel Computing  with Clouds and Cloud Technologiesâ€�, CRC Press (Taylor and Francis), July 2010.  [13] Q. He, S. Zhou, B. Kobler, D. Duffy, and T. McGlynn, â€œCase study for running HPC applications in  public cloudsâ€�, ACM International Symposium on High Performance Distributed Computing, ser. HPDC â€™10.  New York, NY, USA: ACM, pp. 395-401, 2010.  [14] K. R. Jackson, L. Ramakrishnan, K. Muriki, S. Canon, S. Cholia, J. Shalf, H. J. Wasserman, and N. J.  Wright, â€œPerformance analysis of high performance computing applications on the amazon web services  cloudâ€�, in CloudComâ€™10, 2010.  [15] Yan Zhai, Mingliang Liu, Jidong Zhai, Xiaosong Ma, and Wenguang Chen, â€œCloud versus in-house  cluster: Evaluating Amazon cluster compute instances for running MPI applicationsâ€�, International  Conference in High Performance Computing, Networking, Storage and Analysis (SC2011) , pp. 1-10, 2011.  [16] L. Rashid, W. Hassanein, and M. Hammad, â€œAnalyzing and enhancing the parallel sort operation on  multithreaded architecturesâ€�, Journal of Supercomputing, vol. 53, no. 2, pp. 293â€“312, 2010.  [17] â€œMagellan - Argonneâ€™s DoE Cloud Computingâ€�, available at â€œhttp:// magellan.alcf.anl.govâ€�, accessed on  15/05/2014.  [18] â€œNebula Cloud Computing Platformâ€�, available at â€œhttp://nebula.nasa.govâ€�, accessed on 15/05/2014.  [19] Kun Zhou, Minmin Gong, Xin Huang, and Baining Guo, "Data-Parallel Octrees for Surface  Reconstruction", IEEE Transactions on Visualization &amp; Computer Graphics, 2010.  [20] Nadathur Satish et al., "Fast sort on CPUs and GPUs: a case for bandwidth oblivious SIMD sort", pp.  351-362, 2010.  [21] Guojing  Cong,  George  Almasi,  and  Vijay  Saraswat,  "Fast  PGAS  Implementation  of Distributed   Graph  Algorithms", ACM/IEEE  International Conference  fo</xocs:rawtext><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" version="5.2" xml:lang="en" docsubtype="fla"><item-info><jid>IERI</jid><aid>471</aid><ce:pii>S2212-6678(14)00120-8</ce:pii><ce:doi>10.1016/j.ieri.2014.09.072</ce:doi><ce:copyright type="other" year="2014">The Authors</ce:copyright></item-info><head><ce:article-footnote><ce:label>☆</ce:label><ce:note-para id="npar0005" view="all">Selection and peer review under responsibility of Information Engineering Research Institute.</ce:note-para></ce:article-footnote><ce:title id="tit0005">Improving HPC Application Performance in Public Cloud</ce:title><ce:author-group id="aug0005"><ce:author id="aut0005"><ce:given-name>Rashid</ce:given-name><ce:surname>Hassani</ce:surname><ce:cross-ref id="crf0005" refid="cor0005"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:e-address id="eadd0005" type="email">rashid.hassani@uni-rostock.de</ce:e-address></ce:author><ce:author id="aut0010"><ce:given-name>Md</ce:given-name><ce:surname>Aiatullah</ce:surname></ce:author><ce:author id="aut0015"><ce:given-name>Peter</ce:given-name><ce:surname>Luksch</ce:surname></ce:author><ce:affiliation id="aff0005"><ce:textfn>University of Rostock, Rostock, 18059, Germany</ce:textfn></ce:affiliation><ce:correspondence id="cor0005"><ce:label>⁎</ce:label><ce:text>Corresponding author. Tel.: +49-3814987565; fax: +49-3814987522.</ce:text></ce:correspondence></ce:author-group><ce:abstract id="abs0005" view="all" class="author"><ce:section-title id="sect0005">Abstract</ce:section-title><ce:abstract-sec id="abst0005" view="all"><ce:simple-para id="spar0005" view="all">Improving as well as evaluating the performance of High Performance Computing (HPC) applications by migrating them to Cloud environments are widely considered as critical issues in the field of high performance and Cloud computing. However, poor network performance, heterogeneous and dynamic environments are some series of pitfalls for execution of HPC applications in Cloud. This paper proposes a new approach to improve the performance and scalability of HPC applications on Amazon's HPC Cloud. The evidence from our approach points a significant improvement in speed up and scale up with the response rate of more than 20 percent parallel efﬁciency on the Cloud in comparison to dedicated HPC cluster. We state that the EC2 Cloud system is a feasible platform for deploying on-demand, small sized HPC applications.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="kwd0005" class="keyword" view="all"><ce:section-title id="sect0010">Keywords</ce:section-title><ce:keyword id="kw0005"><ce:text>Cloud computing</ce:text></ce:keyword><ce:keyword id="kw0010"><ce:text>HPC applications</ce:text></ce:keyword><ce:keyword id="kw0015"><ce:text>parallel sorting algorithm</ce:text></ce:keyword><ce:keyword id="kw0020"><ce:text>MPI</ce:text></ce:keyword><ce:keyword id="kw0025"><ce:text>Amazon EC2</ce:text></ce:keyword></ce:keywords></head><tail view="all"><ce:bibliography id="bibl0005" view="all"><ce:section-title id="sect0020">References</ce:section-title><ce:bibliography-sec id="bibs0005" view="all"><ce:bib-reference id="bib0005"><ce:label>[1]</ce:label><ce:other-ref id="oref0005"><ce:textref>R. Buyya, C.S. Yeo, S. Venugopal, J. Broberg, and I. Brandic, “Cloud Computing and Emerging IT Platforms: Vision, Hype, and Reality for Delivering Computing as the 5th Utility” Future Generation Computer Systems, vol. 25, no. 6, June 2009, pp 599-616, Elsevier Science, Amsterdam, Netherlands.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>[2]</ce:label><ce:other-ref id="oref0010"><ce:textref>“Amazon Elastic Compute Cloud”, available at “http://aws.amazon.com/ec2”, accessed on 15/05/2014.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>[3]</ce:label><ce:other-ref id="oref0015"><ce:textref>A. Iosup, S. Ostermann, N. Yigitbasi, R. Prodan, T. Fahringer, and D. Epema, “Performance Analysis of Cloud Computing Services for Many-Tasks Scientiﬁc Computing”, IEEE Trans. Parallel Distrib. Syst., vol. 22, pp. 931-945, June 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0020"><ce:label>[4]</ce:label><ce:other-ref id="oref0020"><ce:textref>A. Iosup et al., “Performance Analysis of Cloud Computing Services for Many-Tasks Scientiﬁc Computing”, Parallel and Distributed Systems, IEEE Transactions on, vol. 22, no. 6, pp. 931-945, June 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0025"><ce:label>[5]</ce:label><ce:other-ref id="oref0025"><ce:textref>A. Gupta and D. Milojicic, “Evaluation of HPC Applications on Cloud”, in Open Cirrus Summit, Atlanta, GA, pp. 22-26, Oct 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0030"><ce:label>[6]</ce:label><ce:other-ref id="oref0030"><ce:textref>“Sirius cluster”, available at “http://wwwvhr.informatik.uni-rostock.de/vhr_cluster.html”, accessed on 15/05/2014.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0035"><ce:label>[7]</ce:label><ce:other-ref id="oref0035"><ce:textref>Rashid Hassani, Riaz Choudhury, and Peter Luksch, “Analysis of Sparse Matrix-Vector Multiplication Using Iterative Method in CUDA”, IEEE NAS 2013, ISBN: 978-0-7695-5034-3/13, pp. 262-266, DOI: 10.1109/NAS. 2013.41, July 2013.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0040"><ce:label>[8]</ce:label><ce:other-ref id="oref0040"><ce:textref>Rashid Hassani, and Peter Luksch, “High Performance Concurrent Multi-Path Communication for MPI”, EuroPVM/MPI 2012, Springer LNCS 7490, pp. 285-286, DOI: 10.1007/978-3-642-33518-1_34, Sep 2012.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0045"><ce:label>[9]</ce:label><ce:other-ref id="oref0045"><ce:textref>Rashid Hassani and Peter Luksch, “Scalable High Performance Computing in Wide Area Network”, HPCS 2012, ISBN: 978-1-4673-2362-8/12, pp. 684-686, DOI: 10.1109/HPCSim.2012.6266993, July 2012.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0050"><ce:label>[10]</ce:label><ce:other-ref id="oref0050"><ce:textref>Rashid Hassani, and Peter Luksch, “Optimizing Bandwidth by Employing MPLS AToM with QoS Support”, IEEE NAS 2012, ISBN: 978-0-7695-4722-0/12, pp. 104-108, DOI: 10.1109/NAS. 2012.18, June 2012.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0055"><ce:label>[11]</ce:label><ce:other-ref id="oref0055"><ce:textref>Rashid Hassani, and Peter Luksch, “DMT: A new Approach of DiffServ QoS Methodology”, AICT 2012, ISBN: 978-1-61208-199-1, pp. 179-183, May 2012.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0060"><ce:label>[12]</ce:label><ce:other-ref id="oref0060"><ce:textref>J. Ekanayake, X. Qiu, T. Gunarathne, S. Beason, and G. C. Fox, “High Performance Parallel Computing with Clouds and Cloud Technologies”, CRC Press (Taylor and Francis), July 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0065"><ce:label>[13]</ce:label><ce:other-ref id="oref0065"><ce:textref>Q. He, S. Zhou, B. Kobler, D. Duffy, and T. McGlynn, “Case study for running HPC applications in public clouds”, ACM International Symposium on High Performance Distributed Computing, ser. HPDC ‘10. New York, NY, USA:;1; ACM, pp. 395-401, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0070"><ce:label>[14]</ce:label><ce:other-ref id="oref0070"><ce:textref>K. R. Jackson, L. Ramakrishnan, K. Muriki, S. Canon, S. Cholia, J. Shalf, H.J. Wasserman, and N. J. Wright, “Performance analysis of high performance computing applications on the amazon web services cloud”, in CloudCom’10, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0075"><ce:label>[15]</ce:label><ce:other-ref id="oref0075"><ce:textref>Yan Zhai, Mingliang Liu, Jidong Zhai, Xiaosong Ma, and Wenguang Chen, “Cloud versus in-house cluster: Evaluating Amazon cluster compute instances for running MPI applications”, International Conference in High Performance Computing, Networking, Storage and Analysis (SC2011), pp. 1-10, 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0080"><ce:label>[16]</ce:label><ce:other-ref id="oref0080"><ce:textref>L. Rashid, W. Hassanein, and M. Hammad, “Analyzing and enhancing the parallel sort operation on multithreaded architectures”, Journal of Supercomputing, vol. 53, no. 2, pp. 293-312, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0085"><ce:label>[17]</ce:label><ce:other-ref id="oref0085"><ce:textref>“Magellan - Argonne's DoE Cloud Computing”, available at “http://magellan.alcf.anl.gov”, accessed on 15/05/2014.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0090"><ce:label>[18]</ce:label><ce:other-ref id="oref0090"><ce:textref>“Nebula Cloud Computing Platform”, available at “http://nebula.nasa.gov”, accessed on 15/05/2014.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0095"><ce:label>[19]</ce:label><ce:other-ref id="oref0095"><ce:textref>Kun Zhou, Minmin Gong, Xin Huang, and Baining Guo, “Data-Parallel Octrees for Surface Reconstruction”, IEEE Transactions on Visualization &amp; Computer Graphics, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0100"><ce:label>[20]</ce:label><ce:other-ref id="oref0100"><ce:textref>Nadathur Satish et al., “Fast sort on CPUs and GPUs: a case for bandwidth oblivious SIMD sort”, pp. 351-362, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0105"><ce:label>[21]</ce:label><ce:other-ref id="oref0105"><ce:textref>Guojing Cong, George Almasi, and Vijay Saraswat, “Fast PGAS Implementation of Distributed Graph Algorithms”, ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis (SC’10), pp. 1-11, 2010.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0110"><ce:label>[22]</ce:label><ce:other-ref id="oref0110"><ce:textref>Duane. M, Andrew. G, “High Performance and Scalable Radix Sorting”, Department of Computer Science, University of Virginia Charlottesville, Virginia, USA, Jan 2011.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0115"><ce:label>[23]</ce:label><ce:other-ref id="oref0115"><ce:textref>Rashid Hassani, Ganesh Chavan and Peter Luksch, “Optimization of Communication in MPI-Based Clusters”, IEEE computer society, CyberC 2014, Oct 2014.</ce:textref></ce:other-ref></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
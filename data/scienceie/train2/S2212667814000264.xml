<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S2212667814000264</prism:url><dc:identifier>doi:10.1016/j.ieri.2014.08.007</dc:identifier><eid>1-s2.0-S2212667814000264</eid><prism:doi>10.1016/j.ieri.2014.08.007</prism:doi><pii>S2212-6678(14)00026-4</pii><dc:title>Increasing Immersiveness into a 3D Virtual World: Motion-tracking and Natural Navigation in vAcademia </dc:title><prism:publicationName>IERI Procedia</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>22126678</prism:issn><prism:volume>7</prism:volume><prism:startingPage>35</prism:startingPage><prism:endingPage>41</prism:endingPage><prism:pageRange>35-41</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2014-12-31</prism:coverDate><prism:coverDisplayDate>2014</prism:coverDisplayDate><prism:copyright>Copyright © 2014 The Authors. Published by Elsevier B.V.</prism:copyright><prism:publisher>The Authors. Published by Elsevier B.V.</prism:publisher><prism:issueName>International Conference on Applied Computing, Computer Science, and Computer Engineering (ICACC 2013)</prism:issueName><dc:creator>Fominykh, Mikhail</dc:creator><dc:creator>Prasolova-Førland, Ekaterina</dc:creator><dc:creator>Morozov, Mikhail</dc:creator><dc:creator>Smorkalov, Andrey</dc:creator><dc:creator>Molka-Danielsen, Judith</dc:creator><dc:description>AbstractIn this paper, we present a project aiming at integrating immersive virtual reality technologies into a three-dimensional virtual world. We use an educational platform vAcademia as a test bed for the project, and focus on improving the learning process and, subsequently – the outcomes. We aim at increasing the immersiveness of 3D virtual world experience by applying motion tracking for controlling the avatar and two technologies for natural navigation: immersive projection and head-mounted display. In addition, we propose the major types of learning scenarios for the use of the designed systems.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType>ElsevierWaived</openaccessSponsorType><openaccessUserLicense>http://creativecommons.org/licenses/by-nc-nd/3.0/</openaccessUserLicense><dcterms:subject>3D virtual worlds</dcterms:subject><dcterms:subject>motion capture</dcterms:subject><dcterms:subject>Kinect</dcterms:subject><dcterms:subject>immersive projection technology</dcterms:subject><dcterms:subject>CAVE</dcterms:subject><dcterms:subject>head-mounted displays</dcterms:subject><dcterms:subject>Oculus Rift</dcterms:subject><dcterms:subject>vAcademia.</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S2212667814000264"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S2212667814000264"/></coredata><scopus-id>84922940617</scopus-id><scopus-eid>2-s2.0-84922940617</scopus-eid><link rel="abstract" href="http://api.elsevier.com/content/abstract/scopus_id/84922940617"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>282178</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291773</xocs:ssid><xocs:ssid type="subj">291800</xocs:ssid><xocs:ssid type="subj">291880</xocs:ssid><xocs:ssid type="subj">291882</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>IERI Procedia</xocs:srctitle><xocs:normalized-srctitle>IERIPROCEDIA</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20140906">2014-09-06</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20140906">2014-09-06</xocs:available-online-date><xocs:ew-transaction-id>2014-09-05T18:28:39</xocs:ew-transaction-id><xocs:eid>1-s2.0-S2212667814000264</xocs:eid><xocs:pii-formatted>S2212-6678(14)00026-4</xocs:pii-formatted><xocs:pii-unformatted>S2212667814000264</xocs:pii-unformatted><xocs:doi>10.1016/j.ieri.2014.08.007</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.1</xocs:item-version-number><xocs:item-weight>HEAD-AND-TAIL</xocs:item-weight><xocs:hub-eid>1-s2.0-S2212667814X00031</xocs:hub-eid><xocs:timestamp yyyymmdd="20150515">2015-05-15T07:34:50.756359-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20140101</xocs:date-search-begin><xocs:date-search-end>20141231</xocs:date-search-end><xocs:year-nav>2014</xocs:year-nav><xocs:indexeddate epoch="1409970589">2014-09-06T02:29:49.664744Z</xocs:indexeddate><xocs:articleinfo>rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>2212-6678</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>22126678</xocs:issn-primary-unformatted></xocs:issns><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>7</xocs:vol-first><xocs:volume-list><xocs:volume>7</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 7</xocs:vol-iss-suppl-text><xocs:sort-order>7</xocs:sort-order><xocs:first-fp>35</xocs:first-fp><xocs:last-lp>41</xocs:last-lp><xocs:pages><xocs:first-page>35</xocs:first-page><xocs:last-page>41</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>2014</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>2014</xocs:cover-date-text><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:cover-date-year>2014</xocs:cover-date-year><xocs:title-editors-groups><xocs:title-editors-group><ce:title>International Conference on Applied Computing, Computer Science, and Computer Engineering (ICACC 2013)</ce:title><ce:editors><ce:author-group><ce:author><ce:given-name>Garry</ce:given-name><ce:surname>Lee</ce:surname></ce:author></ce:author-group></ce:editors></xocs:title-editors-group></xocs:title-editors-groups><xocs:hub-sec><xocs:hub-sec-title>Computer Science and Engineering</xocs:hub-sec-title></xocs:hub-sec><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>Copyright © 2014 The Authors. Published by Elsevier B.V.</xocs:copyright-line><xocs:normalized-article-title>INCREASINGIMMERSIVENESSA3DVIRTUALWORLDMOTIONTRACKINGNATURALNAVIGATIONINVACADEMIA</xocs:normalized-article-title><xocs:normalized-first-auth-surname>FOMINYKH</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>M</xocs:normalized-first-auth-initial><xocs:references><xocs:ref-info refid="oref0005"/><xocs:ref-info refid="sbref0010"><xocs:ref-normalized-surname>KLUGE</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>127</xocs:ref-first-fp><xocs:ref-last-lp>135</xocs:ref-last-lp><xocs:ref-normalized-initial>S</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0015"><xocs:ref-normalized-surname>KUMAR</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>46</xocs:ref-first-fp><xocs:ref-last-lp>53</xocs:ref-last-lp><xocs:ref-normalized-initial>S</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0020"><xocs:ref-normalized-surname>DUNCAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>949</xocs:ref-first-fp><xocs:ref-last-lp>964</xocs:ref-last-lp><xocs:ref-normalized-initial>I</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0025"><xocs:ref-normalized-surname>HEW</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>33</xocs:ref-first-fp><xocs:ref-last-lp>55</xocs:ref-last-lp><xocs:ref-normalized-initial>K</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0030"><xocs:ref-normalized-surname>PASCO</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>429</xocs:ref-first-fp><xocs:ref-last-lp>441</xocs:ref-last-lp><xocs:ref-normalized-initial>D</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0035"><xocs:ref-normalized-surname>HUANG</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>1171</xocs:ref-first-fp><xocs:ref-last-lp>1182</xocs:ref-last-lp><xocs:ref-normalized-initial>H</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0040"><xocs:ref-normalized-surname>ROUSSOU</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>227</xocs:ref-first-fp><xocs:ref-last-lp>240</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0045"><xocs:ref-normalized-surname>MONAHAN</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year><xocs:ref-first-fp>1339</xocs:ref-first-fp><xocs:ref-last-lp>1353</xocs:ref-last-lp><xocs:ref-normalized-initial>T</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0050"><xocs:ref-normalized-surname>TRINDADE</xocs:ref-normalized-surname><xocs:ref-pub-year>2002</xocs:ref-pub-year><xocs:ref-first-fp>471</xocs:ref-first-fp><xocs:ref-last-lp>488</xocs:ref-last-lp><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0055"><xocs:ref-normalized-surname>SLATER</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>3549</xocs:ref-first-fp><xocs:ref-last-lp>3557</xocs:ref-last-lp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="oref0060"/><xocs:ref-info refid="oref0065"/><xocs:ref-info refid="sbref0070"><xocs:ref-normalized-surname>SHOTTON</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-normalized-initial>J</xocs:ref-normalized-initial><xocs:ref-normalized-srctitle>MACHINELEARNINGFORCOMPUTERVISIONSPRINGER</xocs:ref-normalized-srctitle><xocs:ref-normalized-article-title>REALTIMEHUMANPOSERECOGNITIONINPARTSSINGLEDEPTHIMAGES</xocs:ref-normalized-article-title></xocs:ref-info><xocs:ref-info refid="oref0075"/><xocs:ref-info refid="sbref0080"><xocs:ref-normalized-surname>CRUZNEIRA</xocs:ref-normalized-surname><xocs:ref-pub-year>1992</xocs:ref-pub-year><xocs:ref-first-fp>64</xocs:ref-first-fp><xocs:ref-last-lp>72</xocs:ref-last-lp><xocs:ref-normalized-initial>C</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0085"><xocs:ref-normalized-surname>CAKMAKCI</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-first-fp>199</xocs:ref-first-fp><xocs:ref-last-lp>216</xocs:ref-last-lp><xocs:ref-normalized-initial>O</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0090"><xocs:ref-normalized-surname>ANTONOV</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="oref0095"/><xocs:ref-info refid="oref0100"/><xocs:ref-info refid="sbref0105"><xocs:ref-normalized-surname>BOYD</xocs:ref-normalized-surname><xocs:ref-pub-year>1983</xocs:ref-pub-year><xocs:ref-first-fp>99</xocs:ref-first-fp><xocs:ref-last-lp>117</xocs:ref-last-lp><xocs:ref-normalized-initial>E</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:refkeys><xocs:refkey3>FOMINYKHX2014X35</xocs:refkey3><xocs:refkey4lp>FOMINYKHX2014X35X41</xocs:refkey4lp><xocs:refkey4ai>FOMINYKHX2014X35XM</xocs:refkey4ai><xocs:refkey5>FOMINYKHX2014X35X41XM</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2014-09-05T13:04:50Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>ElsevierWaived</xocs:oa-sponsor-type></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by-nc-nd/3.0/</xocs:oa-user-license><xocs:oa-access-inherited-from winid="http://vtw.elsevier.com/content/oaw/PROC_UNBOUNDED_ESWaived">OA-Window</xocs:oa-access-inherited-from></xocs:open-access><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S2212-6678(14)00026-4</xocs:pii-formatted><xocs:pii-unformatted>S2212667814000264</xocs:pii-unformatted><xocs:eid>1-s2.0-S2212667814000264</xocs:eid><xocs:doi>10.1016/j.ieri.2014.08.007</xocs:doi><xocs:cid>282178</xocs:cid><xocs:timestamp>2014-09-05T21:29:49.664744-04:00</xocs:timestamp><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S2212667814000264-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814000264/MAIN/application/pdf/af0e6857cfc8ef21734512f052774c39/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814000264/MAIN/application/pdf/af0e6857cfc8ef21734512f052774c39/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>393455</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>7</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S2212667814000264-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2212667814000264/PREVIEW/image/png/72ed2ffb9e4f045c96219a8fef811637/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2212667814000264/PREVIEW/image/png/72ed2ffb9e4f045c96219a8fef811637/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>42629</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:rawtext> IERI Procedia   7  ( 2014 )  35 â€“ 41  Available online at www.sciencedirect.com 2212-6678  2014 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). Selection and peer review under responsibility of Information Engineering Research Institute doi: 10.1016/j.ieri.2014.08.007  ScienceDirect 20 M Abst In th virtu learn expe proje desig Â© 20 Molk Sele Keyw vAca * E 13 Internat Increasin Tr ikhail Fo a Program  b Mu c Departme ract is paper, we pr al world. We  ing process an rience by apply ction and head ned systems.  13Mikhail Fo a-Danielsen. ction and pee ords:3D virtual w demia.  Corresponding a -mail address: m ional Confe g Imme acking minykh a *, S for Learning wit ltimedia Systems nt of Economics, esent a projec use an educati d, subsequent ing motion tra -mounted disp minykh, Eka Published by  r review unde orlds; motion ca uthor.Tel.: (+47) ikhail.fominykh@ rence on A rsivene and Natu  Ekaterina  morkalov h ICT, Norwegia  Laboratory, Vol  Informatics, and t aiming at inte onal platform  ly â€“ the outco cking for contr lay. In additio terina Prasolo Elsevier B.V r responsibilit pture; Kinect; im  735 90731.  ntnu.no.  pplied Com Engineer ss into a ral Nav Prasolova b , Judith M n University of S ga State Univers  Social Sciences grating immer vAcademia as  mes. We aim olling the avata n, we propose  va-FÃ¸rland, M . y of Informat mersive projecti puting, Co ing   3D Vir igation -FÃ¸rland a , olka-Dan cience and Techn ity of Technology , Molde Universi sive virtual rea a test bed for  at increasing r and two tech the major type ikhail Moro ion Engineer on technology; C mputer Sci tual Wo in vAca Mikhail M ielsen c ology, NO-7491 , 424000 Yoshka ty College, NO-6 lity technolog  the project, a  the immersiv nologies for na s of learning  zov, Andrey S ing Research  AVE; head-mou ence, and C rld: Mo demia orozov b , A Trondheim, Norw r-Ola, Russia  402 Molde, Norw ies into a three nd focus on im eness of 3D  tural navigatio scenarios for th morkalov, Ju Institute  nted displays; O omputer  tion- ndrey ay ay -dimensional  proving the  virtual world  n: immersive  e use of the  dith  culus Rift;  2014 The Aut ors. Published by lsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). lection and peer r view under responsibility of Information Engineering Research Institute 36   Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  1. Introduction  Three-dimensional Virtual Worlds provide both opportunities and challenges for education, and many  topics in this area need further research[1,2]. Despite the repeated positive conclusions, 3D VWs have not  become widely used, and researchers often report that their studies have experimental nature. The most  common problems with applying 3D VWs in the everyday teaching are steep learning curve and demand for  computational and network resources [3]. As stated in recent surveys, the use of these technologies as learning  environments is a new emerging trend and still under development [4,5]. While the computers and networks  are constantly improving, the 3D VWs also require significant improvement to make them more convenient  for educators and to deal with the steep learning curve. These facts motivate further research in the area.  In this work, we consider 3D VWs as a type of VR technology â€“ a desktop VR. Various VR systems have  a number of unique features. These technologies are becoming more affordable, and their use has been  continuously increasing in recent years. They have also become more widespread as a technology for learning  despite many challenges. A number of studies have been done in this area outlining advantages and  limitations of these technologies as learning environments [6,7].  The main objective of the project presented in this paper is to explore the possibilities of an educational 3D  VW controlled by a motion-tracking device and accessed through IPT or CAVE and a HMD.Our specific  objectives are designing and developing three prototypes that would allow using vAcademia VW with the  three technologies mentioned above. In particular, we are aiming at enabling vAcademia to work with and  with the motion-tracking device Kinect, the ReaCTor CAVE facility, and with the HMD Oculus Rift. Such  implementation may allow extending the application domains of all three systems and open additional  possibilities for the VW. A research study will be conducted aiming at exploring these possibilities and  defining requirements for deploying the system into practice. Developing and evaluating three prototypes will allow testing the initial assumptions that each of the  mentioned VR technologies can be applied together with an educational 3D VW and benefit learning  experience. This achievement will lead to the opportunities for designing new learning and training activities  for practical use and conducting further research in specific areas of interest (e.g., architecture, health care,  emotions, cooperation, and logistics).  In this paper, we outline the design of the three prototypes we propose and present one of them, that  implements motion tracking, in more detail. We present the design, implementation of the first prototype,  evaluation results, discovered limitations, and outlined solutions. In addition, we describe the major types of  learning scenarios for the use of the all three designed systems.  Nomenclature  3D VW Three-dimensional Virtual Worlds  VR Virtual Reality  SDK  Software Development Kit  HMD  Head-mounted display  CAVE  Cave Automatic Virtual Environment  IPT  Immersive Projection Technology  37 Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  2. Background and Related Work  2.1. Virtual Reality and Desktop Virtual Reality  VR technology has long held promise for teaching and learning. The main arguments for their use are that  3D environments are engaging as media, and that the use of 3D rather than 2D media facilitates  comprehension by the means of situating learning materials in a context, and exploiting the natural  capabilities of humans to interact in 3D space [8]. Studies have shown that learning in 3D environment can  provide a more effective, motivated way of learning than traditional classroom practices [9,10].   Relatively few learning simulations have been built for immersive VR, though the evidence of use in very  high-value training (vehicle simulation, such as aircraft simulators or military training) is compelling. There  has been extensive study of the impact of 3D immersive visualization on user behavior, lower-level task  performance, and comprehension of data. A key characteristic, arguably the one that motivates the use of  immersive VR in high-value training, is that participants tend to react as if the scene they were seeing were  real. That is they behave in a way that is similar to their behavior in a comparable real situation [11]. This  behavioral response itself distinguishes an immersive VR from other media even desktop VR, because when  immersed the participant can actually act to a limited extent, as they would in the real world (e.g., by moving  away from a threat). In desktop VR, this capability is limited by the form and structure of the interface.  2.2. vAcademia  We propose a prototype design using a desktop VR platform vAcademia as a part of the  system.vAcademiais a 3D VW that is designed for collaborative learning (http://vacademia.com/).The most  distinctive feature of vAcademia is 3D recording which allows capturing everything in a given location in the  VW in process, including positions of the objects, appearance and movement of the avatars, displayed media,  and communication messages[12]. 3D recording is conceptually different from the video recording or screen  capturing. A replayed 3D recording does not only deliver the image at any virtual camera angle and a  synchronized communication messages, but contains the entire 3D scene with all objects and avatars. It can be  visited by a group of avatars that can interact with each other and the recorded objects. Moreover, such a visit  can be recorded again [12]. In addition, vAcademia provides a set of tools for collaborative work that can  handle large amount of 2D graphical content, such as streaming and shared workspaces [13].  2.3. Motion-Tracking with Kinect  Microsoft Kinect is a low-cost motion sensing input device that is able to capture one or two humans [14].  The device consists of a video camera, depth camera, and an IR camera.Low-cost motion-sensing  technologies such as Microsoft Kinect, Nintendo Wii Remote, and PlayStation Move provide researchers and  educators with new opportunities for improving learning experience. Multiple examples include a low-cost  alternative for interactive whiteboards and multi-touch teaching stations designed based on Kinect[15].   2.4. Cave Automatic Virtual Environments  CAVE is an IPT and a type of immersive VR [16]. A CAVE is typically a cube-shaped display that the  user stands inside. The CAVE surrounds the user, excluding other distractions and allowing the participant to  move about un-constrained. The wide field of view allows natural peripheral observation and gaze control.   38   Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  ReaCTor is an example of a CAVE system, where users are wearing head trackers situated on a stereo  shutter glasses. The user is surrounded by four large screens: floor, front, left and right walls. In addition, the  system providesspatialized sound. Interaction with the environment is achieved using a hand tracker with  joystick. Immersive VR such as CAVE-like environments have attracted industry attention in certain key  industries such as for example vehicle simulation and training, scientific visualization, and psychology.  2.5. Head-Mounted Display Oculus Rift  Head-mounted displayis a type of on-body VR devices that is worn on the head and has a display in front  of the userâ€™s eyes [17]. Most of these devices consist of a display and a tracking system. It allows much  greater immersion, as the user can control the direction of the view in a virtual world in exactly the same way  as in the physical world â€“ by turning the head. The displays of HMDs have larger field of view and provide a  stereoscopic image, making the experience more believable.  The Oculus Rift (http://www.oculusvr.com/) is an HMD device that has a 7-inch diagonal viewing area and  1280 to 800 resolution split between both eyes, yielding 640 to 800 per eye [18]. A good field of view,  stereoscopic vision, and fast tracking that are promised by the developers created high expectations.  3. Design of Prototypes  3.1. vAcademia-Kinect prototype  The general motivation for designing the vAcademia-Kinect prototype is providing users of the 3D VW  with a possibility to control their avatars with natural gestures. Our specific motivation for designing this  system lies in making the teachers able to conduct regular lectures and presentations in the physical and in the  virtual world at the same time, controlling their avatars with natural gestures.  We use two available technologies to implement the proposed system, Kinect and vAcademia. Kinect is  used for capturing the movement of a lecturer (Fig. 1), while vAcademia is used for creating and recording the  virtual replica of a lecture (Fig. 2). The third component of the system is a software plugin for vAcademia that  translates the motion data from Kinect, the sound, and the contents of the whiteboard into the 3D VW.  Such a hybrid experience can be captured using the virtual recording feature of vAcademia. Several  techniques are used by educators for getting content out of traditional classes, such as video recording of face- to-face lectures and recording of web conferences. These methods allow creating cheap educational content  for asynchronous learning. 3D VWs are also used for generating such content, but learning  activitiesareusually recorded as â€˜flatâ€™ 2D video, which eliminates many advantages of 3D VWs, such as sense  of presence.  39 Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  Fig. 1 Lecture capturing process  Fig. 2 Lecture streaming process  40   Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  3.2. vAcademia-CAVE prototype  The vAcademia-CAVE prototype is being designed should be informed by the literature review that gives  evidence of the learner engagement by use of simulation in learning. We apply a theoretical framework for  learning threshold concepts[19] in VR systems is needed to inform the systems design. In brief, the objective  of system design should be to explore new ways of learning that stimulate and enhance the potential of human  creativity [20]. The prototype design should consist of two development elements. First, implementation of  learning scenarios and second â€“ integration of the capability of â€œVR-replayâ€� feature that is newly designed in  this project to be functional between CAVE and vAcademia.  We hypothesize that using the 3D recording feature of vAcademia in the CAVE could potentially reveal  patterns of becoming aware of one's own reflective learning patterns and deciding to use them consciously.  Sequential interviews have been found to reveal this pattern [21]. The effect on learning of being able to  replay oneâ€™s life-size avatar representation and see oneâ€™s previous actions would be investigated.  The controlled environment allows running systematically observed and tracked learning sessions. This  approach will be used first to implement the scenarios. The testing of scenarios within the CAVE will allow  measuring single-user experience and observing physiological responses (as indicators of engagement). This  would be done for establishment of baseline measures prior to trials involving collaborative learning among  several participants. Multiple participant trials would be possible by running vAcademia in CAVE, so that the  participant in the CAVE would interact with other trial participants who would access the trial while using  vAcademia through desktop. We would compare learning responses of participants using vAcademia on the  desktop and in CAVE. In this way, key features of the threshold concept would be tested on a prototype that is  a CAVE version of vAcademia. The prototype design would aim to support the ultimate objective for  promoting students to overcome thresholds and enable them to identify what creativity in learning means in  relation to their individual experiences in transformative processes.  3.3. vAcademia-Oculus Rift prototype  The motivation for developing the vAcademia-Oculus Rift prototype is grounded in the same sources as  for the one with CAVE. We are aiming at improving immersion to the virtual environment and increasing the  engagement by providing a more sophisticated visual experience. However, the key differences are the higher  affordability and mobility of the HMD devices, the Oculus Rift in particular.  The system will also be applied to the scenarios that are being designed for the vAcademia-CAVE  prototype. However, we will conduct training sessions in multiple locations (without being restricted by a  single CAVE facility we have access to) and will be able to provide multiple (or all) participants of  collaborative scenarios with an immersive experience (avoiding the rigid single-user CAVE setup).  4. Conclusion  In this paper, we outlined the design of the three prototypes of systems that extend the immersive qualities  of a 3D VW vAcademia and improve the virtual experience. We propose that using a motion-tracking device  for controlling the avatar and a CAVE or HMD for perceiving the 3D environment will serve these purposes.   References  [1] Burkle M., Kinshuk (2009) Learning in Virtual Worlds: The Challenges and Opportunities. Paper presented at the 8th  International Conference on CyberWorlds (CW), Bradford, UK, September 7â€“11  41 Mikhail Fominykh et al. /  IERI Procedia  7 ( 2014 )  35 â€“ 41  [2] Kluge S., Riley E.: Teaching in Virtual Worlds: Opportunities and Challenges. The Journal of Issues in Informing Science and  Information Technology 5 (1):127â€“135, (2008)  [3] Kumar S., Chhugani J., Kim C., Kim D., Nguyen A., Dubey P., Bienia C., Kim Y.: Second Life and the New Generation of  Virtual Worlds. Computer 41 (9):46â€“53, (2008)  [4] Duncan I., Miller A., Jiang S.: A taxonomy of virtual worlds usage in education. British Journal of Educational Technology 43  (6):949â€“964, (2012)  [5] Hew K.F., Cheung W.S.: Use of three-dimensional (3-D) immersive virtual worlds in K-12 and higher education settings: A  review of the research. British Journal of Educational Technology 41 (1):33â€“55, (2010)  [6] Pasco D.: The Potential of Using Virtual Reality Technology in Physical Activity Settings. Quest 65 (4):429â€“441, (2013)  [7] Huang H.-M., Rauch U., Liaw S.-S.: Investigating learnersâ€™ attitudes toward virtual reality learning environments: Based on a  constructivist approach. Computers &amp; Education 55 (3):1171â€“1182, (2010)  [8] Roussou M., Oliver M., Slater M.: The virtual playground: an educational virtual reality environment for evaluating  interactivity and conceptual learning. Virtual Reality 10 (3-4):227â€“240, (2006)  [9] Monahan T., McArdle G., Bertolotto M.: Virtual reality for collaborative e-learning. Computers and Education 50 (4):1339â€“ 1353, (2008)  [10] Trindade J., Fiolhais C., Almeida L.: Science learning in virtual environments: a descriptive study. British Journal of  Educational Technology 33 (4):471â€“488, (2002)  [11] Slater M.: Place Illusion and Plausibility Can Lead to Realistic Behaviour in Immersive Virtual Environments. Philos Trans R  Soc Lond 364 (1535 ):3549â€“3557, (2009)  [12] Morozov M., Gerasimov A., Fominykh M., Smorkalov A.: Asynchronous Immersive Classes in a 3D Virtual World: Extended  Description of vAcademia. In: Gavrilova M, Tan CJK, Kuijper A (eds.) Transactions on Computational Science XVIII, vol  7848. Lecture Notes in Computer Science, pp. 81â€“100. Springer Berlin Heidelberg,  (2013)  [13] Smorkalov A., Fominykh M., Morozov M.: Collaborative Work with Large Amount of Graphical Content in a 3D Virtual  World: Evaluation of Learning Tools in vAcademia. In: 16th International Conference on Interactive Collaborative Learning  (ICL), Kazan, Russia, September 25â€“27, pp. 303â€“312. IEEE,  (2013)  [14] Shotton J., Fitzgibbon A., Cook M., Sharp T., Finocchio M., Moore R., Kipman A., Blake A.: Real-Time Human Pose  Recognition in Parts from Single Depth Images. Machine Learning for Computer Vision. Springer, Berlin Heidelberg (2013)  [15] Cheong S.N., Yap W.J., Logeswaran R., Chai I.: Design and Development of Kinect-Based Technology-Enhanced Teaching  Classroom. In: Park JJ, Jeong Y-S, Park SO, Chen H-C (eds.) Embedded and Multimedia Computing Technology and Service.  Lecture Notes in Electrical Engineering, vol 181, pp. 179â€“186.  (2012)  [16] Cruz-Neira C., Sandin D.J., DeFanti T.A., Kenyon R.V., Hart J.C.: The CAVE: audio visual experience automatic virtual  environment. Commun ACM 35 (6):64â€“72, (1992)  [17] Cakmakci O., Rolland J.: Head-worn displays: a review. Display Technology, Journal of 2 (3):199â€“216, (2006)  [18] Antonov M., Mitchell N., Reisse A., Cooper L., LaValle S., Katsev M.: Oculus Software Development Kit. Oculus VR, Inc.,  CA, USA (2013)  [19] Meyer J.H.F., Land R.: Threshold concepts and troublesome knowledge: issues of liminality. In: Meyer JHF, Land R (eds.)  Overcoming barriers to student understanding: threshold concepts and troublesome knowledge. pp. 19â€“32. Routledge,  Abingdon, UK (2006)  [20] Molka-Danielsen J., Savin-Baden M., Steed A., Fominykh M., Oyekoya O., Hokstad L.M., Prasolova-FÃ¸rland E.: Teaching  Threshold Concepts in Virtual Reality: Exploring the Conceptual Requirements for Systems Design. In: Fallmyr T (ed.) Norsk  konferanse for organisasjoners bruk av informasjonsteknologi (NOKOBIT), Stavanger, Norway, November 18â€“20.  Akademika forlag, Trondheim, Norway (2013)  [21] Boyd E.M., Fales A.W.: Reflective Learning: Key to Learning from Experience. Journal of Humanistic Psychology 23 (2):99â€“ 117, (1983)  Journal of Issues in Informing Science and  Informat</xocs:rawtext><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" version="5.2" xml:lang="en" docsubtype="fla"><item-info><jid>IERI</jid><aid>373</aid><ce:pii>S2212-6678(14)00026-4</ce:pii><ce:doi>10.1016/j.ieri.2014.08.007</ce:doi><ce:copyright type="other" year="2014">The Authors</ce:copyright></item-info><head><ce:article-footnote><ce:label>☆</ce:label><ce:note-para id="npar0005" view="all">Selection and peer review under responsibility of Information Engineering Research Institute.</ce:note-para></ce:article-footnote><ce:title id="tit0005">Increasing Immersiveness into a 3D Virtual World: Motion-tracking and Natural Navigation in vAcademia</ce:title><ce:author-group id="aug0005"><ce:author id="aut0005"><ce:given-name>Mikhail</ce:given-name><ce:surname>Fominykh</ce:surname><ce:cross-ref id="crf0005" refid="aff0005"><ce:sup loc="post">a</ce:sup></ce:cross-ref><ce:cross-ref id="crf0010" refid="cor0005"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:e-address id="eadd0005" type="email">mikhail.fominykh@ntnu.no</ce:e-address></ce:author><ce:author id="aut0010"><ce:given-name>Ekaterina</ce:given-name><ce:surname>Prasolova-Førland</ce:surname><ce:cross-ref id="crf0015" refid="aff0005"><ce:sup loc="post">a</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0015"><ce:given-name>Mikhail</ce:given-name><ce:surname>Morozov</ce:surname><ce:cross-ref id="crf0020" refid="aff0010"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0020"><ce:given-name>Andrey</ce:given-name><ce:surname>Smorkalov</ce:surname><ce:cross-ref id="crf0025" refid="aff0010"><ce:sup loc="post">b</ce:sup></ce:cross-ref></ce:author><ce:author id="aut0025"><ce:given-name>Judith</ce:given-name><ce:surname>Molka-Danielsen</ce:surname><ce:cross-ref id="crf0030" refid="aff0015"><ce:sup loc="post">c</ce:sup></ce:cross-ref></ce:author><ce:affiliation id="aff0005"><ce:label>a</ce:label><ce:textfn>Program for Learning with ICT, Norwegian University of Science and Technology, NO-7491Trondheim, Norway</ce:textfn></ce:affiliation><ce:affiliation id="aff0010"><ce:label>b</ce:label><ce:textfn>Multimedia Systems Laboratory, Volga State University of Technology, 424000 Yoshkar-Ola, Russia</ce:textfn></ce:affiliation><ce:affiliation id="aff0015"><ce:label>c</ce:label><ce:textfn>Department of Economics, Informatics, and Social Sciences, Molde University College, NO-6402 Molde, Norway</ce:textfn></ce:affiliation><ce:correspondence id="cor0005"><ce:label>⁎</ce:label><ce:text>Corresponding author. Tel.: (+47) 735 90731.</ce:text></ce:correspondence></ce:author-group><ce:abstract id="abs0005" view="all" class="author"><ce:section-title id="sect0005">Abstract</ce:section-title><ce:abstract-sec id="abst0005" view="all"><ce:simple-para id="spar0005" view="all">In this paper, we present a project aiming at integrating immersive virtual reality technologies into a three-dimensional virtual world. We use an educational platform vAcademia as a test bed for the project, and focus on improving the learning process and, subsequently – the outcomes. We aim at increasing the immersiveness of 3D virtual world experience by applying motion tracking for controlling the avatar and two technologies for natural navigation: immersive projection and head-mounted display. In addition, we propose the major types of learning scenarios for the use of the designed systems.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="kwd0005" class="keyword" view="all"><ce:section-title id="sect0010">Keywords</ce:section-title><ce:keyword id="kw0005"><ce:text>3D virtual worlds</ce:text></ce:keyword><ce:keyword id="kw0010"><ce:text>motion capture</ce:text></ce:keyword><ce:keyword id="kw0015"><ce:text>Kinect</ce:text></ce:keyword><ce:keyword id="kw0020"><ce:text>immersive projection technology</ce:text></ce:keyword><ce:keyword id="kw0025"><ce:text>CAVE</ce:text></ce:keyword><ce:keyword id="kw0030"><ce:text>head-mounted displays</ce:text></ce:keyword><ce:keyword id="kw0035"><ce:text>Oculus Rift</ce:text></ce:keyword><ce:keyword id="kw0040"><ce:text>vAcademia.</ce:text></ce:keyword></ce:keywords></head><tail view="all"><ce:bibliography id="bibl0005" view="all"><ce:section-title id="sect0020">References</ce:section-title><ce:bibliography-sec id="bibs0005" view="all"><ce:bib-reference id="bib0005"><ce:label>[1]</ce:label><ce:other-ref id="oref0005"><ce:textref>Burkle M., Kinshuk (2009) Learning in Virtual Worlds: The Challenges and Opportunities. Paper presented at the 8th International Conference on CyberWorlds (CW), Bradford, UK, September 7-11.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>[2]</ce:label><sb:reference id="sbref0010"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Kluge</ce:surname></sb:author><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Riley</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Teaching in Virtual Worlds: Opportunities and Challenges</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>The Journal of Issues in Informing Science and Information Technology</sb:maintitle></sb:title><sb:volume-nr>5</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>127</sb:first-page><sb:last-page>135</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>[3]</ce:label><sb:reference id="sbref0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Kumar</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Chhugani</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Kim</ce:surname></sb:author><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Kim</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Nguyen</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Dubey</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Bienia</ce:surname></sb:author><sb:author><ce:given-name>Y.</ce:given-name><ce:surname>Kim</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Second Life and the New Generation of Virtual Worlds</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computer</sb:maintitle></sb:title><sb:volume-nr>41</sb:volume-nr></sb:series><sb:issue-nr>9</sb:issue-nr><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>46</sb:first-page><sb:last-page>53</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0020"><ce:label>[4]</ce:label><sb:reference id="sbref0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>I.</ce:given-name><ce:surname>Duncan</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Miller</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>Jiang</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A taxonomy of virtual worlds usage in education</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>British Journal of Educational Technology</sb:maintitle></sb:title><sb:volume-nr>43</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>949</sb:first-page><sb:last-page>964</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0025"><ce:label>[5]</ce:label><sb:reference id="sbref0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>K.F.</ce:given-name><ce:surname>Hew</ce:surname></sb:author><sb:author><ce:given-name>W.S.</ce:given-name><ce:surname>Cheung</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Use of three-dimensional (3-D) immersive virtual worlds in K-12 and higher education settings: A review of the research</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>British Journal of Educational Technology</sb:maintitle></sb:title><sb:volume-nr>41</sb:volume-nr></sb:series><sb:issue-nr>1</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>33</sb:first-page><sb:last-page>55</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0030"><ce:label>[6]</ce:label><sb:reference id="sbref0030"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>D.</ce:given-name><ce:surname>Pasco</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The Potential of Using Virtual Reality Technology in Physical Activity Settings</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Quest</sb:maintitle></sb:title><sb:volume-nr>65</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>429</sb:first-page><sb:last-page>441</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0035"><ce:label>[7]</ce:label><sb:reference id="sbref0035"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>H.-M.</ce:given-name><ce:surname>Huang</ce:surname></sb:author><sb:author><ce:given-name>U.</ce:given-name><ce:surname>Rauch</ce:surname></sb:author><sb:author><ce:given-name>S.-S.</ce:given-name><ce:surname>Liaw</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Investigating learners’ attitudes toward virtual reality learning environments: Based on a constructivist approach</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computers &amp; Education</sb:maintitle></sb:title><sb:volume-nr>55</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>1171</sb:first-page><sb:last-page>1182</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0040"><ce:label>[8]</ce:label><sb:reference id="sbref0040"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Roussou</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Oliver</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Slater</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The virtual playground: an educational virtual reality environment for evaluating interactivity and conceptual learning</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Virtual Reality</sb:maintitle></sb:title><sb:volume-nr>10</sb:volume-nr></sb:series><sb:issue-nr>3–4</sb:issue-nr><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>227</sb:first-page><sb:last-page>240</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0045"><ce:label>[9]</ce:label><sb:reference id="sbref0045"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Monahan</ce:surname></sb:author><sb:author><ce:given-name>G.</ce:given-name><ce:surname>McArdle</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Bertolotto</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Virtual reality for collaborative e-learning. Computers and Education</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:volume-nr>50</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2008</sb:date></sb:issue><sb:pages><sb:first-page>1339</sb:first-page><sb:last-page>1353</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0050"><ce:label>[10]</ce:label><sb:reference id="sbref0050"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Trindade</ce:surname></sb:author><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Fiolhais</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Almeida</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Science learning in virtual environments: a descriptive study</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>British Journal of Educational Technology</sb:maintitle></sb:title><sb:volume-nr>33</sb:volume-nr></sb:series><sb:issue-nr>4</sb:issue-nr><sb:date>2002</sb:date></sb:issue><sb:pages><sb:first-page>471</sb:first-page><sb:last-page>488</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0055"><ce:label>[11]</ce:label><sb:reference id="sbref0055"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Slater</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Place Illusion and Plausibility Can Lead to Realistic Behaviour in Immersive Virtual Environments</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Philos Trans R Soc Lond</sb:maintitle></sb:title><sb:volume-nr>364</sb:volume-nr></sb:series><sb:issue-nr>1535</sb:issue-nr><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>3549</sb:first-page><sb:last-page>3557</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0060"><ce:label>[12]</ce:label><ce:other-ref id="oref0060"><ce:textref>Morozov M., Gerasimov A., Fominykh M., Smorkalov A.: Asynchronous Immersive Classes in a 3D Virtual World: Extended Description of vAcademia. In: Gavrilova M, Tan CJK, Kuijper A (eds.) Transactions on Computational Science XVIII, vol 7848. Lecture Notes in Computer Science, pp. 81-100. Springer Berlin Heidelberg, (2013).</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0065"><ce:label>[13]</ce:label><ce:other-ref id="oref0065"><ce:textref>Smorkalov A., Fominykh M., Morozov M. Collaborative Work with Large Amount of Graphical Content in a 3D Virtual World: Evaluation of Learning Tools in vAcademia. In: 16th International Conference on Interactive Collaborative Learning (ICL), Kazan, Russia, September 25-27, pp. 303-312. IEEE, (2013).</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0070"><ce:label>[14]</ce:label><sb:reference id="sbref0070"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Shotton</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Fitzgibbon</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Cook</ce:surname></sb:author><sb:author><ce:given-name>T.</ce:given-name><ce:surname>Sharp</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Finocchio</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Moore</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Kipman</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Blake</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Real-Time Human Pose Recognition in Parts from Single Depth Images</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:title><sb:maintitle>Machine Learning for Computer Vision. Springer</sb:maintitle></sb:title><sb:date>2013</sb:date><sb:publisher><sb:name>Berlin Heidelberg</sb:name></sb:publisher></sb:book></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0075"><ce:label>[15]</ce:label><ce:other-ref id="oref0075"><ce:textref>Cheong S.N., Yap W.J., Logeswaran R., Chai I.: Design and Development of Kinect-Based Technology-Enhanced Teaching Classroom. In: Park JJ, Jeong Y-S, Park SO, Chen H-C (eds.) Embedded and Multimedia Computing Technology and Service. Lecture Notes in Electrical Engineering, vol 181, pp. 179-186. (2012).</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0080"><ce:label>[16]</ce:label><sb:reference id="sbref0080"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>C.</ce:given-name><ce:surname>Cruz-Neira</ce:surname></sb:author><sb:author><ce:given-name>D.J.</ce:given-name><ce:surname>Sandin</ce:surname></sb:author><sb:author><ce:given-name>T.A.</ce:given-name><ce:surname>DeFanti</ce:surname></sb:author><sb:author><ce:given-name>R.V.</ce:given-name><ce:surname>Kenyon</ce:surname></sb:author><sb:author><ce:given-name>J.C.</ce:given-name><ce:surname>Hart</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The CAVE: audio visual experience automatic virtual environment</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Commun ACM</sb:maintitle></sb:title><sb:volume-nr>35</sb:volume-nr></sb:series><sb:issue-nr>6</sb:issue-nr><sb:date>1992</sb:date></sb:issue><sb:pages><sb:first-page>64</sb:first-page><sb:last-page>72</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0085"><ce:label>[17]</ce:label><sb:reference id="sbref0085"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>O.</ce:given-name><ce:surname>Cakmakci</ce:surname></sb:author><sb:author><ce:given-name>J.</ce:given-name><ce:surname>Rolland</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Head-worn displays: a review</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Display Technology, Journal of</sb:maintitle></sb:title><sb:volume-nr>2</sb:volume-nr></sb:series><sb:issue-nr>3</sb:issue-nr><sb:date>2006</sb:date></sb:issue><sb:pages><sb:first-page>199</sb:first-page><sb:last-page>216</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0090"><ce:label>[18]</ce:label><sb:reference id="sbref0090"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Antonov</ce:surname></sb:author><sb:author><ce:given-name>N.</ce:given-name><ce:surname>Mitchell</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Reisse</ce:surname></sb:author><sb:author><ce:given-name>L.</ce:given-name><ce:surname>Cooper</ce:surname></sb:author><sb:author><ce:given-name>S.</ce:given-name><ce:surname>LaValle</ce:surname></sb:author><sb:author><ce:given-name>M.</ce:given-name><ce:surname>Katsev</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Oculus Software Development Kit</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Oculus VR, Inc., CA, USA</sb:maintitle></sb:title></sb:series><sb:date>2013</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0095"><ce:label>[19]</ce:label><ce:other-ref id="oref0095"><ce:textref>Meyer J.H.F., Land R.: Threshold concepts and troublesome knowledge: issues of liminality. In: Meyer JHF, Land R (eds.) Overcoming barriers to student understanding: threshold concepts and troublesome knowledge. pp. 19-32. Routledge, Abingdon, UK (2006).</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0100"><ce:label>[20]</ce:label><ce:other-ref id="oref0100"><ce:textref>Molka-Danielsen J., Savin-Baden M., Steed A., Fominykh M., Oyekoya O., Hokstad L.M., Prasolova-Førland E.: Teaching Threshold Concepts in Virtual Reality: Exploring the Conceptual Requirements for Systems Design. In: Fallmyr T (ed.) Norsk konferanse for organisasjoners bruk av informasjonsteknologi (NOKOBIT), Stavanger, Norway, November 18-20. Akademika forlag, Trondheim, Norway (2013).</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0105"><ce:label>[21]</ce:label><sb:reference id="sbref0105"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>E.M.</ce:given-name><ce:surname>Boyd</ce:surname></sb:author><sb:author><ce:given-name>A.W.</ce:given-name><ce:surname>Fales</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Reflective Learning: Key to Learning from Experience</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Journal of Humanistic Psychology</sb:maintitle></sb:title><sb:volume-nr>23</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>1983</sb:date></sb:issue><sb:pages><sb:first-page>99</sb:first-page><sb:last-page>117</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
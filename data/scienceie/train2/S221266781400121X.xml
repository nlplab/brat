<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd"><coredata><prism:url>http://api.elsevier.com/content/article/pii/S221266781400121X</prism:url><dc:identifier>doi:10.1016/j.ieri.2014.09.073</dc:identifier><eid>1-s2.0-S221266781400121X</eid><prism:doi>10.1016/j.ieri.2014.09.073</prism:doi><pii>S2212-6678(14)00121-X</pii><dc:title>Distributionally Extended Network-based Word Sense Disambiguation in Semantic Clustering of Polish Texts </dc:title><prism:publicationName>IERI Procedia</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><prism:issn>22126678</prism:issn><prism:volume>10</prism:volume><prism:startingPage>38</prism:startingPage><prism:endingPage>44</prism:endingPage><prism:pageRange>38-44</prism:pageRange><dc:format>text/xml</dc:format><prism:coverDate>2014-12-31</prism:coverDate><prism:coverDisplayDate>2014</prism:coverDisplayDate><prism:copyright>Copyright © 2014 Published by Elsevier B.V.</prism:copyright><prism:publisher>Published by Elsevier B.V.</prism:publisher><prism:issueName>International Conference on Future Information Engineering (FIE 2014)</prism:issueName><dc:creator>Kędzia, Paweł</dc:creator><dc:creator>Piasecki, Maciej</dc:creator><dc:creator>Kocoń, Jan</dc:creator><dc:creator>Indyka-Piasecka, Agnieszka</dc:creator><dc:description>AbstractIn the paper we present an extended version of the graph-based unsupervised Word Sense Disambiguation algorithm. The algorithm is based on the spreading activation scheme applied to the graphs dynamically built on the basis of the text words and a large wordnet. The algorithm, originally proposed for English and Princeton WordNet, was adapted to Polish and plWordNet. An extension based on the knowledge acquired from the corpus-derived Measure of Semantic Relatedness was proposed. The extended algorithm was evaluated against the manually disambiguated corpus. We observed improvement in the case of the disambiguation performed for shorter text contexts. In addition the algorithm application expressed improvement in document clustering task.</dc:description><openaccess>1</openaccess><openaccessArticle>true</openaccessArticle><openaccessType>Full</openaccessType><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType>ElsevierWaived</openaccessSponsorType><openaccessUserLicense>http://creativecommons.org/licenses/by-nc-nd/3.0/</openaccessUserLicense><dcterms:subject>Word Sense Disambiguation</dcterms:subject><dcterms:subject>wordnet</dcterms:subject><dcterms:subject>text classification</dcterms:subject><dcterms:subject>plWordNet</dcterms:subject><link rel="self" href="http://api.elsevier.com/content/article/pii/S221266781400121X"/><link rel="scidir" href="http://www.sciencedirect.com/science/article/pii/S221266781400121X"/></coredata><scopus-id>84949799386</scopus-id><scopus-eid>2-s2.0-84949799386</scopus-eid><link rel="abstract" href="http://api.elsevier.com/content/abstract/scopus_id/84949799386"/><originalText><xocs:doc xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" xsi:schemaLocation="http://www.elsevier.com/xml/xocs/dtd http://be-prod3a/schema/dtds/document/fulltext/xcr/xocs-article.xsd"><xocs:meta><xocs:content-family>serial</xocs:content-family><xocs:content-type>JL</xocs:content-type><xocs:cid>282178</xocs:cid><xocs:ssids><xocs:ssid type="alllist">291210</xocs:ssid><xocs:ssid type="subj">291773</xocs:ssid><xocs:ssid type="subj">291800</xocs:ssid><xocs:ssid type="subj">291880</xocs:ssid><xocs:ssid type="subj">291882</xocs:ssid><xocs:ssid type="content">31</xocs:ssid><xocs:ssid type="oa">90</xocs:ssid></xocs:ssids><xocs:srctitle>IERI Procedia</xocs:srctitle><xocs:normalized-srctitle>IERIPROCEDIA</xocs:normalized-srctitle><xocs:orig-load-date yyyymmdd="20141001">2014-10-01</xocs:orig-load-date><xocs:available-online-date yyyymmdd="20141001">2014-10-01</xocs:available-online-date><xocs:ew-transaction-id>2014-10-10T04:56:58</xocs:ew-transaction-id><xocs:eid>1-s2.0-S221266781400121X</xocs:eid><xocs:pii-formatted>S2212-6678(14)00121-X</xocs:pii-formatted><xocs:pii-unformatted>S221266781400121X</xocs:pii-unformatted><xocs:doi>10.1016/j.ieri.2014.09.073</xocs:doi><xocs:item-stage>S300</xocs:item-stage><xocs:item-version-number>S300.2</xocs:item-version-number><xocs:item-weight>HEAD-AND-TAIL</xocs:item-weight><xocs:hub-eid>1-s2.0-S2212667814X00067</xocs:hub-eid><xocs:timestamp yyyymmdd="20150515">2015-05-15T07:34:50.756359-04:00</xocs:timestamp><xocs:dco>0</xocs:dco><xocs:tomb>0</xocs:tomb><xocs:date-search-begin>20140101</xocs:date-search-begin><xocs:date-search-end>20141231</xocs:date-search-end><xocs:year-nav>2014</xocs:year-nav><xocs:indexeddate epoch="1412186304">2014-10-01T17:58:24.885602Z</xocs:indexeddate><xocs:articleinfo>rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref</xocs:articleinfo><xocs:issns><xocs:issn-primary-formatted>2212-6678</xocs:issn-primary-formatted><xocs:issn-primary-unformatted>22126678</xocs:issn-primary-unformatted></xocs:issns><xocs:crossmark is-crossmark="1">true</xocs:crossmark><xocs:vol-first>10</xocs:vol-first><xocs:volume-list><xocs:volume>10</xocs:volume></xocs:volume-list><xocs:suppl>C</xocs:suppl><xocs:vol-iss-suppl-text>Volume 10</xocs:vol-iss-suppl-text><xocs:sort-order>7</xocs:sort-order><xocs:first-fp>38</xocs:first-fp><xocs:last-lp>44</xocs:last-lp><xocs:pages><xocs:first-page>38</xocs:first-page><xocs:last-page>44</xocs:last-page></xocs:pages><xocs:cover-date-orig><xocs:start-date>2014</xocs:start-date></xocs:cover-date-orig><xocs:cover-date-text>2014</xocs:cover-date-text><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:cover-date-year>2014</xocs:cover-date-year><xocs:title-editors-groups><xocs:title-editors-group><ce:title>International Conference on Future Information Engineering (FIE 2014)</ce:title><ce:editors><ce:author-group><ce:author><ce:given-name>Garry</ce:given-name><ce:surname>Lee</ce:surname></ce:author></ce:author-group></ce:editors></xocs:title-editors-group></xocs:title-editors-groups><xocs:hub-sec><xocs:hub-sec-title>Information Engineering</xocs:hub-sec-title></xocs:hub-sec><xocs:document-type>article</xocs:document-type><xocs:document-subtype>fla</xocs:document-subtype><xocs:copyright-line>Copyright © 2014 Published by Elsevier B.V.</xocs:copyright-line><xocs:normalized-article-title>DISTRIBUTIONALLYEXTENDEDNETWORKBASEDWORDSENSEDISAMBIGUATIONINSEMANTICCLUSTERINGPOLISHTEXTS</xocs:normalized-article-title><xocs:normalized-first-auth-surname>KEDZIA</xocs:normalized-first-auth-surname><xocs:normalized-first-auth-initial>P</xocs:normalized-first-auth-initial><xocs:references><xocs:ref-info refid="sbref0005"><xocs:ref-normalized-surname>YOANGUTIERREZ</xocs:ref-normalized-surname><xocs:ref-pub-year>2012</xocs:ref-pub-year><xocs:ref-first-fp>225</xocs:ref-first-fp><xocs:ref-last-lp>237</xocs:ref-last-lp></xocs:ref-info><xocs:ref-info refid="sbref0010"><xocs:ref-normalized-surname>GEORGETSATSARONIS</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>184</xocs:ref-first-fp><xocs:ref-last-lp>198</xocs:ref-last-lp></xocs:ref-info><xocs:ref-info refid="sbref0015"><xocs:ref-normalized-surname>MIHALCEA</xocs:ref-normalized-surname><xocs:ref-pub-year>2004</xocs:ref-pub-year><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0020"><xocs:ref-normalized-surname>AGIRRE</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-first-fp>33</xocs:ref-first-fp><xocs:ref-last-lp>41</xocs:ref-last-lp><xocs:ref-normalized-initial>E</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0025"><xocs:ref-normalized-surname>NAVIGLI</xocs:ref-normalized-surname><xocs:ref-pub-year>2006</xocs:ref-pub-year><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0030"><xocs:ref-normalized-surname>SINHA</xocs:ref-normalized-surname><xocs:ref-pub-year>2007</xocs:ref-pub-year><xocs:ref-normalized-initial>R</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0035"><xocs:ref-normalized-surname>ENEKOAGIRRE</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year></xocs:ref-info><xocs:ref-info refid="oref0040"/><xocs:ref-info refid="sbref0045"><xocs:ref-normalized-surname>ENEKO</xocs:ref-normalized-surname><xocs:ref-pub-year>2010</xocs:ref-pub-year><xocs:ref-first-fp>2889</xocs:ref-first-fp><xocs:ref-last-lp>2896</xocs:ref-last-lp><xocs:ref-normalized-initial>A</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="oref0050"/><xocs:ref-info refid="sbref0055"><xocs:ref-normalized-surname>ANDREA</xocs:ref-normalized-surname><xocs:ref-pub-year>2008</xocs:ref-pub-year></xocs:ref-info><xocs:ref-info refid="sbref0060"><xocs:ref-normalized-surname>YINGZHAO</xocs:ref-normalized-surname><xocs:ref-pub-year>2005</xocs:ref-pub-year><xocs:ref-first-fp>141</xocs:ref-first-fp><xocs:ref-last-lp>168</xocs:ref-last-lp><xocs:ref-normalized-initial>G</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0065"><xocs:ref-pub-year>1998</xocs:ref-pub-year><xocs:ref-normalized-srctitle>WORDNETELECTRONICLEXICALDATABASE</xocs:ref-normalized-srctitle></xocs:ref-info><xocs:ref-info refid="sbref0070"><xocs:ref-normalized-surname>MAREK</xocs:ref-normalized-surname><xocs:ref-pub-year>2013</xocs:ref-pub-year><xocs:ref-first-fp>2013</xocs:ref-first-fp><xocs:ref-normalized-initial>M</xocs:ref-normalized-initial></xocs:ref-info><xocs:ref-info refid="sbref0075"><xocs:ref-normalized-surname>MACIEJ</xocs:ref-normalized-surname><xocs:ref-pub-year>2009</xocs:ref-pub-year><xocs:ref-normalized-initial>P</xocs:ref-normalized-initial></xocs:ref-info></xocs:references><xocs:refkeys><xocs:refkey3>KEDZIAX2014X38</xocs:refkey3><xocs:refkey4lp>KEDZIAX2014X38X44</xocs:refkey4lp><xocs:refkey4ai>KEDZIAX2014X38XP</xocs:refkey4ai><xocs:refkey5>KEDZIAX2014X38X44XP</xocs:refkey5></xocs:refkeys><xocs:open-access><xocs:oa-article-status is-open-access="1" is-open-archive="0">Full</xocs:oa-article-status><xocs:oa-access-effective-date>2014-10-01T11:57:40Z</xocs:oa-access-effective-date><xocs:oa-sponsor><xocs:oa-sponsor-type>ElsevierWaived</xocs:oa-sponsor-type></xocs:oa-sponsor><xocs:oa-user-license>http://creativecommons.org/licenses/by-nc-nd/3.0/</xocs:oa-user-license><xocs:oa-access-inherited-from winid="http://vtw.elsevier.com/content/oaw/PROC_UNBOUNDED_ESWaived">OA-Window</xocs:oa-access-inherited-from></xocs:open-access><xocs:attachment-metadata-doc><xocs:attachment-set-type>item</xocs:attachment-set-type><xocs:pii-formatted>S2212-6678(14)00121-X</xocs:pii-formatted><xocs:pii-unformatted>S221266781400121X</xocs:pii-unformatted><xocs:eid>1-s2.0-S221266781400121X</xocs:eid><xocs:doi>10.1016/j.ieri.2014.09.073</xocs:doi><xocs:cid>282178</xocs:cid><xocs:timestamp>2014-10-10T10:10:04.759186-04:00</xocs:timestamp><xocs:cover-date-start>2014-01-01</xocs:cover-date-start><xocs:cover-date-end>2014-12-31</xocs:cover-date-end><xocs:attachments><xocs:web-pdf><xocs:attachment-eid>1-s2.0-S221266781400121X-main.pdf</xocs:attachment-eid><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S221266781400121X/MAIN/application/pdf/b2a6f589b8371f5b6e5c840d5e16c674/main.pdf</xocs:ucs-locator><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S221266781400121X/MAIN/application/pdf/b2a6f589b8371f5b6e5c840d5e16c674/main.pdf</xocs:ucs-locator><xocs:filename>main.pdf</xocs:filename><xocs:extension>pdf</xocs:extension><xocs:pdf-optimized>true</xocs:pdf-optimized><xocs:filesize>258277</xocs:filesize><xocs:web-pdf-purpose>MAIN</xocs:web-pdf-purpose><xocs:web-pdf-page-count>7</xocs:web-pdf-page-count><xocs:web-pdf-images><xocs:web-pdf-image><xocs:attachment-eid>1-s2.0-S221266781400121X-main_1.png</xocs:attachment-eid><xocs:ucs-locator>https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S221266781400121X/PREVIEW/image/png/9fb4be7521933a7158f1aec39ed399e1/main_1.png</xocs:ucs-locator><xocs:ucs-locator>https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S221266781400121X/PREVIEW/image/png/9fb4be7521933a7158f1aec39ed399e1/main_1.png</xocs:ucs-locator><xocs:filename>main_1.png</xocs:filename><xocs:extension>png</xocs:extension><xocs:filesize>49274</xocs:filesize><xocs:pixel-height>849</xocs:pixel-height><xocs:pixel-width>656</xocs:pixel-width><xocs:attachment-type>IMAGE-WEB-PDF</xocs:attachment-type><xocs:pdf-page-num>1</xocs:pdf-page-num></xocs:web-pdf-image></xocs:web-pdf-images></xocs:web-pdf></xocs:attachments></xocs:attachment-metadata-doc></xocs:meta><xocs:rawtext> IERI Procedia   10  ( 2014 )  38 â€“ 44  Available online at www.sciencedirect.com 2212-6678  2014 Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). Selection and peer review under responsibility of Information Engineering Research Institute doi: 10.1016/j.ieri.2014.09.073  ScienceDirect 2014 International Conference on Future Information Engineering  Distributionally Extended Network-Based Word Sense  Disambiguation in Semantic Clustering of Polish Texts  PaweÃ¡ KÄŠdzia 1 , Maciej Piasecki, Jan KocoÄ”, Agnieszka Indyka-Piasecka  WrocÃ¡aw University of Technology, ul. WybrzeÄªe WyspiaÄ”skiego 27, WrocÃ¡aw 50-370, Poland  bSecond affiliation, Address, City and Postcode, Country     Abstract  In the paper we present an extended version of the graph-based unsupervised Word Sense Disambiguation algorithm. The  algorithm is based on the spreading activation scheme applied to the graphs dynamically built on the basis of the text  words and a large wordnet. The algorithm, originally proposed for English and Princeton WordNet, was adapted to Polish  and plWordNet. An extension based on the knowledge acquired from the corpus-derived Measure of Semantic  Relatedness was proposed. The extended algorithm was evaluated against the manually disambiguated corpus. We  observed improvement in the case of the disambiguation performed for shorter text contexts. In addition the algorithm  application expressed improvement in document clustering task.    Â© 2014 PaweÃ¡ KÄŠdzia, Maciej Piasecki, Jan KocoÄ”, Agnieszka Indyka-Piasecka. Published by Elsevier B.V.  Selection and peer review under responsibility of Information Engineering Research Institute    Keywords: Word Sense Disambiguation, wordnet, text classification, plWordNet  1. Introduction  Documents are commonly represented in Information Retrieval as bags of words, i.e. collections of words  (words with the number of their occurrences). Linguistic structure of the text is very rarely taken into account,  mostly due to the limited robustness of the natural language processing (i.e. limited precision and speed of  processing). However, the bag of words model causes the loss of information even on the word level. Many                                                             1  * Corresponding author. Tel.: +48 71 320 42 24; fax: +0-000-000-0000.   E-mail address: pawel.kedzia@pwr.wroc.pl.   2014 Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license  (http://creativecommons.org/licenses/by-nc-nd/3.0/). Selection and peer review under responsibility of Information Engineering Research Institute 39 PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  words are polysemous and can express several meanings, e.g. the word car corresponds to 5 noun meanings in  Princeton WordNet 3.1 (PWN) (Fellbaum, 1998): car 1 â€“ a motor vehicle, car 2 â€“ â€œa wheeled vehicle adapted  to the rails of railroadâ€�, car 3 â€“ â€œthe compartment that is suspended from an airshipâ€�, car 4 â€“ an elevator car  and car 5 â€“ a cable car. Improper matching of the words in the user query against their use in the documents  can lead to incorrect retrieval or ranking of the results.  Word Sense Disambiguation (WSD) methods can potentially help in several Information Retrieval (IR)  tasks in which the user information need specification is longer than a couple of words, e.g. in Question  Answering, document classification and document clustering. However, supervised WSD tools (developed on  the basis of supervised machine learning algorithms applied to a text corpus that was manually annotated with  word senses) express relatively good accuracy but have coverage which is limited only to words annotated in  the corpus. Such corpus annotation is very laborious and costly, so the typical coverage is from 100 till  several thousand words at most. Unsupervised WSD methods are often based on the sense induction from text  corpora, but their accuracy is much lower than the accuracy of the supervised methods and the coverage is  still far from perfect (not all word senses are represented well enough). However, there is yet another group of  the unsupervised WSD methods â€“ algorithms that use the wordnet graph of relation (see Sec. 2) and the  spreading activation scheme to find senses matching the surrounding text passages.  Our goal was to adapt a spreading activation based WSD algorithm to a wordnet different than PWN,  namely Polish plWordNet, and the language different than English. Moreover, we wanted to extend the  wordnet with knowledge resources acquired from the text corpus and to build a WSD tool for practical  applications.  2. plWordNet â€“ repository of lexical senses  In the spreading activation based WSD (SA-WSD) a wordnet is used in two roles: as repository of senses  defining all senses per each word, and as a knowledge base describing senses by lexico-semantic relations.  A wordnet consists of synsets, lexical units and lexico-semantic relations. A lexical unit is a pair: a word  plus sense number, e.g. car 2. A synset is a set of near synonyms and consists of one or more lexical units.  Each synset represents a unique lexical meaning and synset identifiers can represent lexical meanings.  Lexico-semantic relations represent binary meaning associations between lexical units observed in the lexical  system. Lexico-semantic relations are encoded in the wordnet as relations between synsets (the basic ones) or  between lexical units, e.g. the synset from PWN 3.1 {car 1, auto 1, automobile 1, â€¦} is linked by the  hypernymy relation with the synset {motor vehicle 1, automotive vehicle 1} and by holonymy with the synset  {bumper 2}.  plWordNet 2.1 (plWN) is a huge wordnet for Polish of the size close to the PWN size: ~161 000 lexical  units, ~118 000 synsets and ~108 000 unique words. The lexical units are described by more than 40 different  lexico-semantic relations. plWN was developed on the basis of Polish corpora and provides better coverage of  the corpus vocabulary than PWN and higher relation density than PWN. However, plWN almost does not  have glosses for synsets (short textual sense descriptions) that are intensively used in SA-WSD methods.  3. Distributionally extended WSD  Many approaches to the graph-based WSD were proposed, e.g. GutiÃ©rrez et al. 2012, Tsatsaronis et al.  2010, Mihalcea and Figa 2004, Agirre and Soroa 2004, Navigli 2006, Sinha and Mihalcea 2007, Agirre and  Soora 2008]. In our work we follow the Page-Rank based approach proposed by Agirre and Soroa 2004  [Agirre and Soora 2008, Agirre et al. 2009, Agirre et al. 2010]. The key concepts are: Lexical Knowledge  Base (LKB) â€“ a set of the concepts (PWN synsets) together with the relations between them and the dictionary  40   PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  of lemmas (word types) describing associations between lemmas and concepts. LKB can be represented as a  graph G = (V;E) where V is the set of concepts and E is a set of relations in the concept set, i.e e i,j  Ä™ E is  undirected relation (v i , v j ), where v i , v j ×� V. The relations correspond to the wordnet lexico-semantic relations  and also weights are assigned to them. The graph based WSD builds a graph related to words included in a  text fragment, next applies a ranking function to the graph, chooses concepts with the highest final ranking  values from the graph and finally assigns them to the words in the text.   Agirre and Soroa 2004 [Agirre and Soora 2008, Agirre et al. 2009, Agirre et al. 2010] used the PWN  relation graph as the basis for LKB. Agirre and Soora 2009 proposed the idea of using Page-Rank approach to  WSD. Basic PR algorithm can be described by the state change equation: Pr =  cMPr + (1 - c)v where v is the  vector with N dimensions (i.e. graph nodes), and Pr is the vector of ranking values. The initial values of the  elements are set all to 1/N. M is a probability matrix of the size N x N, and M ij  = 1/d i  if there is an edge linking  v i  and v j  or 0 otherwise, where d j  is degree of v j  node in the graph, and c is a damping factor (typically set to  &lt;0.85, â€¦, 0.95&gt;). PR is run iteratively for predefined number of iterations.  Disambiguation of the words from a text contexts is done by: selecting the synsets that are associated with  lemmas from the text context, building a subgraph of the wordnet relation on the basis of the selected synsets,  running PR on the subgraph and choosing the appropriate synsets on the basis of the final node values.  This basic scheme can be extended with the use of the personalized vector v prior to the disambiguation. In  both cases the result is an assignment of the chosen synsets to the text words. The context can be one or many  sentences. Agirre and Soroa 2004 [Agirre and Soora 2008] proposed a slightly modified PR:            Â¦   j j i vP d +=vP 1 1 DD   where Ä® is damping factor. They also introduced modified estimation of the initial vector v values  according to which the values are focused only on the nodes including lemmas identical to the text words  being disambiguated. As a result, the probability mass is not distributed over the whole graph - this approach  is called Personalized Page Rank (PPR). The subgraph concept links come first from the wordnet relations  linking synsets selected by the text words. Links to synsets corresponding to words from the glosses of the  synset (selected previously) are added. It was assumed that the glosses were sense disambiguated. In this way  new concepts are added from the glosses to the subgraph which is bigger and provides more information  In our case plWN almost does not provide glosses and the glosses are not disambiguated. Unfortunately,  the additional links derived from glosses lead to the significant improvement in the SA-WSD algorithm.  To supplement the missing information, we used Measure of Semantic Relatedness (MSR) as an additional  source of links for the subgraphs. MSR assigns a numerical value to pairs of words such that words that are  semantically close receive higher values than those that are not related. MSR is built on the basis of the  statistical analysis of word distributions in a large corpus, i.e. words that occur in similar linguistic contexts  are described by similar feature vectors and receive higher values of relatedness. For the work presented here,  we used the MSR proposed by Piasecki, et al. 2009 in which word occurrences are described by a set of basic  syntactic relations with other words, co-occurrence frequencies are weighed by PMI and the relatedness is  calculated by the cosine measure. Using MSR, we constructed an extended LKB in which additional concepts  were added on the basis of the most related words from MSR. For each word w i  we acquired from MSR a list  SW i  of the k=20 most related words to w i . For each word w j  from the list SW i  we added to the disambiguation  subgraphs all synsets including w j  as additional concepts and all links between those synsets and synsets  already present in the subgraph, e.g. the initial list of 385 370 synset relations in the text-based subgraph was  expanded with 234 6834 new edges in the output graph.  41 PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  4. Evaluation  WSD algorithm can be evaluated directly by comparison of its decisions with the human judgments and,  indirectly, by applying the algorithm in a text processing task as a tool.  4.1. Corpus based evaluation   For comparison we used a part of the KPWr corpus of Polish [Broda et al. 2012] which is sense  disambiguated. This part include 1996 documents, 14 022 words and 60 unique lemmas manually sense  disambiguated. WSD annotation contains information about the appropriate plWN synset e.g.:  &lt;tok&gt;&lt;orth&gt;dni&lt;/orth&gt;      &lt;lex&gt;&lt;base&gt;dzie &lt;/base&gt;&lt;ctag&gt;subst:pl:nom:m3&lt;/ctag&gt;&lt;/lex&gt; z        â€¦.      &lt;prop key="sense:wsd_dzie "&gt;dzie z z -2&lt;/prop&gt; &lt;/tok&gt;  where dzieÄ” 2 `a dayâ€™ annotates the sense of the word dni `daysâ€™ (lemma dzieÄ”). The precision and recall of  our algorithm in relation to the annotation are presented in Table 1, where plWordnet data source means that  the subgraph included only relation added from plWN on the basis of the text word, MSRkbes20 â€“ the  subgraph was built on the basis of the synsets corresponding to the 20 most related words and  plWwordNet+MSRkbest20 â€“ the full extended subgraph was built. Sentence context type describes the size of  the text context used for the subgraph construction: sentence by sentence (initial vector v has assigned values  in the nodes with lemmas from the sentence in PPR) or the whole document at once.  Table 1. Results of precision on annotated KPWr corpora for Personalized Page rank with 30 iterations.  Data source Context type Noun precision Verb precision  plWordNet Sentence 0.34 0.24  Whole document 0.43 0.28  MSRkbest20 Sentence 0.38 0.0  Whole document 0.37 0.0  plWordNet +  MSRkbest20  Sentence 0.39 0.22  Whole document 0.37 0.27  The best result is highlighted. In all configurations the recall was equal to 0.88. The precision of for verbs  in the case of MSRkbes20 data source is equal to 0, because the used MSR covered only nouns. The use of  the 20 most related words improved the results only in the case of sentences as contexts. A potential cause is  that the first words have a high similarity, but the further do not, e.g. for word subst:opatrznoÄžÃ¼ `providenceâ€™  the most related word is subst:bÃ³g `Godâ€™ (~0.25) but one of the last is subst:ojciec `fatherâ€™  (~0.096).  4.2. Evaluation by application  Evaluation by application was performed for document clustering due to the available document collection.  We used two different data sources with two different representations: TF and TF/IDF with two types of  features (bag-of-words of orthographic forms and plWN synsets corresponding to the text words). The first set  of documents was derived from the Polish Wikipedia (http://pl.wikipedia.org). It contains 40 documents from  4 categories (10 documents per category): Planets (P in Table 2) , Cities (C), Felidae (F) and Canidae animals  (A). During evaluation we used CLUTO system [Tagarelli and Karypis 2008, Zhao and Karypis 2005] for  42   PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  clustering. The results presented in Table 2 were achieved for RBR clustering method with G1' criteria  function, 4 clusters, the cosine similarity function and TF documents representation.  Table 2. Clustering results using RBR method, G1' criteria function, cosine similarity and 4 clusters for Wiki dataset and synset features. Class Size ISim ISdev ESim ESdev Entropy Purity P C F A  0 10 0.341 0.060 0.019 0.004 0.000 1.000 0 10 0 0  1 10 0.299 0.045 0.021 0.006 0.000 1.000 10 0 0 0  2  9 0.210 0.023 0.033 0.010 0.000 1.000 0 0 0 9  3  11 0.182 0.020 0.029 0.008 0.220 0.909 0 0 10 1  G1'=510, Entropy: 0.062, Purity: 0.974 Accuracy = 97.5%  The purity and entropy indicator (the general and in all subclass) are almost perfect. Only one document  from Canidae was erroneously clustered to Felidae. It is about hyenas that are related to Canidae, but they  belong to the Felidae taxonomy. So it can be treated as correct clustering. In Table 3 the results with bag of  words features for the same dataset were shown. They are worse than those for WSD synset features.  Table 3. Clustering results using RBR method, G1' criteria function, cosine similarity and 4 clusters for Wiki dataset and b-o-w features. Class Size ISim ISdev ESim ESdev Entropy Purity P C F A  0 9 0.226 0.020 0.013 0.002 0.217 0.889 0 10 0 0  1 10 0.184 0.023 0.010 0.002 0.000 1.000 10 0 0 0  2  9 0.151 0.012 0.015 0.006 0.395 0.667 0 0 3 6  3  11 0.143 0.010 0.015 0.003 0.407 0.636 0 0 7 4  G1'=470, Entropy: 0.256, Purity: 0.795 Accuracy = 82.5%  The second dataset comes from KPWr and includes 30 documents from 3 categories: Government (G in  Table 4) Science (S) and Technical (T) with 10 documents in each category. The results for best configuration  from the Wikipedia dataset are presented in Table 4.  Table 4. Clustering results using RBR method, G1' criteria function, cosine similarity and 4 clusters, KPWr dataset and synset features. Class Size ISim ISdev ESim ESdev Entropy Purity G S T  0 13 0.268 0.061 0.065 0.025 0.829 0.462 1 6 6  1 8 0.418 0.079 0.037 0.020 0.000 1.000 8 0 0  2  8 0.192 0.027 0.078 0.039 0.500 0.500 1 4 3  G1'=430, Entropy: 0.616, Purity: 0.621 Accuracy = 58%  On this dataset, the obtained results were worse than those on the Wikipedia (also for bag of words feature  in Table 5). Only for the government category it was possible to separate the documents. This may be due to  the fact that the documents in KPWr are more complex and longer than in the Wikipedia.  Table 5. Clustering results using RBR method, G1' criteria function, cosine similarity and 4 clusters, KPWr dataset and b-o-w features. Class Size ISim ISdev ESim ESdev Entropy Purity G S T  0 13 0.497 0.111 0.105 0.019 0.648 0.538 1 7 5  1 10 0.320 0.091 0.048 0.047 0.234 0.900 9 1 0  43 PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  2  6 0.315 0.087 0.111 0.041 0.730 0.500 0 2 4  G1'=392, Entropy: 0.447, Purity: 0.655 Accuracy = 71,5%  5. Conclusions (MP)  The application of the large lexicon WSD algorithm brought very encouraging results. WSD of the limited  accuracy in tests on the disambiguated corpus, showed improvement in document clustering. The WSD  algorithm based on spreading activation has been easily adapted to the new language and new wordnet. So,  from this perspective, even the evaluation by comparison with the human judgment can be treated as positive.  In order to supplement the missing information in the plWordNet (i.e. glosses) we used a corpus-derived  Measure of Semantic Relatedness which provides automatically extracted semantic associations between  words. The extension of WSD algorithm with the information from MSR brought improvement for shorter  contexts, but decreased the accuracy for larger contexts. There is clear need for further research on defining  MSR parameters appropriate for WSD and further exploration of the corpus-derived information in SA WSD.  Acknowledgements. Polish National Centre for Research and Development project SyNaT and the European  Union within European Innovative Economy Programme project NEKST POIG.01.01.02-14-013/09  References  [1] Yoan GutiÃ©rrez,  Sonia VÃ¡zquez, AndrÃ©s Montoyo . A graph-Based Approach to WSD Using Relevant  Semantic Trees and N-Cliques Model. Computational Linguistics and Intelligent Text Processing LNCS  Volume 7181, 2012, pp 225-237   [2] George Tsatsaronis, Iraklis Varlamis, and Kjetil Norvag An Experimental Study on Unsupervised Graph- based Word Sense Disambiguation, LNCS Volume 6008, 2010, pp 184-198   [3] R. Mihalcea, P. Tarau, and E. Figa. Pagerank on semantic networks with application to word sense  disambiguation. In Proc. of COLING, 2004.   [4] E. Agirre and A. Soroa. Personalizing pagerank for word sense disambiguation. In Proc. Of EACL, pages  33â€“41, 2009.  [5] R. Navigli. Online word sense disambiguation with structural semantic interconnections. In Proc. of  EACL, 2006.  [6] R. Sinha and R. Mihalcea. Unsupervised graph-based word sense disambiguation using measures of word  semantic similarity. In Proc. of ICSC, 2007.  [7] Eneko Agirre and Aitor Soroa. Using the multilingual central repository for graph-based word sense  disambiguation. In Proc. of the Language Resources and Evaluation, 2008. ELRA.   [8] Eneko Agirre, Oier Lopez De Lacalle, and Aitor Soroa. Knowledge-based wsd on specific domains:  Performing better than generic supervised wsd. In Proceedings of the 21st International Jont Conference on  Artifical Intelligence , IJCAIâ€™09, pages 1501â€“1506, San Francisco, CA, USA, 2009.  [9] Eneko Agirre, Aitor Soroa, and Mark Stevenson. Graph-based word sense disambiguation of biomedical  documents. Bioinformatics , 26(22):2889â€“2896, November 2010b.  [10] Bartosz Broda, MichaÃ¡ MarciÄ”czuk, Marek Maziarz, Adam Radziszewski and Adam WardyÄ”ski: KPWr:  Towards a Free Corpus of Polish. LREC 2012.   [11] Andrea Tagarelli and George Karypis. A Segment-based Approach To Clustering Multi-Topic  Documents. Text Mining Workshop, SIAM Datamining Conference, 2008.   [12] Ying Zhao and George Karypis. Hierarchical Clustering Algorithms for Document Datasets. Data  Mining and Knowledge Discovery, Vol. 10, No. 2, pp. 141 - 168, 2005.  [13] Christiane Fellbaum, editor. 1998. WordNet â€“ An Electronic Lexical Database. The MIT Press.  [14] Marek Maziarz, Maciej Piasecki, Ewa Rudnicka, and Stan Szpakowicz. 2013. Beyond the transfer-and  44   PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  merge wordnet construction: plWordNet and a comparison with WordNet. In Proc. of the Recent Advances in  Natural Language Processing RANLP 2013, Hissar, Bulgaria, ACL, 2013.  [15] Maciej Piasecki, StanisÃ¡aw Szpakowicz, and Bartosz Broda. 2009. A Wordnet from the Ground Up.  Oficyna Wydawnicza Politechniki WrocÃ¡awskiej.  11 0.105 0.019 0.648 0.538 1 7 5  1 10 0.320 0.091 0.048 0.047 0.234 0.900 9 1 0  43 PaweÅ‚ KÄ™dzia et al. /  IERI Procedia  10 ( 2014 )  38 â€“ 44  2  6 0.315 0.087 0.111 0.041 0.730 0.500 0 2 4  G1'=392, Entropy: 0.447, Purity: 0.655 Accuracy = 71,5%  5. Conclusions (MP)  The application of the large lexicon WSD algorithm brought very encouraging results. WSD of the limited  accuracy in tests on the disambiguated corpus, showed improvement in document clustering. The WSD  algorithm based on spreading activation has been easily adapted to the new language and new wordnet. So,  from this perspective, even the evaluation by comparison with the human judgment can be treated as positive.  In order to supplement the missing information in the plWordNet (i.e. glosses) we used a corpus-derived  Measure of Semantic Relatedness which provides automatically extracted semantic associations between  words. The extension of WSD algorithm with the information from MSR brought improvement for shorter  contexts, but decreased the accuracy for larger contexts. There is clear need for further research on defining  MSR parameters appropriate for WSD and further exploration of the corpus-derived information in SA WSD.  Acknowledgements. Polish National Centre for Research and Development project SyNaT and the European  Union within European Innovative Economy Programme project NEKST POIG.01.01.02-14-013/09  References  [1] Yoan GutiÃ©rrez,  Sonia VÃ¡zquez, AndrÃ©s Montoyo . A graph-Based Approach to WSD Using Relevant  Semantic Trees and N-Cliques Model. Computational Linguistics and Intelligent Text Processing LNCS  Volume 7181, 2012, pp 225-237   [2] George Tsatsaronis, Iraklis Varlamis, and Kjetil Norvag An Experimental Study on Unsupervised Graph- based Word Sense Disambiguation, LNCS Volume 6008, 2010, pp 184-198   [3] R. Mihalcea, P. Tarau, and E. Figa. Pagerank on semantic networks with application to word sense  disambiguation. In Proc. of COLING, 2004.   [4] E. Agirre and A. Soroa. Personalizing pagerank for word sense disambiguation. In Proc. Of EACL, pages  33â€“41, 2009.  [5] R. Navigli. Online word sense disambiguation with structural semantic interconnections. In Proc. of  EACL, 2006.  [6] R. Sinha and R. Mihalcea. Unsupervised graph-based word sense disambiguation using measures of word  semantic similarity. In Proc. of ICSC, 2007.  [7] Eneko Agirre and Aitor Soroa. Using the multilingual central repository for graph-based word sense  disambiguation. In Proc. of the Language Resources and Evaluation, 2008. ELRA.   [8] Eneko Agirre, Oier Lopez De Lacalle, and Aitor Soroa. Knowledge-based wsd on specific domains:  Performing better than generic supervised wsd. In Proceedings of the 21st International Jont Conference on  Artifical Intelligence , IJCAIâ€™09, pages 1501â€“1506, San Francisco, CA, USA, 2009.  [9] Eneko Agirre, Aitor Soroa, and Mark Stevenson. Graph-based word sense disambiguation of biomedical  documents. Bioinformatics , 26(22):2889â€“2896, November 2010b.  [10] Bartosz Broda, MichaÃ¡ MarciÄ”czuk, Marek Maziarz, Adam Radziszewski and Adam WardyÄ”ski: KPWr:  Towards a Free Corpus of Polish. LREC 2012.   [11] Andrea Tagarelli and George Karypis. A Segment-based Approach To Clustering Multi-Topic  Documents. Text Mining Workshop, SIAM Datamining Conference, 2008.   [</xocs:rawtext><xocs:serial-item><article xmlns="http://www.elsevier.com/xml/ja/dtd" version="5.2" xml:lang="en" docsubtype="fla"><item-info><jid>IERI</jid><aid>453</aid><ce:pii>S2212-6678(14)00121-X</ce:pii><ce:doi>10.1016/j.ieri.2014.09.073</ce:doi><ce:copyright type="unknown" year="2014"/></item-info><head><ce:article-footnote><ce:label>☆</ce:label><ce:note-para id="npar0005" view="all">Selection and peer review under responsibility of Information Engineering Research Institute.</ce:note-para></ce:article-footnote><ce:title id="tit0005">Distributionally Extended Network-based Word Sense Disambiguation in Semantic Clustering of Polish Texts</ce:title><ce:author-group id="aug0005"><ce:author id="aut0005"><ce:given-name>Paweł</ce:given-name><ce:surname>Kędzia</ce:surname><ce:cross-ref id="crf0005" refid="cor0005"><ce:sup loc="post">⁎</ce:sup></ce:cross-ref><ce:e-address id="eadd0005" type="email">pawel.kedzia@pwr.wroc.pl</ce:e-address></ce:author><ce:author id="aut0010"><ce:given-name>Maciej</ce:given-name><ce:surname>Piasecki</ce:surname></ce:author><ce:author id="aut0015"><ce:given-name>Jan</ce:given-name><ce:surname>Kocoń</ce:surname></ce:author><ce:author id="aut0020"><ce:given-name>Agnieszka</ce:given-name><ce:surname>Indyka-Piasecka</ce:surname></ce:author><ce:affiliation id="aff0005"><ce:textfn>Wrocław University of Technology, ul. Wybrzeże Wyspiańskiego 27, Wrocław 50-370, Poland</ce:textfn></ce:affiliation><ce:correspondence id="cor0005"><ce:label>⁎</ce:label><ce:text>Corresponding author. Tel.: +48 71 320 42 24.</ce:text></ce:correspondence></ce:author-group><ce:abstract id="abs0005" view="all" class="author"><ce:section-title id="sect0005">Abstract</ce:section-title><ce:abstract-sec id="abst0005" view="all"><ce:simple-para id="spar0005" view="all">In the paper we present an extended version of the graph-based unsupervised Word Sense Disambiguation algorithm. The algorithm is based on the spreading activation scheme applied to the graphs dynamically built on the basis of the text words and a large wordnet. The algorithm, originally proposed for English and Princeton WordNet, was adapted to Polish and plWordNet. An extension based on the knowledge acquired from the corpus-derived Measure of Semantic Relatedness was proposed. The extended algorithm was evaluated against the manually disambiguated corpus. We observed improvement in the case of the disambiguation performed for shorter text contexts. In addition the algorithm application expressed improvement in document clustering task.</ce:simple-para></ce:abstract-sec></ce:abstract><ce:keywords id="kwd0005" class="keyword" view="all"><ce:section-title id="sect0010">Keywords</ce:section-title><ce:keyword id="kw0005"><ce:text>Word Sense Disambiguation</ce:text></ce:keyword><ce:keyword id="kw0010"><ce:text>wordnet</ce:text></ce:keyword><ce:keyword id="kw0015"><ce:text>text classification</ce:text></ce:keyword><ce:keyword id="kw0020"><ce:text>plWordNet</ce:text></ce:keyword></ce:keywords></head><tail view="all"><ce:bibliography id="bibl0005" view="all"><ce:section-title id="sect0020">References</ce:section-title><ce:bibliography-sec id="bibs0005" view="all"><ce:bib-reference id="bib0005"><ce:label>[1]</ce:label><sb:reference id="sbref0005"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Yoan Gutiérrez</ce:surname></sb:author><sb:author><ce:surname>Sonia Vázquez</ce:surname></sb:author><sb:author><ce:surname>Andrés Montoyo</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A graph-Based Approach to WSD Using Relevant Semantic Trees and N-Cliques Model</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Computational Linguistics and Intelligent Text Processing LNCS</sb:maintitle></sb:title><sb:volume-nr>7181</sb:volume-nr></sb:series><sb:date>2012</sb:date></sb:issue><sb:pages><sb:first-page>225</sb:first-page><sb:last-page>237</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0010"><ce:label>[2]</ce:label><sb:reference id="sbref0010"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>George Tsatsaronis</ce:surname></sb:author><sb:author><ce:surname>Iraklis Varlamis</ce:surname></sb:author><sb:author><ce:surname>Kjetil Norvag</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>An Experimental Study on Unsupervised Graph-based Word Sense Disambiguation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>LNCS</sb:maintitle></sb:title><sb:volume-nr>6008</sb:volume-nr></sb:series><sb:date>2010</sb:date></sb:issue><sb:pages><sb:first-page>184</sb:first-page><sb:last-page>198</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0015"><ce:label>[3]</ce:label><sb:reference id="sbref0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Mihalcea</ce:surname></sb:author><sb:author><ce:given-name>P.</ce:given-name><ce:surname>Tarau</ce:surname></sb:author><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Figa</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Pagerank on semantic networks with application to word sense disambiguation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. of COLING</sb:maintitle></sb:title></sb:series><sb:date>2004</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0020"><ce:label>[4]</ce:label><sb:reference id="sbref0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>E.</ce:given-name><ce:surname>Agirre</ce:surname></sb:author><sb:author><ce:given-name>A.</ce:given-name><ce:surname>Soroa</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Personalizing pagerank for word sense disambiguation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. Of EACL</sb:maintitle></sb:title></sb:series><sb:date>2009</sb:date></sb:issue><sb:pages><sb:first-page>33</sb:first-page><sb:last-page>41</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0025"><ce:label>[5]</ce:label><sb:reference id="sbref0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Navigli</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Online word sense disambiguation with structural semantic interconnections</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. of EACL</sb:maintitle></sb:title></sb:series><sb:date>2006</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0030"><ce:label>[6]</ce:label><sb:reference id="sbref0030"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Sinha</ce:surname></sb:author><sb:author><ce:given-name>R.</ce:given-name><ce:surname>Mihalcea</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Unsupervised graph-based word sense disambiguation using measures of word semantic similarity</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. of ICSC</sb:maintitle></sb:title></sb:series><sb:date>2007</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0035"><ce:label>[7]</ce:label><sb:reference id="sbref0035"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Eneko Agirre</ce:surname></sb:author><sb:author><ce:surname>Aitor</ce:surname></sb:author><sb:author><ce:surname>Soroa</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Using the multilingual central repository for graph-based word sense disambiguation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. of the Language Resources and Evaluation, ELRA</sb:maintitle></sb:title></sb:series><sb:date>2008</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0040"><ce:label>[8]</ce:label><ce:other-ref id="oref0040"><ce:textref>Eneko Agirre, Oier Lopez De Lacalle, Aitor Soroa. Knowledge-based wsd on specific domains: Performing better than generic supervised wsd. In Proceedings of the 21st International Jont Conference on Artifical Intelligence, IJCAI’09, pages 1501-1506, San Francisco, CA, USA, 2009.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0045"><ce:label>[9]</ce:label><sb:reference id="sbref0045"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Agirre</ce:given-name><ce:surname>Eneko</ce:surname></sb:author><sb:author><ce:given-name>Soroa</ce:given-name><ce:surname>Aitor</ce:surname></sb:author><sb:author><ce:given-name>Mark</ce:given-name><ce:surname>Stevenson</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Graph-based word sense disambiguation of biomedical documents</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Bioinformatics</sb:maintitle></sb:title><sb:volume-nr>26</sb:volume-nr></sb:series><sb:issue-nr>22</sb:issue-nr><sb:date>2010 November</sb:date></sb:issue><sb:pages><sb:first-page>2889</sb:first-page><sb:last-page>2896</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0050"><ce:label>[10]</ce:label><ce:other-ref id="oref0050"><ce:textref>Bartosz Broda, Michał Marcińczuk, Marek Maziarz, Adam Radziszewski and Adam Wardyński: KPWr: Towards a Free Corpus of Polish. LREC 2012.</ce:textref></ce:other-ref></ce:bib-reference><ce:bib-reference id="bib0055"><ce:label>[11]</ce:label><sb:reference id="sbref0055"><sb:contribution langtype="en"><sb:authors><sb:author><ce:surname>Andrea</ce:surname></sb:author><sb:author><ce:surname>Tagarelli</ce:surname></sb:author><sb:author><ce:surname>George</ce:surname></sb:author><sb:author><ce:surname>Karypis</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A Segment-based Approach To Clustering Multi-Topic Documents</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Text Mining Workshop, SIAM Datamining Conference</sb:maintitle></sb:title></sb:series><sb:date>2008</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0060"><ce:label>[12]</ce:label><sb:reference id="sbref0060"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>George</ce:given-name><ce:surname>Ying Zhao</ce:surname></sb:author><sb:author><ce:surname>Karypis</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Hierarchical Clustering Algorithms for Document Datasets</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Data Mining and Knowledge Discovery</sb:maintitle></sb:title><sb:volume-nr>10</sb:volume-nr></sb:series><sb:issue-nr>2</sb:issue-nr><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>141</sb:first-page><sb:last-page>168</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0065"><ce:label>[13]</ce:label><sb:reference id="sbref0065"><sb:host><sb:edited-book><sb:editors><sb:editor><ce:surname>Christiane Fellbaum</ce:surname></sb:editor></sb:editors><sb:title><sb:maintitle>WordNet – An Electronic Lexical Database</sb:maintitle></sb:title><sb:date>1998</sb:date><sb:publisher><sb:name>The MIT Press</sb:name></sb:publisher></sb:edited-book></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0070"><ce:label>[14]</ce:label><sb:reference id="sbref0070"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Maziarz</ce:given-name><ce:surname>Marek</ce:surname></sb:author><sb:author><ce:given-name>Piasecki</ce:given-name><ce:surname>Maciej</ce:surname></sb:author><sb:author><ce:given-name>Rudnicka</ce:given-name><ce:surname>Ewa</ce:surname></sb:author><sb:author><ce:given-name>Szpakowicz</ce:given-name><ce:surname>Stan</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Beyond the transfer-and merge wordnet construction: plWordNet and a comparison with WordNet</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>In Proc. of the Recent Advances in Natural Language Processing RANLP 2013, Hissar, Bulgaria, ACL</sb:maintitle></sb:title></sb:series><sb:date>2013</sb:date></sb:issue><sb:pages><sb:first-page>2013</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib0075"><ce:label>[15]</ce:label><sb:reference id="sbref0075"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>Piasecki</ce:given-name><ce:surname>Maciej</ce:surname></sb:author><sb:author><ce:given-name>Szpakowicz</ce:given-name><ce:surname>Stanisław</ce:surname></sb:author><sb:author><ce:given-name>Broda</ce:given-name><ce:surname>Bartosz</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A Wordnet from the Ground Up</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Oficyna Wydawnicza Politechniki Wrocławskiej</sb:maintitle></sb:title></sb:series><sb:date>2009</sb:date></sb:issue></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography></tail></article></xocs:serial-item></xocs:doc></originalText></full-text-retrieval-response>
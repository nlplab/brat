T1	TASK 220 230	embeddings
T2	METHOD 257 277	matrix factorization
T3	METHOD 330 354	neural language modeling
R1	addresses Arg1:T3 Arg2:T1	
R2	addresses Arg1:T2 Arg2:T1	
T4	TASK 415 428	POS induction
T5	METHOD 634 654	Skip-gram embeddings
T6	METHOD 693 711	log bilinear model
R3	is_subclass_of Arg1:T5 Arg2:T6	
T7	METHOD 950 981	Structured skip-gram embeddings
T8	METHOD 1022 1042	skip-gram embeddings
R4	is_subclass_of Arg1:T7 Arg2:T8	
T9	SOFTWARE 1157 1165	word2vec
T10	SOFTWARE 1172 1209	Ling et al. (2015)'s modified version
T11	METHOD 1250 1270	skip-gram embeddings
R5	implements Arg1:T10 Arg2:T11	
R6	implements Arg1:T9 Arg2:T11	
T12	TASK 0 15	Word embeddings
